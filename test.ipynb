{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f022df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def load_master_data_safely():\n",
    "    \"\"\"Safely load master data and check columns\"\"\"\n",
    "    print(\"📊 Loading master dataset safely...\")\n",
    "    \n",
    "    try:\n",
    "        # Try loading with coordinates first\n",
    "        if os.path.exists(\"data/master_transactions_with_coords.parquet\"):\n",
    "            master_data = pl.read_parquet(\"data/master_transactions_with_coords.parquet\")\n",
    "            print(f\"✅ Master data with coordinates loaded: {master_data.shape}\")\n",
    "        else:\n",
    "            # Load original master data\n",
    "            master_data = pl.read_parquet(\"data/master_transactions.parquet\")\n",
    "            print(f\"✅ Master data loaded: {master_data.shape}\")\n",
    "            \n",
    "            # Add coordinates if needed\n",
    "            print(\"🗺️ Adding coordinates...\")\n",
    "            stores_original = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\stores.csv')\n",
    "            stores_coords = pl.from_pandas(stores_original).select([\n",
    "                'Store ID', 'Latitude', 'Longitude'\n",
    "            ])\n",
    "            \n",
    "            master_data = master_data.join(stores_coords, on='Store ID', how='left')\n",
    "            master_data.write_parquet(\"data/master_transactions_with_coords.parquet\")\n",
    "            print(\"✅ Coordinates added and saved!\")\n",
    "        \n",
    "        # Verify key columns exist\n",
    "        required_columns = ['Line_Total_USD', 'Unit Price', 'Quantity', 'Country', 'Transaction Type']\n",
    "        missing_columns = [col for col in required_columns if col not in master_data.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"❌ Missing columns: {missing_columns}\")\n",
    "            return None\n",
    "        \n",
    "        print(\"✅ All required columns found!\")\n",
    "        return master_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading master data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c17fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading master dataset safely...\n",
      "✅ Master data with coordinates loaded: (6416827, 45)\n",
      "✅ All required columns found!\n"
     ]
    }
   ],
   "source": [
    "master_data = load_master_data_safely()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4175b0f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming master_data is a Polars DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m city_counts_df \u001b[38;5;241m=\u001b[39m master_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m      7\u001b[0m city_counts_df\u001b[38;5;241m.\u001b[39mwrite_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/city_counts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming master_data is a Polars DataFrame\n",
    "city_counts_df = master_data.groupby(\"City\").count().sort(\"count\", descending=True)\n",
    "\n",
    "# Save to CSV\n",
    "city_counts_df.write_csv(\"data/city_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5536d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alan\\AppData\\Local\\Temp\\ipykernel_28480\\2483994064.py:10: DeprecationWarning:\n",
      "\n",
      "`pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Confirm your frame is a normal DataFrame, not LazyFrame\n",
    "print(type(master_data))  # should show: polars.dataframe.frame.DataFrame\n",
    "\n",
    "# Now perform value counts\n",
    "city_counts_df = (\n",
    "    df\n",
    "    .group_by(\"City\")  # not `groupby`, correct is `group_by`\n",
    "    .agg(pl.count().alias(\"Count\"))\n",
    "    .sort(\"Count\", descending=True)\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "city_counts_df.write_csv(\"data/city_counts2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "city_translation_map = {\n",
    "}\n",
    "\n",
    "country_translation_map = {\n",
    "    '中国': 'China',\n",
    "    'España': 'Spain',\n",
    "    'Portugal': 'Portugal',\n",
    "    'Deutschland': 'Germany',\n",
    "    'France': 'France',\n",
    "    'United Kingdom': 'United Kingdom',\n",
    "    'United States': 'United States'\n",
    "}\n",
    "\n",
    "def clean_and_translate_data(master_data, city_translation_map, country_translation_map):\n",
    "    \"\"\"\n",
    "    Clean and translate city and country names into English using Polars DataFrame.\n",
    "    Compatible with older Polars versions.\n",
    "    \"\"\"\n",
    "    master_data = master_data.with_columns([\n",
    "        pl.col(\"City\").replace(city_translation_map).alias(\"City\"),\n",
    "        pl.col(\"Country\").replace(country_translation_map).alias(\"Country\")\n",
    "    ])\n",
    "    return master_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b91661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_translation_map = {\"München\": \"Munich\", \"Köln\": \"Cologne\"}\n",
    "# country_translation_map = {\"Deutschland\": \"Germany\"}\n",
    "\n",
    "df = clean_and_translate_data(master_data, city_translation_map, country_translation_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "956f8392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (763, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>City</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Motherwell&quot;</td><td>2065</td></tr><tr><td>&quot;Ronda&quot;</td><td>276</td></tr><tr><td>&quot;Alboraya&quot;</td><td>1724</td></tr><tr><td>&quot;Huyton&quot;</td><td>2113</td></tr><tr><td>&quot;Skokie&quot;</td><td>5660</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Kornwestheim&quot;</td><td>417</td></tr><tr><td>&quot;Rubí&quot;</td><td>2113</td></tr><tr><td>&quot;Mettmann&quot;</td><td>231</td></tr><tr><td>&quot;Peoria (AZ)&quot;</td><td>4874</td></tr><tr><td>&quot;Gáldar&quot;</td><td>199</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (763, 2)\n",
       "┌──────────────┬───────┐\n",
       "│ City         ┆ count │\n",
       "│ ---          ┆ ---   │\n",
       "│ str          ┆ u32   │\n",
       "╞══════════════╪═══════╡\n",
       "│ Motherwell   ┆ 2065  │\n",
       "│ Ronda        ┆ 276   │\n",
       "│ Alboraya     ┆ 1724  │\n",
       "│ Huyton       ┆ 2113  │\n",
       "│ Skokie       ┆ 5660  │\n",
       "│ …            ┆ …     │\n",
       "│ Kornwestheim ┆ 417   │\n",
       "│ Rubí         ┆ 2113  │\n",
       "│ Mettmann     ┆ 231   │\n",
       "│ Peoria (AZ)  ┆ 4874  │\n",
       "│ Gáldar       ┆ 199   │\n",
       "└──────────────┴───────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"City\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5e828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
