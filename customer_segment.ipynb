{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from operator import attrgetter\n",
    "\n",
    "def load_master_data_for_customer_segmentation():\n",
    "    \"\"\"Load master data for customer segmentation analysis\"\"\"\n",
    "    print(\" Loading master data for customer segmentation analysis...\")\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(\"data/master_transactions_with_coords.parquet\"):\n",
    "            master_data = pl.read_parquet(\"data/master_transactions_with_coords.parquet\")\n",
    "        else:\n",
    "            master_data = pl.read_parquet(\"data/master_transactions.parquet\")\n",
    "        \n",
    "        print(f\" Master data loaded: {master_data.shape}\")\n",
    "        return master_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error loading master data: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_advanced_rfm_analysis(master_data):\n",
    "    \"\"\"Calculate advanced RFM analysis with additional customer metrics\"\"\"\n",
    "    print(\"Calculating Advanced RFM Analysis...\")\n",
    "    \n",
    "    # Filter for sales only\n",
    "    sales_data = master_data.filter(pl.col(\"Transaction Type\") == \"Sale\")\n",
    "    \n",
    "    # Get the latest date in the dataset as reference point\n",
    "    latest_date = sales_data.select(pl.col(\"Date\").max()).item()\n",
    "    print(f\"Analysis reference date: {latest_date}\")\n",
    "    \n",
    "    # Calculate comprehensive RFM metrics\n",
    "    # Calculate comprehensive RFM metrics\n",
    "    rfm_data = sales_data.group_by(\"Customer ID\").agg([\n",
    "        # Core RFM metrics\n",
    "        (pl.lit(latest_date) - pl.col(\"Date\").max()).dt.total_days().alias(\"Recency_Days\"),\n",
    "        pl.col(\"Invoice ID\").n_unique().alias(\"Frequency\"),\n",
    "        pl.col(\"Line_Total_USD\").sum().alias(\"Monetary_Value\"),\n",
    "        \n",
    "        # Additional customer behavior metrics\n",
    "        pl.col(\"Date\").min().alias(\"First_Purchase_Date\"),\n",
    "        pl.col(\"Date\").max().alias(\"Last_Purchase_Date\"),\n",
    "        pl.col(\"Quantity\").sum().alias(\"Total_Items_Purchased\"),\n",
    "        pl.col(\"Product ID\").n_unique().alias(\"Unique_Products_Purchased\"),\n",
    "        pl.col(\"Category\").n_unique().alias(\"Unique_Categories_Purchased\"),\n",
    "        pl.col(\"Store ID\").n_unique().alias(\"Stores_Visited\"),\n",
    "        pl.col(\"Line_Total_USD\").mean().alias(\"Average_Order_Value\"),\n",
    "        (pl.col(\"Line_Total_USD\").sum() / pl.col(\"Quantity\").sum()).alias(\"Average_Unit_Price\"),\n",
    "        \n",
    "        # Seasonal behavior (simplified)\n",
    "        pl.col(\"Date\").dt.quarter().first().alias(\"First_Quarter\"),\n",
    "        pl.col(\"Date\").dt.weekday().first().alias(\"First_Weekday\"),\n",
    "        pl.col(\"Date\").dt.month().first().alias(\"First_Month\"),\n",
    "        \n",
    "        # Product preferences\n",
    "        pl.col(\"Category\").first().alias(\"First_Category\"),  # Changed from mode() to first()\n",
    "        pl.col(\"Sub Category\").first().alias(\"First_Sub_Category\")  # Changed from mode() to first()\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # Convert to pandas for advanced calculations\n",
    "    rfm_pandas = rfm_data.to_pandas()\n",
    "    \n",
    "    # Calculate customer lifetime and additional metrics\n",
    "    rfm_pandas['Customer_Lifetime_Days'] = (rfm_pandas['Last_Purchase_Date'] - rfm_pandas['First_Purchase_Date']).dt.days\n",
    "    rfm_pandas['Customer_Lifetime_Days'] = rfm_pandas['Customer_Lifetime_Days'].fillna(1).replace(0, 1)\n",
    "    \n",
    "    # Advanced behavioral metrics\n",
    "    rfm_pandas['Monthly_Purchase_Frequency'] = (rfm_pandas['Frequency'] / rfm_pandas['Customer_Lifetime_Days'] * 30).fillna(1.0)\n",
    "    rfm_pandas['Items_Per_Transaction'] = rfm_pandas['Total_Items_Purchased'] / rfm_pandas['Frequency']\n",
    "    rfm_pandas['Categories_Per_Transaction'] = rfm_pandas['Unique_Categories_Purchased'] / rfm_pandas['Frequency']\n",
    "    rfm_pandas['Store_Loyalty_Score'] = 1 / rfm_pandas['Stores_Visited']  # Higher = more loyal to specific stores\n",
    "    rfm_pandas['Product_Diversity_Score'] = rfm_pandas['Unique_Products_Purchased'] / rfm_pandas['Frequency']\n",
    "    \n",
    "    # Calculate percentile-based RFM scores (1-5 scale)\n",
    "    rfm_pandas['R_Score'] = pd.qcut(rfm_pandas['Recency_Days'], 5, labels=[5,4,3,2,1], duplicates='drop')  # Lower recency = higher score\n",
    "    rfm_pandas['F_Score'] = pd.qcut(rfm_pandas['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')\n",
    "    rfm_pandas['M_Score'] = pd.qcut(rfm_pandas['Monetary_Value'], 5, labels=[1,2,3,4,5], duplicates='drop')\n",
    "    \n",
    "    # Handle any NaN values in scores\n",
    "    rfm_pandas['R_Score'] = rfm_pandas['R_Score'].fillna(3)\n",
    "    rfm_pandas['F_Score'] = rfm_pandas['F_Score'].fillna(3)\n",
    "    rfm_pandas['M_Score'] = rfm_pandas['M_Score'].fillna(3)\n",
    "    \n",
    "    # Create RFM segment string\n",
    "    rfm_pandas['RFM_Score'] = rfm_pandas['R_Score'].astype(str) + rfm_pandas['F_Score'].astype(str) + rfm_pandas['M_Score'].astype(str)\n",
    "    \n",
    "    print(f\" Advanced RFM analysis completed for {len(rfm_pandas):,} customers\")\n",
    "    \n",
    "    return rfm_pandas\n",
    "\n",
    "def create_customer_segments(rfm_data):\n",
    "    \"\"\"Create detailed customer segments based on RFM and behavioral data - OPTIMIZED\"\"\"\n",
    "    print(\" Creating detailed customer segments...\")\n",
    "    \n",
    "    # Convert R_Score, F_Score, M_Score to integers for faster operations\n",
    "    rfm_data['R_Score'] = rfm_data['R_Score'].astype(int)\n",
    "    rfm_data['F_Score'] = rfm_data['F_Score'].astype(int)\n",
    "    rfm_data['M_Score'] = rfm_data['M_Score'].astype(int)\n",
    "    \n",
    "    # Vectorized RFM segmentation using numpy conditions\n",
    "    conditions = [\n",
    "        # Champions: High value, frequent, recent\n",
    "        (rfm_data['R_Score'] >= 4) & (rfm_data['F_Score'] >= 4) & (rfm_data['M_Score'] >= 4),\n",
    "        \n",
    "        # Loyal Customers: High frequency, good monetary\n",
    "        (rfm_data['F_Score'] >= 4) & (rfm_data['M_Score'] >= 3),\n",
    "        \n",
    "        # Potential Loyalists: Recent customers with good frequency\n",
    "        (rfm_data['R_Score'] >= 3) & (rfm_data['F_Score'] >= 2) & (rfm_data['F_Score'] <= 3),\n",
    "        \n",
    "        # New Customers: Recent but low frequency\n",
    "        (rfm_data['R_Score'] >= 4) & (rfm_data['F_Score'] <= 2),\n",
    "        \n",
    "        # Promising: Recent customers with potential\n",
    "        (rfm_data['R_Score'] >= 3) & (rfm_data['F_Score'] <= 2) & (rfm_data['M_Score'] >= 2),\n",
    "        \n",
    "        # Need Attention: Above average recency, frequency & monetary\n",
    "        (rfm_data['R_Score'] >= 2) & (rfm_data['F_Score'] >= 2) & (rfm_data['M_Score'] >= 2),\n",
    "        \n",
    "        # About to Sleep: Below average recency but good frequency\n",
    "        (rfm_data['R_Score'] <= 2) & (rfm_data['F_Score'] >= 3),\n",
    "        \n",
    "        # At Risk: Good customers who haven't purchased recently\n",
    "        (rfm_data['R_Score'] <= 2) & (rfm_data['F_Score'] >= 2) & (rfm_data['M_Score'] >= 3),\n",
    "        \n",
    "        # Cannot Lose Them: High value but low recency and frequency\n",
    "        (rfm_data['F_Score'] >= 4) & (rfm_data['M_Score'] >= 4),\n",
    "        \n",
    "        # Hibernating: Low recency, frequency & monetary\n",
    "        (rfm_data['R_Score'] <= 2) & (rfm_data['F_Score'] <= 2) & (rfm_data['M_Score'] <= 2)\n",
    "    ]\n",
    "    \n",
    "    choices = [\n",
    "        \"Champions\", \"Loyal Customers\", \"Potential Loyalists\", \"New Customers\", \n",
    "        \"Promising\", \"Need Attention\", \"About to Sleep\", \"At Risk\", \n",
    "        \"Cannot Lose Them\", \"Hibernating\"\n",
    "    ]\n",
    "    \n",
    "   \n",
    "    rfm_data['Customer_Segment'] = np.select(conditions, choices, default=\"Lost\")\n",
    "    \n",
    "    # Vectorized behavioral segmentation\n",
    "    aov_threshold = rfm_data['Average_Order_Value'].quantile(0.75)\n",
    "    freq_threshold = rfm_data['Monthly_Purchase_Frequency'].quantile(0.75)\n",
    "    cat_threshold = rfm_data['Unique_Categories_Purchased'].quantile(0.75)\n",
    "    loyalty_threshold = rfm_data['Store_Loyalty_Score'].quantile(0.75)\n",
    "    \n",
    "    behavioral_conditions = [\n",
    "        (rfm_data['Average_Order_Value'] >= aov_threshold) & (rfm_data['Monthly_Purchase_Frequency'] >= freq_threshold),\n",
    "        (rfm_data['Average_Order_Value'] >= aov_threshold) & (rfm_data['Monthly_Purchase_Frequency'] < freq_threshold),\n",
    "        rfm_data['Monthly_Purchase_Frequency'] >= freq_threshold,\n",
    "        rfm_data['Unique_Categories_Purchased'] >= cat_threshold,\n",
    "        rfm_data['Store_Loyalty_Score'] >= loyalty_threshold\n",
    "    ]\n",
    "    \n",
    "    behavioral_choices = [\n",
    "        \"High Value Frequent\", \"High Value Occasional\", \"Frequent Shoppers\", \n",
    "        \"Category Explorers\", \"Store Loyalists\"\n",
    "    ]\n",
    "    \n",
    "    rfm_data['Behavioral_Segment'] = np.select(behavioral_conditions, behavioral_choices, default=\"Regular Customers\")\n",
    "    \n",
    "    # Vectorized value segmentation\n",
    "    high_value = rfm_data['Monetary_Value'].quantile(0.8)\n",
    "    medium_value = rfm_data['Monetary_Value'].quantile(0.5)\n",
    "    high_freq = rfm_data['Frequency'].quantile(0.7)\n",
    "    \n",
    "    value_conditions = [\n",
    "        (rfm_data['Monetary_Value'] >= high_value) & (rfm_data['Frequency'] >= high_freq),\n",
    "        (rfm_data['Monetary_Value'] >= high_value) & (rfm_data['Frequency'] < high_freq),\n",
    "        (rfm_data['Monetary_Value'] >= medium_value) & (rfm_data['Frequency'] >= high_freq),\n",
    "        (rfm_data['Monetary_Value'] >= medium_value) & (rfm_data['Frequency'] < high_freq),\n",
    "        (rfm_data['Monetary_Value'] < medium_value) & (rfm_data['Frequency'] >= high_freq)\n",
    "    ]\n",
    "    \n",
    "    value_choices = [\n",
    "        \"VIP Customers\", \"Big Spenders\", \"Loyal Regulars\", \n",
    "        \"Medium Value\", \"Frequent Low Spenders\"\n",
    "    ]\n",
    "    \n",
    "    rfm_data['Value_Segment'] = np.select(value_conditions, value_choices, default=\"Low Value\")\n",
    "    \n",
    "    print(f\" Customer segmentation completed\")\n",
    "    print(f\" RFM Segments: {rfm_data['Customer_Segment'].nunique()}\")\n",
    "    print(f\" Behavioral Segments: {rfm_data['Behavioral_Segment'].nunique()}\")\n",
    "    print(f\" Value Segments: {rfm_data['Value_Segment'].nunique()}\")\n",
    "    \n",
    "    return rfm_data\n",
    "\n",
    "\n",
    "def calculate_customer_lifetime_value(rfm_data):\n",
    "    \"\"\"Calculate Customer Lifetime Value (CLV) using computational methods\"\"\"\n",
    "    print(\" Calculating Customer Lifetime Value...\")\n",
    "    \n",
    "    # Historical CLV (what customer has already spent)\n",
    "    rfm_data['Historical_CLV'] = rfm_data['Monetary_Value']\n",
    "    \n",
    "    # Predicted CLV based on purchase patterns\n",
    "    # Method 1: Simple frequency-based prediction\n",
    "    rfm_data['Avg_Days_Between_Purchases'] = rfm_data['Customer_Lifetime_Days'] / (rfm_data['Frequency'] - 1)\n",
    "    rfm_data['Avg_Days_Between_Purchases'] = rfm_data['Avg_Days_Between_Purchases'].fillna(rfm_data['Customer_Lifetime_Days'])\n",
    "    \n",
    "    # Estimate future purchases in next 12 months\n",
    "    rfm_data['Estimated_Future_Purchases'] = np.where(\n",
    "        rfm_data['Avg_Days_Between_Purchases'] > 0,\n",
    "        365 / rfm_data['Avg_Days_Between_Purchases'],\n",
    "        rfm_data['Monthly_Purchase_Frequency'] * 12\n",
    "    )\n",
    "    \n",
    "    # Predicted CLV (conservative estimate)\n",
    "    rfm_data['Predicted_CLV'] = rfm_data['Average_Order_Value'] * rfm_data['Estimated_Future_Purchases']\n",
    "    \n",
    "    # Total CLV (Historical + Predicted)\n",
    "    rfm_data['Total_CLV'] = rfm_data['Historical_CLV'] + rfm_data['Predicted_CLV']\n",
    "    \n",
    "    # CLV segments based on total CLV\n",
    "    rfm_data['CLV_Segment'] = pd.qcut(\n",
    "        rfm_data['Total_CLV'], \n",
    "        q=5, \n",
    "        labels=['Very Low CLV', 'Low CLV', 'Medium CLV', 'High CLV', 'Very High CLV'],\n",
    "        duplicates='drop'\n",
    "    )\n",
    "    \n",
    "    # Customer risk assessment based on recency and frequency trends\n",
    "    def risk_assessment(row):\n",
    "        recency = row['Recency_Days']\n",
    "        avg_gap = row['Avg_Days_Between_Purchases']\n",
    "        \n",
    "        if recency > avg_gap * 2:\n",
    "            return \"High Risk\"\n",
    "        elif recency > avg_gap * 1.5:\n",
    "            return \"Medium Risk\"\n",
    "        else:\n",
    "            return \"Low Risk\"\n",
    "    \n",
    "    rfm_data['Churn_Risk'] = rfm_data.apply(risk_assessment, axis=1)\n",
    "    \n",
    "    print(\" CLV calculation completed\")\n",
    "    \n",
    "    return rfm_data\n",
    "\n",
    "def create_cohort_analysis(master_data):\n",
    "    \"\"\"Create customer cohort analysis\"\"\"\n",
    "    print(\" Creating cohort analysis...\")\n",
    "    \n",
    "    # Filter for sales only\n",
    "    sales_data = master_data.filter(pl.col(\"Transaction Type\") == \"Sale\")\n",
    "    \n",
    "    # Convert to pandas for cohort analysis\n",
    "    df = sales_data.select([\n",
    "        \"Customer ID\", \"Date\", \"Line_Total_USD\"\n",
    "    ]).to_pandas()\n",
    "    \n",
    "    # Get customer's first purchase date\n",
    "    df['Order_Period'] = df['Date'].dt.to_period('M')\n",
    "    df['Cohort_Group'] = df.groupby('Customer ID')['Date'].transform('min').dt.to_period('M')\n",
    "    \n",
    "    # Calculate period number\n",
    "    df['Period_Number'] = (df['Order_Period'] - df['Cohort_Group']).apply(attrgetter('n'))\n",
    "    \n",
    "    # Create cohort table for customer retention\n",
    "    cohort_data = df.groupby(['Cohort_Group', 'Period_Number'])['Customer ID'].nunique().reset_index()\n",
    "    cohort_counts = cohort_data.pivot(index='Cohort_Group', columns='Period_Number', values='Customer ID')\n",
    "    \n",
    "    # Calculate cohort sizes (first month customers)\n",
    "    cohort_sizes = df.groupby('Cohort_Group')['Customer ID'].nunique()\n",
    "    cohort_table = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "    \n",
    "    # Revenue cohort analysis\n",
    "    revenue_cohort_data = df.groupby(['Cohort_Group', 'Period_Number'])['Line_Total_USD'].sum().reset_index()\n",
    "    revenue_cohort_table = revenue_cohort_data.pivot(index='Cohort_Group', columns='Period_Number', values='Line_Total_USD')\n",
    "    \n",
    "    print(\" Cohort analysis completed\")\n",
    "    \n",
    "    return cohort_table, cohort_counts, revenue_cohort_table\n",
    "\n",
    "def analyze_customer_journey(master_data):\n",
    "    \"\"\"Analyze customer journey and purchase patterns\"\"\"\n",
    "    print(\" Analyzing customer journey patterns...\")\n",
    "    \n",
    "    # Filter for sales only\n",
    "    sales_data = master_data.filter(pl.col(\"Transaction Type\") == \"Sale\")\n",
    "    \n",
    "    # Customer journey metrics\n",
    "    journey_analysis = sales_data.group_by(\"Customer ID\").agg([\n",
    "        pl.col(\"Date\").min().alias(\"First_Purchase\"),\n",
    "        pl.col(\"Date\").max().alias(\"Last_Purchase\"),\n",
    "        pl.col(\"Invoice ID\").n_unique().alias(\"Total_Transactions\"),\n",
    "        pl.col(\"Line_Total_USD\").sum().alias(\"Total_Spent\"),\n",
    "        pl.col(\"Store ID\").n_unique().alias(\"Stores_Visited\"),\n",
    "        pl.col(\"Category\").n_unique().alias(\"Categories_Explored\"),\n",
    "        \n",
    "        # Purchase evolution\n",
    "        pl.col(\"Line_Total_USD\").first().alias(\"First_Purchase_Amount\"),\n",
    "        pl.col(\"Line_Total_USD\").last().alias(\"Last_Purchase_Amount\"),\n",
    "        pl.col(\"Line_Total_USD\").mean().alias(\"Average_Purchase_Amount\"),\n",
    "        pl.col(\"Line_Total_USD\").max().alias(\"Highest_Purchase_Amount\")\n",
    "    ]).to_pandas()\n",
    "    \n",
    "    # Calculate journey metrics\n",
    "    journey_analysis['Customer_Lifespan_Days'] = (journey_analysis['Last_Purchase'] - journey_analysis['First_Purchase']).dt.days\n",
    "    journey_analysis['Purchase_Growth'] = ((journey_analysis['Last_Purchase_Amount'] - journey_analysis['First_Purchase_Amount']) / \n",
    "                                         journey_analysis['First_Purchase_Amount'] * 100).fillna(0)\n",
    "    \n",
    "    # Journey stages\n",
    "    def journey_stage(row):\n",
    "        transactions = row['Total_Transactions']\n",
    "        lifespan = row['Customer_Lifespan_Days']\n",
    "        \n",
    "        if transactions == 1:\n",
    "            return \"One-Time Buyer\"\n",
    "        elif transactions <= 3 and lifespan <= 90:\n",
    "            return \"Early Stage\"\n",
    "        elif transactions <= 5 and lifespan <= 180:\n",
    "            return \"Developing\"\n",
    "        elif transactions <= 10:\n",
    "            return \"Established\"\n",
    "        else:\n",
    "            return \"Mature\"\n",
    "    \n",
    "    journey_analysis['Journey_Stage'] = journey_analysis.apply(journey_stage, axis=1)\n",
    "    \n",
    "    print(\" Customer journey analysis completed\")\n",
    "    \n",
    "    return journey_analysis\n",
    "\n",
    "def create_customer_segmentation_dashboard(rfm_data, cohort_table, revenue_cohort_table, journey_analysis):\n",
    "    \"\"\"Create comprehensive customer segmentation dashboard\"\"\"\n",
    "    print(\" Creating Customer Segmentation Dashboard...\")\n",
    "    \n",
    "    # Create HTML structure\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Advanced Customer Segmentation Analysis Dashboard</title>\n",
    "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }\n",
    "            .chart-container { background-color: white; margin: 20px 0; padding: 20px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }\n",
    "            .chart-title { font-size: 24px; font-weight: bold; text-align: center; margin-bottom: 20px; color: #333; }\n",
    "            .dashboard-title { font-size: 36px; font-weight: bold; text-align: center; margin-bottom: 30px; color: #2c3e50; }\n",
    "            .insights-box { background-color: #e8f4f8; padding: 15px; margin: 10px 0; border-radius: 8px; font-size: 14px; }\n",
    "            .metric-highlight { background-color: #fff3cd; padding: 10px; margin: 5px 0; border-radius: 5px; font-weight: bold; }\n",
    "            .segment-summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }\n",
    "            .segment-card { background-color: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #007bff; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"dashboard-title\"> Advanced Customer Segmentation Analysis</div>\n",
    "        \n",
    "        <div class=\"insights-box\">\n",
    "            <strong> Customer Segmentation Insights:</strong><br>\n",
    "            â€¢ <strong>RFM Analysis</strong>: Segments customers based on Recency, Frequency, and Monetary value<br>\n",
    "            â€¢ <strong>Behavioral Segmentation</strong>: Groups customers by shopping patterns and preferences<br>\n",
    "            â€¢ <strong>Customer Lifetime Value</strong>: Predicts future value and identifies high-value customers<br>\n",
    "            â€¢ <strong>Cohort Analysis</strong>: Tracks customer retention and revenue patterns over time<br>\n",
    "            â€¢ <strong>Journey Analysis</strong>: Maps customer evolution and purchase progression\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. RFM Analysis 3D Scatter Plot\n",
    "    fig1 = px.scatter_3d(\n",
    "        rfm_data,\n",
    "        x='Recency_Days',\n",
    "        y='Frequency', \n",
    "        z='Monetary_Value',\n",
    "        color='Customer_Segment',\n",
    "        size='Total_CLV',\n",
    "        hover_name='Customer ID',\n",
    "        hover_data={\n",
    "            'Average_Order_Value': ':.2f',\n",
    "            'Total_Items_Purchased': ':,',\n",
    "            'Stores_Visited': True,\n",
    "            'CLV_Segment': True\n",
    "        },\n",
    "        title=\" 3D RFM Analysis: Customer Segmentation\",\n",
    "        labels={\n",
    "            'Recency_Days': 'Recency (Days)',\n",
    "            'Frequency': 'Purchase Frequency',\n",
    "            'Monetary_Value': 'Total Spent (USD)'\n",
    "        },\n",
    "        height=700\n",
    "    )\n",
    "    fig1.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 2. Customer Segment Distribution\n",
    "    segment_counts = rfm_data['Customer_Segment'].value_counts()\n",
    "    fig2 = px.pie(\n",
    "        values=segment_counts.values,\n",
    "        names=segment_counts.index,\n",
    "        title=\" Customer Segment Distribution\",\n",
    "        height=600\n",
    "    )\n",
    "    fig2.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    fig2.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 3. CLV Analysis by Segment\n",
    "    clv_by_segment = rfm_data.groupby('Customer_Segment').agg({\n",
    "        'Total_CLV': ['mean', 'sum', 'count'],\n",
    "        'Historical_CLV': 'mean',\n",
    "        'Predicted_CLV': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    fig3 = px.bar(\n",
    "        x=clv_by_segment.index,\n",
    "        y=clv_by_segment[('Total_CLV', 'mean')],\n",
    "        title=\" Average Customer Lifetime Value by Segment\",\n",
    "        labels={'x': 'Customer Segment', 'y': 'Average CLV (USD)'},\n",
    "        height=600\n",
    "    )\n",
    "    fig3.update_layout(template=\"plotly_white\", xaxis_tickangle=45)\n",
    "    \n",
    "    # 4. Behavioral Segmentation\n",
    "    behavioral_counts = rfm_data['Behavioral_Segment'].value_counts()\n",
    "    fig4 = px.bar(\n",
    "        x=behavioral_counts.index,\n",
    "        y=behavioral_counts.values,\n",
    "        title=\" Behavioral Segmentation Distribution\",\n",
    "        labels={'x': 'Behavioral Segment', 'y': 'Number of Customers'},\n",
    "        height=600\n",
    "    )\n",
    "    fig4.update_layout(template=\"plotly_white\", xaxis_tickangle=45)\n",
    "    \n",
    "    # 5. Customer Journey Stage Analysis\n",
    "    journey_counts = journey_analysis['Journey_Stage'].value_counts()\n",
    "    fig5 = px.funnel(\n",
    "        x=journey_counts.values,\n",
    "        y=journey_counts.index,\n",
    "        title=\" Customer Journey Stage Distribution\",\n",
    "        height=600\n",
    "    )\n",
    "    fig5.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 6. Cohort Retention Heatmap\n",
    "    fig6 = px.imshow(\n",
    "        cohort_table.iloc[:12, :12].values,  # Show first 12 months of first 12 cohorts\n",
    "        labels=dict(x=\"Period\", y=\"Cohort Month\", color=\"Retention Rate\"),\n",
    "        x=[f\"Month {i}\" for i in range(12)],\n",
    "        y=[str(cohort)[:7] for cohort in cohort_table.index[:12]],\n",
    "        title=\" Customer Retention Cohort Analysis\",\n",
    "        color_continuous_scale=\"RdYlGn\",\n",
    "        height=600\n",
    "    )\n",
    "    fig6.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 7. Revenue Cohort Analysis\n",
    "    fig7 = px.imshow(\n",
    "        revenue_cohort_table.iloc[:12, :12].fillna(0).values,\n",
    "        labels=dict(x=\"Period\", y=\"Cohort Month\", color=\"Revenue (USD)\"),\n",
    "        x=[f\"Month {i}\" for i in range(12)],\n",
    "        y=[str(cohort)[:7] for cohort in revenue_cohort_table.index[:12]],\n",
    "        title=\" Revenue Cohort Analysis\",\n",
    "        color_continuous_scale=\"Blues\",\n",
    "        height=600\n",
    "    )\n",
    "    fig7.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 8. Customer Value vs Risk Matrix\n",
    "    fig8 = px.scatter(\n",
    "        rfm_data,\n",
    "        x='Total_CLV',\n",
    "        y='Recency_Days',\n",
    "        color='Churn_Risk',\n",
    "        size='Frequency',\n",
    "        hover_name='Customer ID',\n",
    "        hover_data={\n",
    "            'Customer_Segment': True,\n",
    "            'Average_Order_Value': ':.2f',\n",
    "            'Monthly_Purchase_Frequency': ':.2f'\n",
    "        },\n",
    "        title=\" Customer Value vs Churn Risk Matrix\",\n",
    "        labels={\n",
    "            'Total_CLV': 'Customer Lifetime Value (USD)',\n",
    "            'Recency_Days': 'Days Since Last Purchase'\n",
    "        },\n",
    "        height=700\n",
    "    )\n",
    "    fig8.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 9. Purchase Behavior Analysis\n",
    "    fig9 = px.scatter(\n",
    "        rfm_data,\n",
    "        x='Average_Order_Value',\n",
    "        y='Monthly_Purchase_Frequency',\n",
    "        color='Value_Segment',\n",
    "        size='Total_Items_Purchased',\n",
    "        hover_name='Customer ID',\n",
    "        title=\" Purchase Behavior Analysis\",\n",
    "        labels={\n",
    "            'Average_Order_Value': 'Average Order Value (USD)',\n",
    "            'Monthly_Purchase_Frequency': 'Monthly Purchase Frequency'\n",
    "        },\n",
    "        height=600\n",
    "    )\n",
    "    fig9.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # 10. Customer Loyalty Analysis\n",
    "    fig10 = px.scatter(\n",
    "        rfm_data,\n",
    "        x='Store_Loyalty_Score',\n",
    "        y='Product_Diversity_Score',\n",
    "        color='Behavioral_Segment',\n",
    "        size='Monetary_Value',\n",
    "        hover_name='Customer ID',\n",
    "        title=\" Customer Loyalty vs Product Diversity\",\n",
    "        labels={\n",
    "            'Store_Loyalty_Score': 'Store Loyalty Score',\n",
    "            'Product_Diversity_Score': 'Product Diversity Score'\n",
    "        },\n",
    "        height=600\n",
    "    )\n",
    "    fig10.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # Convert all figures to HTML\n",
    "    figures = [fig1, fig2, fig3, fig4, fig5, fig6, fig7, fig8, fig9, fig10]\n",
    "    titles = [\n",
    "        \"3D RFM Analysis: Customer Segmentation\",\n",
    "        \"Customer Segment Distribution\", \n",
    "        \"Average Customer Lifetime Value by Segment\",\n",
    "        \"Behavioral Segmentation Distribution\",\n",
    "        \"Customer Journey Stage Distribution\",\n",
    "        \"Customer Retention Cohort Analysis\",\n",
    "        \"Revenue Cohort Analysis\",\n",
    "        \"Customer Value vs Churn Risk Matrix\",\n",
    "        \"Purchase Behavior Analysis\",\n",
    "        \"Customer Loyalty vs Product Diversity\"\n",
    "    ]\n",
    "    \n",
    "    for i, (fig, title) in enumerate(zip(figures, titles)):\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"chart-container\">\n",
    "            <div class=\"chart-title\">{title}</div>\n",
    "            <div id=\"chart{i+1}\"></div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Add segment summary cards\n",
    "    segment_summary = rfm_data.groupby('Customer_Segment').agg({\n",
    "        'Customer ID': 'count',\n",
    "        'Total_CLV': 'mean',\n",
    "        'Average_Order_Value': 'mean',\n",
    "        'Monthly_Purchase_Frequency': 'mean',\n",
    "        'Recency_Days': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        <div class=\"chart-container\">\n",
    "            <div class=\"chart-title\"> Customer Segment Summary</div>\n",
    "            <div class=\"segment-summary\">\n",
    "    \"\"\"\n",
    "    \n",
    "    for segment in segment_summary.index:\n",
    "        data = segment_summary.loc[segment]\n",
    "        html_content += f\"\"\"\n",
    "            <div class=\"segment-card\">\n",
    "                <h3>{segment}</h3>\n",
    "                <p><strong>Customers:</strong> {data['Customer ID']:,}</p>\n",
    "                <p><strong>Avg CLV:</strong> ${data['Total_CLV']:,.2f}</p>\n",
    "                <p><strong>Avg Order Value:</strong> ${data['Average_Order_Value']:,.2f}</p>\n",
    "                <p><strong>Monthly Frequency:</strong> {data['Monthly_Purchase_Frequency']:.2f}</p>\n",
    "                <p><strong>Avg Recency:</strong> {data['Recency_Days']:.0f} days</p>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add key insights\n",
    "    total_customers = len(rfm_data)\n",
    "    total_clv = rfm_data['Total_CLV'].sum()\n",
    "    avg_clv = rfm_data['Total_CLV'].mean()\n",
    "    champions = len(rfm_data[rfm_data['Customer_Segment'] == 'Champions'])\n",
    "    at_risk = len(rfm_data[rfm_data['Customer_Segment'] == 'At Risk'])\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "        <div class=\"insights-box\">\n",
    "            <strong> Key Customer Insights:</strong><br>\n",
    "            <div class=\"metric-highlight\"> Total Customers Analyzed: {total_customers:,}</div>\n",
    "            <div class=\"metric-highlight\"> Total Customer Lifetime Value: ${total_clv:,.0f}</div>\n",
    "            <div class=\"metric-highlight\"> Average CLV per Customer: ${avg_clv:,.2f}</div>\n",
    "            <div class=\"metric-highlight\"> Champion Customers: {champions:,} ({champions/total_customers*100:.1f}%)</div>\n",
    "            <div class=\"metric-highlight\"> At-Risk Customers: {at_risk:,} ({at_risk/total_customers*100:.1f}%)</div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "    <script>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add JavaScript for each plot\n",
    "    for i, fig in enumerate(figures):\n",
    "        plot_json = fig.to_json()\n",
    "        html_content += f\"\"\"\n",
    "        var plotData{i+1} = {plot_json};\n",
    "        Plotly.newPlot('chart{i+1}',\n",
    "        plotData{i+1}.data, plotData{i+1}.layout, {{responsive: true}});\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "    </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec86085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initializing Advanced Customer Segmentation Analysis...\n",
      " Starting Advanced Customer Segmentation Analysis...\n",
      " Loading master data for customer segmentation analysis...\n",
      " Master data loaded: (6416827, 45)\n",
      "\n",
      " Step 1: Calculating RFM Analysis...\n",
      "Calculating Advanced RFM Analysis...\n",
      "Analysis reference date: 2025-03-18\n",
      " Advanced RFM analysis completed for 1,283,707 customers\n",
      "\n",
      " Step 2: Creating Customer Segments...\n",
      " Creating detailed customer segments...\n",
      " Customer segmentation completed\n",
      " RFM Segments: 10\n",
      " Behavioral Segments: 6\n",
      " Value Segments: 6\n",
      "\n",
      " Step 3: Calculating Customer Lifetime Value...\n",
      " Calculating Customer Lifetime Value...\n",
      " CLV calculation completed\n",
      "\n",
      " Step 4: Performing Cohort Analysis...\n",
      " Creating cohort analysis...\n",
      " Cohort analysis completed\n",
      "\n",
      " Step 5: Analyzing Customer Journey...\n",
      " Analyzing customer journey patterns...\n",
      " Customer journey analysis completed\n",
      "\n",
      " Step 6: Generating Insights and Recommendations...\n",
      " Generating customer insights and recommendations...\n",
      "\n",
      " Step 7: Saving Analysis Data...\n",
      " Saving customer segmentation analysis data files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alan\\AppData\\Local\\Temp\\ipykernel_15572\\892873010.py:38: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Customer segmentation data files saved!\n",
      "\n",
      " Step 8: Creating Interactive Dashboard...\n",
      " Creating Customer Segmentation Dashboard...\n",
      "\n",
      "================================================================================\n",
      " CUSTOMER SEGMENTATION ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      " CUSTOMER OVERVIEW:\n",
      "    Total Customers Analyzed: 1,283,707\n",
      "    Total Revenue: $305,884,836.55\n",
      "    Average CLV: $410.86\n",
      "    Average Order Value: $50.16\n",
      "\n",
      " SEGMENT DISTRIBUTION:\n",
      "   â€¢ Potential Loyalists: 268,853 customers (20.9%)\n",
      "   â€¢ Champions: 250,529 customers (19.5%)\n",
      "   â€¢ Loyal Customers: 241,444 customers (18.8%)\n",
      "   â€¢ Hibernating: 229,119 customers (17.8%)\n",
      "   â€¢ Need Attention: 126,175 customers (9.8%)\n",
      "\n",
      " HIGH-VALUE CUSTOMERS:\n",
      "    Champions: 250,529 customers\n",
      "  Champions Revenue: $126,578,308.19\n",
      "   Champions CLV: $696.86\n",
      "\n",
      " AT-RISK CUSTOMERS:\n",
      "    High Risk: 203,138 customers (15.8%)\n",
      "    Potential Revenue Loss: $123,512,118.84\n",
      "\n",
      " BEHAVIORAL INSIGHTS:\n",
      "  Multi-Category Shoppers: 0.0%\n",
      "  Store Loyalists: 75.5%\n",
      "  Frequent Shoppers: 28.3%\n",
      "\n",
      " FILES CREATED:\n",
      "   customer_segmentation/customer_segmentation_dashboard.html\n",
      "   customer_segmentation/data/ (Multiple CSV files)\n",
      "  Segment-specific customer lists\n",
      "   Summary reports and analysis\n",
      "\n",
      " TOP RECOMMENDATIONS:\n",
      "   1. Focus retention efforts on 250,529 Champion customers\n",
      "   2. Immediate re-engagement for 203,138 at-risk customers\n",
      "   3. Develop loyalty programs for Potential Loyalists\n",
      "   4. Create win-back campaigns for hibernating customers\n",
      "\n",
      " Analysis completed successfully!\n",
      "Open the dashboard to explore detailed customer insights and segments\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_customer_segmentation_data(rfm_data, cohort_table, revenue_cohort_table, journey_analysis):\n",
    "    \"\"\"Save customer segmentation analysis data files\"\"\"\n",
    "    print(\" Saving customer segmentation analysis data files...\")\n",
    "    \n",
    "    os.makedirs(\"customer_segmentation/data\", exist_ok=True)\n",
    "    \n",
    "    # Save main datasets\n",
    "    rfm_data.to_csv(\"customer_segmentation/data/rfm_customer_analysis.csv\", index=False)\n",
    "    cohort_table.to_csv(\"customer_segmentation/data/customer_retention_cohorts.csv\")\n",
    "    revenue_cohort_table.to_csv(\"customer_segmentation/data/revenue_cohorts.csv\")\n",
    "    journey_analysis.to_csv(\"customer_segmentation/data/customer_journey_analysis.csv\", index=False)\n",
    "    \n",
    "    # Create segment-specific files\n",
    "    for segment in rfm_data['Customer_Segment'].unique():\n",
    "        segment_data = rfm_data[rfm_data['Customer_Segment'] == segment]\n",
    "        filename = f\"customer_segmentation/data/segment_{segment.lower().replace(' ', '_')}.csv\"\n",
    "        segment_data.to_csv(filename, index=False)\n",
    "    \n",
    "    # Create summary reports\n",
    "    segment_summary = rfm_data.groupby('Customer_Segment').agg({\n",
    "        'Customer ID': 'count',\n",
    "        'Total_CLV': ['mean', 'sum', 'std'],\n",
    "        'Historical_CLV': 'mean',\n",
    "        'Predicted_CLV': 'mean',\n",
    "        'Average_Order_Value': 'mean',\n",
    "        'Monthly_Purchase_Frequency': 'mean',\n",
    "        'Recency_Days': 'mean',\n",
    "        'Frequency': 'mean',\n",
    "        'Monetary_Value': 'mean',\n",
    "        'Total_Items_Purchased': 'mean',\n",
    "        'Unique_Products_Purchased': 'mean',\n",
    "        'Stores_Visited': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    segment_summary.to_csv(\"customer_segmentation/data/segment_summary_report.csv\")\n",
    "    \n",
    "    # CLV analysis by segment\n",
    "    clv_analysis = rfm_data.groupby(['Customer_Segment', 'CLV_Segment']).size().unstack(fill_value=0)\n",
    "    clv_analysis.to_csv(\"customer_segmentation/data/clv_by_segment_analysis.csv\")\n",
    "    \n",
    "    # Risk analysis\n",
    "    risk_analysis = rfm_data.groupby(['Customer_Segment', 'Churn_Risk']).size().unstack(fill_value=0)\n",
    "    risk_analysis.to_csv(\"customer_segmentation/data/churn_risk_by_segment.csv\")\n",
    "    \n",
    "    print(\" Customer segmentation data files saved!\")\n",
    "\n",
    "def generate_customer_insights_report(rfm_data, journey_analysis):\n",
    "    \"\"\"Generate detailed customer insights and recommendations\"\"\"\n",
    "    print(\" Generating customer insights and recommendations...\")\n",
    "    \n",
    "    insights = {\n",
    "        'segment_insights': {},\n",
    "        'clv_insights': {},\n",
    "        'risk_insights': {},\n",
    "        'behavioral_insights': {},\n",
    "        'recommendations': {}\n",
    "    }\n",
    "    \n",
    "    # Segment-specific insights\n",
    "    for segment in rfm_data['Customer_Segment'].unique():\n",
    "        segment_data = rfm_data[rfm_data['Customer_Segment'] == segment]\n",
    "        \n",
    "        insights['segment_insights'][segment] = {\n",
    "            'count': len(segment_data),\n",
    "            'percentage': len(segment_data) / len(rfm_data) * 100,\n",
    "            'avg_clv': segment_data['Total_CLV'].mean(),\n",
    "            'avg_aov': segment_data['Average_Order_Value'].mean(),\n",
    "            'avg_frequency': segment_data['Monthly_Purchase_Frequency'].mean(),\n",
    "            'avg_recency': segment_data['Recency_Days'].mean(),\n",
    "            'revenue_contribution': segment_data['Monetary_Value'].sum() / rfm_data['Monetary_Value'].sum() * 100\n",
    "        }\n",
    "    \n",
    "    # CLV insights\n",
    "    high_clv_customers = rfm_data[rfm_data['CLV_Segment'].isin(['High CLV', 'Very High CLV'])]\n",
    "    insights['clv_insights'] = {\n",
    "        'high_clv_count': len(high_clv_customers),\n",
    "        'high_clv_percentage': len(high_clv_customers) / len(rfm_data) * 100,\n",
    "        'high_clv_revenue_share': high_clv_customers['Monetary_Value'].sum() / rfm_data['Monetary_Value'].sum() * 100,\n",
    "        'avg_clv_all': rfm_data['Total_CLV'].mean(),\n",
    "        'top_10_percent_clv': rfm_data.nlargest(int(len(rfm_data) * 0.1), 'Total_CLV')['Total_CLV'].mean()\n",
    "    }\n",
    "    \n",
    "    # Risk insights\n",
    "    at_risk_customers = rfm_data[rfm_data['Churn_Risk'] == 'High Risk']\n",
    "    insights['risk_insights'] = {\n",
    "        'high_risk_count': len(at_risk_customers),\n",
    "        'high_risk_percentage': len(at_risk_customers) / len(rfm_data) * 100,\n",
    "        'potential_revenue_loss': at_risk_customers['Predicted_CLV'].sum(),\n",
    "        'avg_recency_at_risk': at_risk_customers['Recency_Days'].mean()\n",
    "    }\n",
    "    \n",
    "    # Behavioral insights\n",
    "    insights['behavioral_insights'] = {\n",
    "        'multi_category_shoppers': len(rfm_data[rfm_data['Unique_Categories_Purchased'] > 3]) / len(rfm_data) * 100,\n",
    "        'store_loyalists': len(rfm_data[rfm_data['Stores_Visited'] == 1]) / len(rfm_data) * 100,\n",
    "        'frequent_shoppers': len(rfm_data[rfm_data['Monthly_Purchase_Frequency'] > 2]) / len(rfm_data) * 100,\n",
    "        'high_aov_customers': len(rfm_data[rfm_data['Average_Order_Value'] > rfm_data['Average_Order_Value'].quantile(0.8)]) / len(rfm_data) * 100\n",
    "    }\n",
    "    \n",
    "    # Generate recommendations\n",
    "    insights['recommendations'] = {\n",
    "        'champions': \"Focus on retention programs, VIP experiences, and referral incentives\",\n",
    "        'loyal_customers': \"Reward loyalty with exclusive offers and early access to new products\",\n",
    "        'potential_loyalists': \"Nurture with personalized recommendations and loyalty programs\",\n",
    "        'new_customers': \"Onboard with welcome series and product education\",\n",
    "        'at_risk': \"Immediate re-engagement campaigns with special offers\",\n",
    "        'cannot_lose_them': \"Win-back campaigns with premium service recovery\",\n",
    "        'hibernating': \"Reactivation campaigns with significant incentives\",\n",
    "        'lost': \"Final win-back attempt or remove from active marketing\"\n",
    "    }\n",
    "    \n",
    "    return insights\n",
    "\n",
    "def run_customer_segmentation_analysis():\n",
    "    \"\"\"Run comprehensive customer segmentation analysis\"\"\"\n",
    "    print(\" Starting Advanced Customer Segmentation Analysis...\")\n",
    "    \n",
    "    # Load data\n",
    "    master_data = load_master_data_for_customer_segmentation()\n",
    "    if master_data is None:\n",
    "        print(\" Failed to load master data!\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate RFM analysis\n",
    "    print(\"\\n Step 1: Calculating RFM Analysis...\")\n",
    "    rfm_data = calculate_advanced_rfm_analysis(master_data)\n",
    "    \n",
    "    # Create customer segments\n",
    "    print(\"\\n Step 2: Creating Customer Segments...\")\n",
    "    rfm_data = create_customer_segments(rfm_data)\n",
    "    \n",
    "    # Calculate CLV\n",
    "    print(\"\\n Step 3: Calculating Customer Lifetime Value...\")\n",
    "    rfm_data = calculate_customer_lifetime_value(rfm_data)\n",
    "    \n",
    "    # Cohort analysis\n",
    "    print(\"\\n Step 4: Performing Cohort Analysis...\")\n",
    "    cohort_table, cohort_counts, revenue_cohort_table = create_cohort_analysis(master_data)\n",
    "    \n",
    "    # Customer journey analysis\n",
    "    print(\"\\n Step 5: Analyzing Customer Journey...\")\n",
    "    journey_analysis = analyze_customer_journey(master_data)\n",
    "    \n",
    "    # Generate insights\n",
    "    print(\"\\n Step 6: Generating Insights and Recommendations...\")\n",
    "    insights = generate_customer_insights_report(rfm_data, journey_analysis)\n",
    "    \n",
    "    # Save data files\n",
    "    print(\"\\n Step 7: Saving Analysis Data...\")\n",
    "    save_customer_segmentation_data(rfm_data, cohort_table, revenue_cohort_table, journey_analysis)\n",
    "    \n",
    "    # Create dashboard\n",
    "    print(\"\\n Step 8: Creating Interactive Dashboard...\")\n",
    "    html_content = create_customer_segmentation_dashboard(rfm_data, cohort_table, revenue_cohort_table, journey_analysis)\n",
    "    \n",
    "    # Create directory and save HTML\n",
    "    os.makedirs(\"customer_segmentation\", exist_ok=True)\n",
    "    \n",
    "    with open(\"customer_segmentation/customer_segmentation_dashboard.html\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" CUSTOMER SEGMENTATION ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n CUSTOMER OVERVIEW:\")\n",
    "    print(f\"    Total Customers Analyzed: {len(rfm_data):,}\")\n",
    "    print(f\"    Total Revenue: ${rfm_data['Monetary_Value'].sum():,.2f}\")\n",
    "    print(f\"    Average CLV: ${rfm_data['Total_CLV'].mean():,.2f}\")\n",
    "    print(f\"    Average Order Value: ${rfm_data['Average_Order_Value'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\n SEGMENT DISTRIBUTION:\")\n",
    "    segment_dist = rfm_data['Customer_Segment'].value_counts()\n",
    "    for segment, count in segment_dist.head(5).items():\n",
    "        percentage = count / len(rfm_data) * 100\n",
    "        print(f\"   â€¢ {segment}: {count:,} customers ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n HIGH-VALUE CUSTOMERS:\")\n",
    "    champions = rfm_data[rfm_data['Customer_Segment'] == 'Champions']\n",
    "    print(f\"    Champions: {len(champions):,} customers\")\n",
    "    print(f\"  Champions Revenue: ${champions['Monetary_Value'].sum():,.2f}\")\n",
    "    print(f\"   Champions CLV: ${champions['Total_CLV'].mean():,.2f}\")\n",
    "    \n",
    "    print(f\"\\n AT-RISK CUSTOMERS:\")\n",
    "    at_risk = rfm_data[rfm_data['Churn_Risk'] == 'High Risk']\n",
    "    print(f\"    High Risk: {len(at_risk):,} customers ({len(at_risk)/len(rfm_data)*100:.1f}%)\")\n",
    "    print(f\"    Potential Revenue Loss: ${at_risk['Predicted_CLV'].sum():,.2f}\")\n",
    "    \n",
    "    print(f\"\\n BEHAVIORAL INSIGHTS:\")\n",
    "    print(f\"  Multi-Category Shoppers: {insights['behavioral_insights']['multi_category_shoppers']:.1f}%\")\n",
    "    print(f\"  Store Loyalists: {insights['behavioral_insights']['store_loyalists']:.1f}%\")\n",
    "    print(f\"  Frequent Shoppers: {insights['behavioral_insights']['frequent_shoppers']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n FILES CREATED:\")\n",
    "    print(f\"   customer_segmentation/customer_segmentation_dashboard.html\")\n",
    "    print(f\"   customer_segmentation/data/ (Multiple CSV files)\")\n",
    "    print(f\"  Segment-specific customer lists\")\n",
    "    print(f\"   Summary reports and analysis\")\n",
    "    \n",
    "    print(f\"\\n TOP RECOMMENDATIONS:\")\n",
    "    print(f\"   1. Focus retention efforts on {len(champions):,} Champion customers\")\n",
    "    print(f\"   2. Immediate re-engagement for {len(at_risk):,} at-risk customers\")\n",
    "    print(f\"   3. Develop loyalty programs for Potential Loyalists\")\n",
    "    print(f\"   4. Create win-back campaigns for hibernating customers\")\n",
    "    \n",
    "    return {\n",
    "        'rfm_data': rfm_data,\n",
    "        'cohort_table': cohort_table,\n",
    "        'revenue_cohort_table': revenue_cohort_table,\n",
    "        'journey_analysis': journey_analysis,\n",
    "        'insights': insights\n",
    "    }\n",
    "\n",
    "# Run the customer segmentation analysis\n",
    "print(\" Initializing Advanced Customer Segmentation Analysis...\")\n",
    "results = run_customer_segmentation_analysis()\n",
    "\n",
    "if results:\n",
    "    print(\"\\n Analysis completed successfully!\")\n",
    "    print(\"Open the dashboard to explore detailed customer insights and segments\")\n",
    "else:\n",
    "    print(\"\\n Analysis failed. Please check the data and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833f2881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Memory cleared: 0 objects\n"
     ]
    }
   ],
   "source": [
    "# Add this line before loading your data\n",
    "import gc; gc.collect(); print(f\"ðŸ§¹ Memory cleared: {gc.collect()} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718fafba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e6c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cd8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
