{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3492c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.offline as pyo\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import polars as pl\n",
    "# import gc\n",
    "\n",
    "# # Load and prepare data\n",
    "# transactions = pd.read_parquet(\"../data/transactions_cleaned.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94174ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Standardize column names for consistency\n",
    "# column_mapping = {\n",
    "#     'Store Country': 'Store_Country',\n",
    "#     'Store City': 'Store_City', \n",
    "#     'Employee ID': 'Employee_ID',\n",
    "#     'Customer ID': 'Customer_ID',\n",
    "#     'Product ID': 'Product_ID',\n",
    "#     'Invoice USD': 'Invoice_USD',\n",
    "#     'Unit Price': 'Unit_Price'\n",
    "# }\n",
    "\n",
    "# # Apply column mapping if columns exist\n",
    "# for old_name, new_name in column_mapping.items():\n",
    "#     if old_name in transactions.columns:\n",
    "#         transactions.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "# # Data preparation and cleaning\n",
    "# def prepare_data():\n",
    "#     \"\"\"Prepare and clean all datasets for analysis\"\"\"\n",
    "    \n",
    "#     # Geographic Sales Data\n",
    "#     geo_sales = (\n",
    "#         transactions\n",
    "#         .dropna(subset=['Store_Country', 'Store_City', 'Latitude', 'Longitude', 'Invoice_USD'])\n",
    "#         .groupby(['Store_Country', 'Store_City', 'Latitude', 'Longitude'], as_index=False)\n",
    "#         .agg({'Invoice_USD': 'sum'})\n",
    "#         .rename(columns={'Invoice_USD': 'Total_Sales_USD'})\n",
    "#     )\n",
    "#     geo_sales.to_csv(\"data/geo_sales_summary.csv\", index=False)\n",
    "    \n",
    "#     # Employee Performance Data\n",
    "#     employee_perf = transactions.groupby(\"Employee_ID\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     employee_perf[\"Avg_Price\"] = employee_perf[\"Total_Sales\"] / employee_perf[\"Total_Quantity\"]\n",
    "#     employee_perf = employee_perf[employee_perf[\"Total_Quantity\"] >= 5]  # Filter minimum activity\n",
    "#     employee_perf.to_csv(\"data/employee_performance.csv\", index=False)\n",
    "    \n",
    "#     # Country Performance Data\n",
    "#     country_perf = transactions.groupby(\"Store_Country\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     country_perf[\"Avg_Price\"] = country_perf[\"Total_Sales\"] / country_perf[\"Total_Quantity\"]\n",
    "#     country_perf.to_csv(\"data/country_performance.csv\", index=False)\n",
    "    \n",
    "#     # City Performance Data\n",
    "#     city_perf = transactions.groupby(\"Store_City\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     city_perf[\"Avg_Price\"] = city_perf[\"Total_Sales\"] / city_perf[\"Total_Quantity\"]\n",
    "#     city_perf.to_csv(\"data/city_performance.csv\", index=False)\n",
    "    \n",
    "#     # Customer Performance Data\n",
    "#     customer_perf = transactions.groupby(\"Customer_ID\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     customer_perf[\"Avg_Price\"] = customer_perf[\"Total_Sales\"] / customer_perf[\"Total_Quantity\"]\n",
    "#     customer_perf = customer_perf[\n",
    "#         (customer_perf[\"Total_Quantity\"] > 0) &\n",
    "#         (customer_perf[\"Total_Sales\"] > 0) &\n",
    "#         customer_perf[\"Avg_Price\"].notna()\n",
    "#     ]\n",
    "#     customer_perf.to_csv(\"data/customer_performance.csv\", index=False)\n",
    "    \n",
    "#     # Product Performance Data\n",
    "#     product_perf = transactions.groupby(\"Product_ID\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     product_perf[\"Avg_Price\"] = product_perf[\"Total_Sales\"] / product_perf[\"Total_Quantity\"]\n",
    "#     product_perf = product_perf[\n",
    "#         (product_perf[\"Total_Quantity\"] > 0) &\n",
    "#         (product_perf[\"Total_Sales\"] > 0) &\n",
    "#         product_perf[\"Avg_Price\"].notna()\n",
    "#     ]\n",
    "#     product_perf.to_csv(\"data/product_performance.csv\", index=False)\n",
    "    \n",
    "#     # Discount Analysis Data\n",
    "#     transactions['Net_Revenue'] = transactions['Quantity'] * (\n",
    "#         transactions['Unit_Price'] * (1 - transactions['Discount'])\n",
    "#     )\n",
    "    \n",
    "#     discount_analysis = transactions.groupby('Product_ID').agg(\n",
    "#         Avg_Discount=('Discount', 'mean'),\n",
    "#         Total_Quantity=('Quantity', 'sum'),\n",
    "#         Net_Revenue=('Net_Revenue', 'sum'),\n",
    "#         Total_Sales=('Invoice_USD', 'sum')\n",
    "#     ).reset_index()\n",
    "#     discount_analysis.to_csv(\"data/discount_analysis.csv\", index=False)\n",
    "    \n",
    "#     # Customer Segmentation (RFM Analysis)\n",
    "#     # Assuming we have date column for recency calculation\n",
    "#     if 'Date' in transactions.columns:\n",
    "#         current_date = transactions['Date'].max()\n",
    "#         rfm_data = transactions.groupby('Customer_ID').agg(\n",
    "#             Recency=('Date', lambda x: (current_date - x.max()).days),\n",
    "#             Frequency=('Invoice_USD', 'count'),\n",
    "#             Monetary=('Invoice_USD', 'sum')\n",
    "#         ).reset_index()\n",
    "        \n",
    "#         # RFM Scoring\n",
    "#         rfm_data['R_Score'] = pd.qcut(rfm_data['Recency'], 5, labels=[5,4,3,2,1])\n",
    "#         rfm_data['F_Score'] = pd.qcut(rfm_data['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "#         rfm_data['M_Score'] = pd.qcut(rfm_data['Monetary'], 5, labels=[1,2,3,4,5])\n",
    "#         rfm_data['RFM_Score'] = rfm_data['R_Score'].astype(str) + rfm_data['F_Score'].astype(str) + rfm_data['M_Score'].astype(str)\n",
    "        \n",
    "#         # Customer Segments\n",
    "#         def segment_customers(row):\n",
    "#             if row['RFM_Score'] in ['555', '554', '544', '545', '454', '455', '445']:\n",
    "#                 return 'Champions'\n",
    "#             elif row['RFM_Score'] in ['543', '444', '435', '355', '354', '345', '344', '335']:\n",
    "#                 return 'Loyal Customers'\n",
    "#             elif row['RFM_Score'] in ['512', '511', '422', '421', '412', '411', '311']:\n",
    "#                 return 'Potential Loyalists'\n",
    "#             elif row['RFM_Score'] in ['533', '532', '531', '523', '522', '521', '515', '514', '513', '425', '424', '413', '414', '415', '315', '314', '313']:\n",
    "#                 return 'New Customers'\n",
    "#             elif row['RFM_Score'] in ['155', '154', '144', '214', '215', '115', '114']:\n",
    "#                 return 'At Risk'\n",
    "#             elif row['RFM_Score'] in ['255', '254', '245', '244', '253', '252', '243', '242', '235', '234', '225', '224', '153', '152', '145', '143', '142', '135', '134', '125', '124']:\n",
    "#                 return 'Cannot Lose Them'\n",
    "#             else:\n",
    "#                 return 'Others'\n",
    "        \n",
    "#         rfm_data['Customer_Segment'] = rfm_data.apply(segment_customers, axis=1)\n",
    "#         rfm_data.to_csv(\"data/rfm_analysis.csv\", index=False)\n",
    "    \n",
    "#     print(\"‚úÖ All data preparation completed successfully!\")\n",
    "\n",
    "# # Execute data preparation\n",
    "# prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# from datetime import datetime, timedelta\n",
    "# import gc\n",
    "# import os\n",
    "\n",
    "# # Create data directory if it doesn't exist\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# # Load data with Polars for better memory efficiency\n",
    "# print(\"üìä Loading data with Polars for memory efficiency...\")\n",
    "# # transactions_pl = pl.read_parquet(\"data/transactions_cleaned.parquet\")\n",
    "# transactions_pl = pl.from_pandas(transactions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5119b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Optimized Data Pipeline...\n",
      "üèóÔ∏è Creating master dataset...\n",
      "üìä Loading data efficiently...\n",
      "Loading discounts...\n",
      "Loading products...\n",
      "Loading employees...\n",
      "Loading stores...\n",
      "Loading customers...\n",
      "Loading transactions (this may take a moment)...\n",
      "Intial Transactions loaded: 6416827 rows\n",
      "Final Transactions loaded: 6416029 rows\n",
      "Converting to Polars for better performance...\n",
      "‚úÖ Data loaded successfully!\n",
      "Transactions shape: (6416029, 19)\n",
      "üîß Preparing optimized lookup tables...\n",
      "üóìÔ∏è Converting date columns to YYYY-MM-DD format: ['Start', 'End']\n",
      "‚úÖ Converted Start to YYYY-MM-DD date format\n",
      "‚úÖ Converted End to YYYY-MM-DD date format\n",
      "üóìÔ∏è Converting date columns to YYYY-MM-DD format: ['Date Of Birth']\n",
      "‚úÖ Converted Date Of Birth to YYYY-MM-DD date format\n",
      "‚úÖ Lookup tables prepared\n",
      "üí∞ Processing transactions...\n",
      "üóìÔ∏è Converting date columns to YYYY-MM-DD format: ['Date']\n",
      "‚úÖ Converted Date to YYYY-MM-DD date format\n",
      "üí± Adding USD conversion...\n",
      "‚úÖ Created Unit_Price_USD\n",
      "‚úÖ Created Line_Total_USD\n",
      "‚úÖ Created Invoice_Total_USD\n",
      "üîó Merging tables...\n",
      "‚úÖ Merged with products. Shape: (6416029, 29)\n",
      "‚úÖ Merged with customers. Shape: (6416029, 34)\n",
      "‚úÖ Merged with stores. Shape: (6416029, 38)\n",
      "‚úÖ Merged with employees. Shape: (6416029, 41)\n",
      "üíæ Saving lookup tables...\n",
      "üíæ Saving master dataset...\n",
      "‚úÖ Master dataset created successfully!\n",
      "Final shape: (6416029, 41)\n",
      "Memory usage optimized by keeping only essential columns from lookup tables\n",
      "\n",
      "üìä MASTER DATASET SUMMARY:\n",
      "Shape: (6416029, 41)\n",
      "Columns: 41\n",
      "\n",
      "üìã Column List:\n",
      " 1. Invoice ID\n",
      " 2. Line\n",
      " 3. Customer ID\n",
      " 4. Product ID\n",
      " 5. Size\n",
      " 6. Color\n",
      " 7. Unit Price\n",
      " 8. Quantity\n",
      " 9. Date\n",
      "10. Discount\n",
      "11. Line Total\n",
      "12. Store ID\n",
      "13. Employee ID\n",
      "14. Currency\n",
      "15. Currency Symbol\n",
      "16. SKU\n",
      "17. Transaction Type\n",
      "18. Payment Method\n",
      "19. Invoice Total\n",
      "20. Exchange_Rate_to_USD\n",
      "21. Unit_Price_USD\n",
      "22. Line_Total_USD\n",
      "23. Invoice_Total_USD\n",
      "24. Category\n",
      "25. Sub Category\n",
      "26. Description EN\n",
      "27. Color_right\n",
      "28. Sizes\n",
      "29. Production Cost\n",
      "30. Name\n",
      "31. Email\n",
      "32. Gender\n",
      "33. Date Of Birth\n",
      "34. Job Title\n",
      "35. Country\n",
      "36. City\n",
      "37. Store Name\n",
      "38. Number of Employees\n",
      "39. Store ID_right\n",
      "40. Name_right\n",
      "41. Position\n",
      "\n",
      "üí∞ USD Converted Columns:\n",
      "   ‚Ä¢ Exchange_Rate_to_USD\n",
      "   ‚Ä¢ Unit_Price_USD\n",
      "   ‚Ä¢ Line_Total_USD\n",
      "   ‚Ä¢ Invoice_Total_USD\n",
      "\n",
      "üóìÔ∏è Date Columns (YYYY-MM-DD format):\n",
      "   ‚Ä¢ Date\n",
      "     Sample: [datetime.date(2023, 1, 1), datetime.date(2023, 1, 1), datetime.date(2023, 1, 1)]\n",
      "   ‚Ä¢ Date Of Birth\n",
      "     Sample: [datetime.date(1983, 12, 25), datetime.date(1983, 12, 25), datetime.date(1983, 12, 25)]\n",
      "\n",
      "üìà Sample Data:\n",
      "shape: (3, 41)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ Invoice ID ‚îÜ Line ‚îÜ Customer   ‚îÜ Product ID ‚îÜ ‚Ä¶ ‚îÜ Number of  ‚îÜ Store     ‚îÜ Name_righ ‚îÜ Position  ‚îÇ\n",
      "‚îÇ ---        ‚îÜ ---  ‚îÜ ID         ‚îÜ ---        ‚îÜ   ‚îÜ Employees  ‚îÜ ID_right  ‚îÜ t         ‚îÜ ---       ‚îÇ\n",
      "‚îÇ str        ‚îÜ i64  ‚îÜ ---        ‚îÜ i64        ‚îÜ   ‚îÜ ---        ‚îÜ ---       ‚îÜ ---       ‚îÜ str       ‚îÇ\n",
      "‚îÇ            ‚îÜ      ‚îÜ i64        ‚îÜ            ‚îÜ   ‚îÜ i64        ‚îÜ i64       ‚îÜ str       ‚îÜ           ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ INV-US-001 ‚îÜ 1    ‚îÜ 47162      ‚îÜ 485        ‚îÜ ‚Ä¶ ‚îÜ 10         ‚îÜ 1         ‚îÜ Melissa   ‚îÜ Sales     ‚îÇ\n",
      "‚îÇ -03558761  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ            ‚îÜ           ‚îÜ Wilson    ‚îÜ Associate ‚îÇ\n",
      "‚îÇ INV-US-001 ‚îÜ 2    ‚îÜ 47162      ‚îÜ 2779       ‚îÜ ‚Ä¶ ‚îÜ 10         ‚îÜ 1         ‚îÜ Melissa   ‚îÜ Sales     ‚îÇ\n",
      "‚îÇ -03558761  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ            ‚îÜ           ‚îÜ Wilson    ‚îÜ Associate ‚îÇ\n",
      "‚îÇ INV-US-001 ‚îÜ 3    ‚îÜ 47162      ‚îÜ 64         ‚îÜ ‚Ä¶ ‚îÜ 10         ‚îÜ 1         ‚îÜ Melissa   ‚îÜ Sales     ‚îÇ\n",
      "‚îÇ -03558761  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ            ‚îÜ           ‚îÜ Wilson    ‚îÜ Associate ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "‚úÖ Pipeline Complete!\n",
      "Files saved:\n",
      "   ‚Ä¢ data/master_transactions.parquet (main dataset)\n",
      "   ‚Ä¢ data/master_transactions_sample.csv (sample for inspection)\n",
      "   ‚Ä¢ data/discounts_lookup.parquet (for discount analysis)\n",
      "   ‚Ä¢ data/products_lookup.parquet\n",
      "   ‚Ä¢ data/employees_lookup.parquet\n",
      "   ‚Ä¢ data/stores_lookup.parquet\n",
      "   ‚Ä¢ data/customers_lookup.parquet\n",
      "\n",
      "üìÖ All dates are now in simple YYYY-MM-DD format!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Exchange rates you provided\n",
    "exchange_rates = {\n",
    "    'EUR': 1.13,\n",
    "    'GBP': 1.34,\n",
    "    'CNY': 0.14,\n",
    "    'USD': 1.0\n",
    "}\n",
    "\n",
    "city_translation_map = {\n",
    "\n",
    "}\n",
    "\n",
    "country_translation_map = {\n",
    "    '‰∏≠ÂõΩ': 'China',\n",
    "    'Espa√±a': 'Spain',\n",
    "    'Portugal': 'Portugal',\n",
    "    'Deutschland': 'Germany',\n",
    "    'France': 'France',\n",
    "    'United Kingdom': 'United Kingdom',\n",
    "    'United States': 'United States'\n",
    "}\n",
    "\n",
    "def load_data_efficiently():\n",
    "    \"\"\"Load data with optimized memory usage\"\"\"\n",
    "    print(\"üìä Loading data efficiently...\")\n",
    "    \n",
    "    # Load with pandas first, then convert to polars for better performance\n",
    "    print(\"Loading discounts...\")\n",
    "    discounts = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\discounts.csv')\n",
    "    \n",
    "    print(\"Loading products...\")\n",
    "    products = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\products.csv')\n",
    "    \n",
    "    print(\"Loading employees...\")\n",
    "    employees = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\employees.csv')\n",
    "    \n",
    "    print(\"Loading stores...\")\n",
    "    stores = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\stores.csv')\n",
    "    \n",
    "    print(\"Loading customers...\")\n",
    "    customers = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\customers.csv', low_memory=False)\n",
    "    \n",
    "    print(\"Loading transactions (this may take a moment)...\")\n",
    "    transactions = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\transactions.csv', low_memory=False)\n",
    "    print(f\"Intial Transactions loaded: {len(transactions)} rows\")\n",
    "    transactions=transactions.drop_duplicates()\n",
    "    print(f\"Final Transactions loaded: {len(transactions)} rows\")\n",
    "    \n",
    "    # Convert to polars for better performance\n",
    "    print(\"Converting to Polars for better performance...\")\n",
    "    discounts_pl = pl.from_pandas(discounts)\n",
    "    products_pl = pl.from_pandas(products)\n",
    "    employees_pl = pl.from_pandas(employees)\n",
    "    stores_pl = pl.from_pandas(stores)\n",
    "    customers_pl = pl.from_pandas(customers)\n",
    "    transactions_pl = pl.from_pandas(transactions)\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"Transactions shape: {transactions_pl.shape}\")\n",
    "    \n",
    "    return discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl\n",
    "\n",
    "\n",
    "def clean_and_translate_data(master_data, city_translation_map, country_translation_map):\n",
    "    \"\"\"\n",
    "    Clean and translate city and country names into English using Polars DataFrame.\n",
    "    Compatible with older Polars versions.\n",
    "    \"\"\"\n",
    "    master_data = master_data.with_columns([\n",
    "        pl.col(\"City\").replace(city_translation_map).alias(\"City\"),\n",
    "        pl.col(\"Country\").replace(country_translation_map).alias(\"Country\")\n",
    "    ])\n",
    "    return master_data\n",
    "\n",
    "\n",
    "def clean_date_columns(df, date_columns):\n",
    "    \"\"\"Clean and convert date columns to simple YYYY-MM-DD format\"\"\"\n",
    "    print(f\"üóìÔ∏è Converting date columns to YYYY-MM-DD format: {date_columns}\")\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                # Convert to date (not datetime) - this removes time component automatically\n",
    "                df = df.with_columns(\n",
    "                    pl.col(col).str.strptime(pl.Date, format=\"%Y-%m-%d\", strict=False)\n",
    "                    .fill_null(\n",
    "                        pl.col(col).str.strptime(pl.Date, format=\"%Y-%m-%d %H:%M:%S\", strict=False)\n",
    "                    )\n",
    "                    .fill_null(\n",
    "                        pl.col(col).str.strptime(pl.Date, format=\"%d/%m/%Y\", strict=False)\n",
    "                    )\n",
    "                    .alias(col)\n",
    "                )\n",
    "                print(f\"‚úÖ Converted {col} to YYYY-MM-DD date format\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Could not convert {col}: {e}\")\n",
    "                # Keep original if conversion fails\n",
    "                pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_lookup_tables(discounts_pl, products_pl, employees_pl, stores_pl, customers_pl):\n",
    "    \"\"\"Prepare minimal lookup tables with only essential information\"\"\"\n",
    "    print(\"üîß Preparing optimized lookup tables...\")\n",
    "    \n",
    "    # Clean discount dates - Start and End to YYYY-MM-DD\n",
    "    discounts_clean = clean_date_columns(discounts_pl, ['Start', 'End'])\n",
    "    discounts_lookup = discounts_clean.select([\n",
    "        'Start', 'End', 'Discont', 'Description', 'Category', 'Sub Category'\n",
    "    ])\n",
    "    \n",
    "    # Products - keep essential info only\n",
    "    products_lookup = products_pl.select([\n",
    "        'Product ID', 'Category', 'Sub Category', 'Description EN', \n",
    "        'Color', 'Sizes', 'Production Cost'\n",
    "    ])\n",
    "    \n",
    "    # Employees - minimal info\n",
    "    employees_lookup = employees_pl.select([\n",
    "        'Employee ID', 'Store ID', 'Name', 'Position'\n",
    "    ])\n",
    "    \n",
    "    # Stores - essential location info\n",
    "    stores_pl = clean_and_translate_data(stores_pl, city_translation_map, country_translation_map)\n",
    "    stores_lookup = stores_pl.select([\n",
    "        'Store ID', 'Country', 'City', 'Store Name', 'Number of Employees'\n",
    "    ])\n",
    "    \n",
    "    # Customers - clean birth date to YYYY-MM-DD and keep essential info\n",
    "    customers_pl = clean_and_translate_data(customers_pl, city_translation_map, country_translation_map)\n",
    "    customers_clean = clean_date_columns(customers_pl, ['Date Of Birth'])\n",
    "    customers_lookup = customers_clean.select([\n",
    "        'Customer ID', 'Name', 'Email', 'Gender', 'Date Of Birth', 'Job Title'\n",
    "    ])\n",
    "    \n",
    "    print(\"‚úÖ Lookup tables prepared\")\n",
    "    return discounts_lookup, products_lookup, employees_lookup, stores_lookup, customers_lookup\n",
    "\n",
    "def process_transactions(transactions_pl, exchange_rates):\n",
    "    \"\"\"Process transactions with USD conversion and date cleaning\"\"\"\n",
    "    print(\"üí∞ Processing transactions...\")\n",
    "    \n",
    "    # Clean transaction dates - convert Date to YYYY-MM-DD format (removes time)\n",
    "    \n",
    "    transactions_clean = clean_date_columns(transactions_pl, ['Date'])\n",
    "    \n",
    "    # Add exchange rate column\n",
    "    print(\"üí± Adding USD conversion...\")\n",
    "    transactions_clean = transactions_clean.with_columns(\n",
    "        pl.col('Currency').map_elements(\n",
    "            lambda x: exchange_rates.get(x, 1.0), \n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(\"Exchange_Rate_to_USD\")\n",
    "    )\n",
    "    \n",
    "    # Convert monetary columns to USD\n",
    "    monetary_columns = ['Unit Price', 'Line Total', 'Invoice Total']\n",
    "    \n",
    "    for col in monetary_columns:\n",
    "        if col in transactions_clean.columns:\n",
    "            usd_col_name = f\"{col.replace(' ', '_')}_USD\"\n",
    "            transactions_clean = transactions_clean.with_columns(\n",
    "                (pl.col(col) * pl.col(\"Exchange_Rate_to_USD\")).alias(usd_col_name)\n",
    "            )\n",
    "            print(f\"‚úÖ Created {usd_col_name}\")\n",
    "    \n",
    "    return transactions_clean\n",
    "\n",
    "def create_master_dataset():\n",
    "    \"\"\"Create the master dataset with optimized merging\"\"\"\n",
    "    print(\"üèóÔ∏è Creating master dataset...\")\n",
    "    \n",
    "    # Load data\n",
    "    discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl = load_data_efficiently()\n",
    "    \n",
    "    # Prepare lookup tables\n",
    "    discounts_lookup, products_lookup, employees_lookup, stores_lookup, customers_lookup = prepare_lookup_tables(\n",
    "        discounts_pl, products_pl, employees_pl, stores_pl, customers_pl\n",
    "    )\n",
    "    \n",
    "    # Process transactions\n",
    "    transactions_processed = process_transactions(transactions_pl, exchange_rates)\n",
    "    \n",
    "    # Merge with lookup tables (left joins to keep all transactions)\n",
    "    print(\"üîó Merging tables...\")\n",
    "    \n",
    "    # Merge with products\n",
    "    master_data = transactions_processed.join(\n",
    "        products_lookup, \n",
    "        on='Product ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"‚úÖ Merged with products. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Merge with customers\n",
    "    master_data = master_data.join(\n",
    "        customers_lookup, \n",
    "        on='Customer ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"‚úÖ Merged with customers. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Merge with stores\n",
    "    master_data = master_data.join(\n",
    "        stores_lookup, \n",
    "        on='Store ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"‚úÖ Merged with stores. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Merge with employees\n",
    "    master_data = master_data.join(\n",
    "        employees_lookup, \n",
    "        on='Employee ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"‚úÖ Merged with employees. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Save lookup tables separately for future use\n",
    "    print(\"üíæ Saving lookup tables...\")\n",
    "    discounts_lookup.write_parquet(\"data/discounts_lookup.parquet\")\n",
    "    products_lookup.write_parquet(\"data/products_lookup.parquet\")\n",
    "    employees_lookup.write_parquet(\"data/employees_lookup.parquet\")\n",
    "    stores_lookup.write_parquet(\"data/stores_lookup.parquet\")\n",
    "    customers_lookup.write_parquet(\"data/customers_lookup.parquet\")\n",
    "    \n",
    "    # Save master dataset\n",
    "    print(\"üíæ Saving master dataset...\")\n",
    "    master_data.write_parquet(\"data/master_transactions.parquet\")\n",
    "    \n",
    "    # Save a sample CSV for inspection (first 10k rows)\n",
    "    master_data.head(10000).write_csv(\"data/master_transactions_sample.csv\")\n",
    "    \n",
    "    print(\"‚úÖ Master dataset created successfully!\")\n",
    "    print(f\"Final shape: {master_data.shape}\")\n",
    "    print(f\"Memory usage optimized by keeping only essential columns from lookup tables\")\n",
    "    \n",
    "    return master_data, discounts_lookup\n",
    "\n",
    "def show_dataset_summary(master_data):\n",
    "    \"\"\"Show summary of the final dataset\"\"\"\n",
    "    print(\"\\nüìä MASTER DATASET SUMMARY:\")\n",
    "    print(f\"Shape: {master_data.shape}\")\n",
    "    print(f\"Columns: {len(master_data.columns)}\")\n",
    "    \n",
    "    print(\"\\nüìã Column List:\")\n",
    "    for i, col in enumerate(master_data.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ USD Converted Columns:\")\n",
    "    usd_cols = [col for col in master_data.columns if 'USD' in col]\n",
    "    for col in usd_cols:\n",
    "        print(f\"   ‚Ä¢ {col}\")\n",
    "    \n",
    "    print(f\"\\nüóìÔ∏è Date Columns (YYYY-MM-DD format):\")\n",
    "    date_cols = [col for col in master_data.columns if master_data[col].dtype == pl.Date]\n",
    "    for col in date_cols:\n",
    "        print(f\"   ‚Ä¢ {col}\")\n",
    "        # Show sample dates\n",
    "        sample_dates = master_data.select(col).drop_nulls().head(3)\n",
    "        print(f\"     Sample: {sample_dates.to_series().to_list()}\")\n",
    "    \n",
    "    print(f\"\\nüìà Sample Data:\")\n",
    "    print(master_data.head(3))\n",
    "    \n",
    "    return master_data\n",
    "\n",
    "# Execute the pipeline\n",
    "print(\"üöÄ Starting Optimized Data Pipeline...\")\n",
    "master_data, discounts_lookup = create_master_dataset()\n",
    "final_data = show_dataset_summary(master_data)\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline Complete!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"   ‚Ä¢ data/master_transactions.parquet (main dataset)\")\n",
    "print(\"   ‚Ä¢ data/master_transactions_sample.csv (sample for inspection)\")\n",
    "print(\"   ‚Ä¢ data/discounts_lookup.parquet (for discount analysis)\")\n",
    "print(\"   ‚Ä¢ data/products_lookup.parquet\")\n",
    "print(\"   ‚Ä¢ data/employees_lookup.parquet\") \n",
    "print(\"   ‚Ä¢ data/stores_lookup.parquet\")\n",
    "print(\"   ‚Ä¢ data/customers_lookup.parquet\")\n",
    "print(\"\\nüìÖ All dates are now in simple YYYY-MM-DD format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08f3cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Memory cleared: 0 objects\n"
     ]
    }
   ],
   "source": [
    "# Add this line before loading your data\n",
    "import gc; gc.collect(); print(f\"üßπ Memory cleared: {gc.collect()} objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b888a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total USD for Sale: 305884836.54719996\n",
      "Total USD for Return: -17136183.740900002\n"
     ]
    }
   ],
   "source": [
    "sale_total = final_data.filter(pl.col(\"Transaction Type\") == \"Sale\")[\"Line_Total_USD\"].sum()\n",
    "\n",
    "# Filter rows for 'Return' and calculate the sum of 'Line_Total_USD'\n",
    "return_total = final_data.filter(pl.col(\"Transaction Type\") == \"Return\")[\"Line_Total_USD\"].sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total USD for Sale: {sale_total}\")\n",
    "print(f\"Total USD for Return: {return_total}\")\n",
    "\n",
    "# # Print the results\n",
    "# print(sum_by_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f30ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Line_Total_USD for unique InvoiceIDs (Sale transactions): 305884634.1774\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming final_data is your Polars DataFrame\n",
    "# Step 1: Filter rows where the transaction type is 'Sale'\n",
    "sale_data = final_data.filter(pl.col(\"Transaction Type\") == \"Sale\")\n",
    "\n",
    "# Step 2: Remove duplicate InvoiceID values\n",
    "unique_sale_data = sale_data.unique(subset=[\"Invoice ID\"])\n",
    "\n",
    "# Step 3: Sum the Line_Total_USD column\n",
    "line_total_sum = unique_sale_data[\"Invoice_Total_USD\"].sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Sum of Line_Total_USD for unique InvoiceIDs (Sale transactions): {line_total_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b87e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Line_Total_USD for unique InvoiceIDs (Return transactions): -15683410.0896\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming final_data is your Polars DataFrame\n",
    "# Step 1: Filter rows where the transaction type is 'Sale'\n",
    "sale_data2 = final_data.filter(pl.col(\"Transaction Type\") == \"Return\")\n",
    "\n",
    "# Step 2: Remove duplicate InvoiceID values\n",
    "unique_sale_data2 = sale_data2.unique(subset=[\"Invoice ID\"])\n",
    "\n",
    "# Step 3: Sum the Line_Total_USD column\n",
    "line_total_sum2 = unique_sale_data2[\"Invoice_Total_USD\"].sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Sum of Line_Total_USD for unique InvoiceIDs (Return transactions): {line_total_sum2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff9c6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading data efficiently...\n",
      "Loading discounts...\n",
      "Loading products...\n",
      "Loading employees...\n",
      "Loading stores...\n",
      "Loading customers...\n",
      "Loading transactions (this may take a moment)...\n",
      "Converting to Polars for better performance...\n",
      "‚úÖ Data loaded successfully!\n",
      "Transactions shape: (6416827, 19)\n",
      "\n",
      "============================================================\n",
      "üìä PERFORMING DESCRIPTIVE STATISTICS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üè∑Ô∏è DISCOUNTS Dataset Analysis:\n",
      "----------------------------------------\n",
      "   üìã Records: 181\n",
      "   üìä Columns: 6\n",
      "   üíæ Memory: 0.02 MB\n",
      "\n",
      "üì¶ PRODUCTS Dataset Analysis:\n",
      "----------------------------------------\n",
      "   üìã Records: 17,940\n",
      "   üìä Columns: 12\n",
      "   üíæ Memory: 4.67 MB\n",
      "   üè∑Ô∏è Categories: 3\n",
      "\n",
      "üë• EMPLOYEES Dataset Analysis:\n",
      "----------------------------------------\n",
      "   üìã Records: 404\n",
      "   üìä Columns: 4\n",
      "   üíæ Memory: 0.02 MB\n",
      "\n",
      "üè™ STORES Dataset Analysis:\n",
      "----------------------------------------\n",
      "   üìã Records: 35\n",
      "   üìä Columns: 8\n",
      "   üíæ Memory: 0.00 MB\n",
      "\n",
      "üë§ CUSTOMERS Dataset Analysis:\n",
      "----------------------------------------\n",
      "   üìã Records: 1,643,306\n",
      "   üìä Columns: 9\n",
      "   üíæ Memory: 169.71 MB\n",
      "\n",
      "üí≥ TRANSACTIONS Dataset Analysis:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alan\\AppData\\Local\\Temp\\ipykernel_47356\\164116053.py:32: DeprecationWarning: `NUMERIC_DTYPES` was deprecated in version 1.0.0. Define your own data type groups or use the `polars.selectors` module for selecting columns of a certain data type.\n",
      "  numeric_cols = discounts_pl.select(pl.col(pl.NUMERIC_DTYPES)).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Records: 6,416,827\n",
      "   üìä Columns: 19\n",
      "   üíæ Memory: 936.64 MB\n",
      "\n",
      "üìà OVERALL DATA SUMMARY:\n",
      "----------------------------------------\n",
      "   üìä Total Datasets: 6\n",
      "   üìã Total Records: 8,078,693\n",
      "   üíæ Total Memory: 1111.06 MB\n",
      "\n",
      "üíæ Saving descriptive statistics...\n",
      "‚úÖ Descriptive statistics completed!\n",
      "üìÅ Results saved in: descriptive_statistics/\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(shape: (181, 6)\n",
       " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       " ‚îÇ Start      ‚îÜ End        ‚îÜ Discont ‚îÜ Description         ‚îÜ Category  ‚îÜ Sub Category               ‚îÇ\n",
       " ‚îÇ ---        ‚îÜ ---        ‚îÜ ---     ‚îÜ ---                 ‚îÜ ---       ‚îÜ ---                        ‚îÇ\n",
       " ‚îÇ str        ‚îÜ str        ‚îÜ f64     ‚îÜ str                 ‚îÜ str       ‚îÜ str                        ‚îÇ\n",
       " ‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       " ‚îÇ 2020-01-01 ‚îÜ 2020-01-10 ‚îÜ 0.4     ‚îÜ 40% discount during ‚îÜ Feminine  ‚îÜ Coats and Blazers          ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our New Ye‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2020-01-01 ‚îÜ 2020-01-10 ‚îÜ 0.4     ‚îÜ 40% discount during ‚îÜ Feminine  ‚îÜ Sweaters and Knitwear      ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our New Ye‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2020-01-01 ‚îÜ 2020-01-10 ‚îÜ 0.4     ‚îÜ 40% discount during ‚îÜ Masculine ‚îÜ Coats and Blazers          ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our New Ye‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2020-01-01 ‚îÜ 2020-01-10 ‚îÜ 0.4     ‚îÜ 40% discount during ‚îÜ Masculine ‚îÜ Sweaters and Sweatshirts   ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our New Ye‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2020-01-01 ‚îÜ 2020-01-10 ‚îÜ 0.4     ‚îÜ 40% discount during ‚îÜ Children  ‚îÜ Coats                      ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our New Ye‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ ‚Ä¶          ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶                   ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶                          ‚îÇ\n",
       " ‚îÇ 2025-03-15 ‚îÜ 2025-03-31 ‚îÜ 0.35    ‚îÜ 35% discount during ‚îÜ Feminine  ‚îÜ Dresses and Jumpsuits      ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our Early ‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2025-03-15 ‚îÜ 2025-03-31 ‚îÜ 0.35    ‚îÜ 35% discount during ‚îÜ Feminine  ‚îÜ Shirts and Blouses         ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our Early ‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2025-03-15 ‚îÜ 2025-03-31 ‚îÜ 0.35    ‚îÜ 35% discount during ‚îÜ Masculine ‚îÜ T-shirts and Polos         ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our Early ‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2025-03-15 ‚îÜ 2025-03-31 ‚îÜ 0.35    ‚îÜ 35% discount during ‚îÜ Masculine ‚îÜ Shirts                     ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our Early ‚Ä¶         ‚îÜ           ‚îÜ                            ‚îÇ\n",
       " ‚îÇ 2025-03-15 ‚îÜ 2025-03-31 ‚îÜ 0.35    ‚îÜ 35% discount during ‚îÜ Children  ‚îÜ Girl and Boy (1-5 years,   ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ         ‚îÜ our Early ‚Ä¶         ‚îÜ           ‚îÜ 6-14 ‚Ä¶                     ‚îÇ\n",
       " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò,\n",
       " shape: (17_940, 12)\n",
       " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       " ‚îÇ Product ID ‚îÜ Category ‚îÜ Sub       ‚îÜ Descripti ‚îÜ ‚Ä¶ ‚îÜ Descripti ‚îÜ Color     ‚îÜ Sizes    ‚îÜ Productio ‚îÇ\n",
       " ‚îÇ ---        ‚îÜ ---      ‚îÜ Category  ‚îÜ on PT     ‚îÜ   ‚îÜ on ZH     ‚îÜ ---       ‚îÜ ---      ‚îÜ n Cost    ‚îÇ\n",
       " ‚îÇ i64        ‚îÜ str      ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ ---       ‚îÜ str       ‚îÜ str      ‚îÜ ---       ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ str       ‚îÜ str       ‚îÜ   ‚îÜ str       ‚îÜ           ‚îÜ          ‚îÜ f64       ‚îÇ\n",
       " ‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       " ‚îÇ 1          ‚îÜ Feminine ‚îÜ Coats and ‚îÜ Esportivo ‚îÜ ‚Ä¶ ‚îÜ ËøêÂä®Â§©ÈπÖ  ‚îÜ null      ‚îÜ S|M|L|XL ‚îÜ 10.73     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ Blazers   ‚îÜ Veludo    ‚îÜ   ‚îÜ ÁªíËøêÂä®‰∏é  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Verde Com ‚îÜ   ‚îÜ ÊåâÈíÆ      ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Bot‚Ä¶      ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 2          ‚îÜ Feminine ‚îÜ Sweaters  ‚îÜ Luxuoso   ‚îÜ ‚Ä¶ ‚îÜ Ë±™ÂçéÁöÑÁ≤â  ‚îÜ PINK      ‚îÜ S|M|L|XL ‚îÜ 19.55     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ and       ‚îÜ Denim     ‚îÜ   ‚îÜ Á∫¢Ëâ≤Áâõ‰ªî  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ Knitwear  ‚îÜ Rosa Com  ‚îÜ   ‚îÜ Â∏ÉÂíåÁ∫ΩÊâ£  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Bot√µes    ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 3          ‚îÜ Feminine ‚îÜ Dresses   ‚îÜ Retr√¥     ‚îÜ ‚Ä¶ ‚îÜ ÈªëËâ≤‰∏âËßí  ‚îÜ BLACK     ‚îÜ S|M|L|XL ‚îÜ 25.59     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ and       ‚îÜ Tricot    ‚îÜ   ‚îÜ ÂΩ¢Âç∞Âà∑‰∏â  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ Jumpsuits ‚îÜ Preto     ‚îÜ   ‚îÜ ËßíÂΩ¢      ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Estampado ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 4          ‚îÜ Feminine ‚îÜ Shirts    ‚îÜ Blusa De  ‚îÜ ‚Ä¶ ‚îÜ Âü∫Êú¨ÁöÑÊ£â  ‚îÜ null      ‚îÜ S|M|L|XL ‚îÜ 27.62     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ and       ‚îÜ Algod√£o   ‚îÜ   ‚îÜ Ë°¨Ë°´      ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ Blouses   ‚îÜ B√°sica    ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 5          ‚îÜ Feminine ‚îÜ T-shirts  ‚îÜ T-Shirt   ‚îÜ ‚Ä¶ ‚îÜ Âü∫Êú¨Ê£âTÊÅ§ ‚îÜ null      ‚îÜ S|M|L    ‚îÜ 11.69     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ and Tops  ‚îÜ B√°sica De ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Algod√£o   ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ ‚Ä¶          ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÇ\n",
       " ‚îÇ 17936      ‚îÜ Children ‚îÜ Girl and  ‚îÜ Executivo ‚îÜ ‚Ä¶ ‚îÜ Ë°åÊîøÁªøÈù©  ‚îÜ GREEN     ‚îÜ P|M|G|GG ‚îÜ 7.69      ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ Boy (1-5  ‚îÜ Camur√ßa   ‚îÜ   ‚îÜ ‰∏éÊãâÈìæ    ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ years,    ‚îÜ Verde Com ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ 6-14 ‚Ä¶    ‚îÜ Z√≠‚Ä¶       ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 17937      ‚îÜ Children ‚îÜ Coats     ‚îÜ Luxuoso   ‚îÜ ‚Ä¶ ‚îÜ Ë±™ÂçéÁöÑÁªø  ‚îÜ TURQUOISE ‚îÜ P|M|G    ‚îÜ 11.65     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ L√£        ‚îÜ   ‚îÜ ÊùæÁü≥ÁæäÊØõ  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Turquesa  ‚îÜ   ‚îÜ ÂíåÂºïÊìéÁõñ  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Com Capuz ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 17938      ‚îÜ Children ‚îÜ Sweaters  ‚îÜ Camisola  ‚îÜ ‚Ä¶ ‚îÜ Â∏¶Âá†‰ΩïÂç∞  ‚îÜ null      ‚îÜ P|M|G    ‚îÜ 24.38     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Infantil  ‚îÜ   ‚îÜ Âà∑ÁöÑKidsk ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ De Tric√¥  ‚îÜ   ‚îÜ otË°¨Ë°´    ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Com‚Ä¶      ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 17939      ‚îÜ Children ‚îÜ Pajamas   ‚îÜ Pijama    ‚îÜ ‚Ä¶ ‚îÜ Â≠©Â≠ê‰ª¨Áºé  ‚îÜ null      ‚îÜ P|M|G    ‚îÜ 18.27     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Infantil  ‚îÜ   ‚îÜ Èù¢Áù°Ë°£Ôºå  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ De Cetim  ‚îÜ   ‚îÜ ÂÖâÊªëÁöÑÂÖâ  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Com B‚Ä¶    ‚îÜ   ‚îÜ Ê≥ΩÂíåÂè£Ë¢ã  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 17940      ‚îÜ Children ‚îÜ Accessori ‚îÜ Protetor  ‚îÜ ‚Ä¶ ‚îÜ ‰∏∫‰∫ÜÂÆâÂÖ®  ‚îÜ null      ‚îÜ null     ‚îÜ 10.99     ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ es        ‚îÜ De Bra√ßo  ‚îÜ   ‚îÜ Ëµ∑ËßÅÂÑøÁ´•  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Infantil  ‚îÜ   ‚îÜ ÊâãËáÇ‰øùÊä§  ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ          ‚îÜ           ‚îÜ Par‚Ä¶      ‚îÜ   ‚îÜ Âô®        ‚îÜ           ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò,\n",
       " shape: (404, 4)\n",
       " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       " ‚îÇ Employee ID ‚îÜ Store ID ‚îÜ Name               ‚îÜ Position          ‚îÇ\n",
       " ‚îÇ ---         ‚îÜ ---      ‚îÜ ---                ‚îÜ ---               ‚îÇ\n",
       " ‚îÇ i64         ‚îÜ i64      ‚îÜ str                ‚îÜ str               ‚îÇ\n",
       " ‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       " ‚îÇ 1           ‚îÜ 1        ‚îÜ Stephen Johnson    ‚îÜ Store Manager     ‚îÇ\n",
       " ‚îÇ 2           ‚îÜ 1        ‚îÜ Rebecca Myers      ‚îÜ Assistant Manager ‚îÇ\n",
       " ‚îÇ 3           ‚îÜ 1        ‚îÜ Katherine Buchanan ‚îÜ Cashier           ‚îÇ\n",
       " ‚îÇ 4           ‚îÜ 1        ‚îÜ Jessica Hicks      ‚îÜ Stock Clerk       ‚îÇ\n",
       " ‚îÇ 5           ‚îÜ 1        ‚îÜ Ryan Gross         ‚îÜ Sales Associate   ‚îÇ\n",
       " ‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶                  ‚îÜ ‚Ä¶                 ‚îÇ\n",
       " ‚îÇ 400         ‚îÜ 35       ‚îÜ Henrique Amaral    ‚îÜ Sales Associate   ‚îÇ\n",
       " ‚îÇ 401         ‚îÜ 35       ‚îÜ Brian Rocha        ‚îÜ Sales Associate   ‚îÇ\n",
       " ‚îÇ 402         ‚îÜ 35       ‚îÜ Matilde Campos     ‚îÜ Sales Associate   ‚îÇ\n",
       " ‚îÇ 403         ‚îÜ 35       ‚îÜ Emanuel Marques    ‚îÜ Sales Associate   ‚îÇ\n",
       " ‚îÇ 404         ‚îÜ 35       ‚îÜ Violeta Gon√ßalves  ‚îÜ Sales Associate   ‚îÇ\n",
       " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò,\n",
       " shape: (35, 8)\n",
       " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       " ‚îÇ Store ID ‚îÜ Country     ‚îÜ City        ‚îÜ Store Name ‚îÜ Number of  ‚îÜ ZIP Code ‚îÜ Latitude ‚îÜ Longitude ‚îÇ\n",
       " ‚îÇ ---      ‚îÜ ---         ‚îÜ ---         ‚îÜ ---        ‚îÜ Employees  ‚îÜ ---      ‚îÜ ---      ‚îÜ ---       ‚îÇ\n",
       " ‚îÇ i64      ‚îÜ str         ‚îÜ str         ‚îÜ str        ‚îÜ ---        ‚îÜ str      ‚îÜ f64      ‚îÜ f64       ‚îÇ\n",
       " ‚îÇ          ‚îÜ             ‚îÜ             ‚îÜ            ‚îÜ i64        ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       " ‚îÇ 1        ‚îÜ United      ‚îÜ New York    ‚îÜ Store New  ‚îÜ 10         ‚îÜ 10001    ‚îÜ 40.7128  ‚îÜ -74.006   ‚îÇ\n",
       " ‚îÇ          ‚îÜ States      ‚îÜ             ‚îÜ York       ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 2        ‚îÜ United      ‚îÜ Los Angeles ‚îÜ Store Los  ‚îÜ 8          ‚îÜ 90001    ‚îÜ 34.0522  ‚îÜ -118.2437 ‚îÇ\n",
       " ‚îÇ          ‚îÜ States      ‚îÜ             ‚îÜ Angeles    ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 3        ‚îÜ United      ‚îÜ Chicago     ‚îÜ Store      ‚îÜ 9          ‚îÜ 60601    ‚îÜ 41.8781  ‚îÜ -87.6298  ‚îÇ\n",
       " ‚îÇ          ‚îÜ States      ‚îÜ             ‚îÜ Chicago    ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 4        ‚îÜ United      ‚îÜ Houston     ‚îÜ Store      ‚îÜ 10         ‚îÜ 77001    ‚îÜ 29.7604  ‚îÜ -95.3698  ‚îÇ\n",
       " ‚îÇ          ‚îÜ States      ‚îÜ             ‚îÜ Houston    ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 5        ‚îÜ United      ‚îÜ Phoenix     ‚îÜ Store      ‚îÜ 9          ‚îÜ 85001    ‚îÜ 33.4484  ‚îÜ -112.074  ‚îÇ\n",
       " ‚îÇ          ‚îÜ States      ‚îÜ             ‚îÜ Phoenix    ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ ‚Ä¶        ‚îÜ ‚Ä¶           ‚îÜ ‚Ä¶           ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÇ\n",
       " ‚îÇ 31       ‚îÜ Portugal    ‚îÜ Lisboa      ‚îÜ Store      ‚îÜ 10         ‚îÜ 1000-001 ‚îÜ 38.7167  ‚îÜ -9.1333   ‚îÇ\n",
       " ‚îÇ          ‚îÜ             ‚îÜ             ‚îÜ Lisboa     ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 32       ‚îÜ Portugal    ‚îÜ Porto       ‚îÜ Store      ‚îÜ 7          ‚îÜ 4000-001 ‚îÜ 41.1496  ‚îÜ -8.611    ‚îÇ\n",
       " ‚îÇ          ‚îÜ             ‚îÜ             ‚îÜ Porto      ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 33       ‚îÜ Portugal    ‚îÜ Braga       ‚îÜ Store      ‚îÜ 9          ‚îÜ 4700-001 ‚îÜ 41.5503  ‚îÜ -8.4201   ‚îÇ\n",
       " ‚îÇ          ‚îÜ             ‚îÜ             ‚îÜ Braga      ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 34       ‚îÜ Portugal    ‚îÜ Guimar√£es   ‚îÜ Store      ‚îÜ 9          ‚îÜ 4800-001 ‚îÜ 41.4444  ‚îÜ -8.2962   ‚îÇ\n",
       " ‚îÇ          ‚îÜ             ‚îÜ             ‚îÜ Guimar√£es  ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îÇ 35       ‚îÜ Portugal    ‚îÜ Coimbra     ‚îÜ Store      ‚îÜ 7          ‚îÜ 3000-001 ‚îÜ 40.2056  ‚îÜ -8.4196   ‚îÇ\n",
       " ‚îÇ          ‚îÜ             ‚îÜ             ‚îÜ Coimbra    ‚îÜ            ‚îÜ          ‚îÜ          ‚îÜ           ‚îÇ\n",
       " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò,\n",
       " shape: (1_643_306, 9)\n",
       " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       " ‚îÇ Customer   ‚îÜ Name       ‚îÜ Email     ‚îÜ Telephone ‚îÜ ‚Ä¶ ‚îÜ Country   ‚îÜ Gender ‚îÜ Date Of   ‚îÜ Job Title ‚îÇ\n",
       " ‚îÇ ID         ‚îÜ ---        ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ ---       ‚îÜ ---    ‚îÜ Birth     ‚îÜ ---       ‚îÇ\n",
       " ‚îÇ ---        ‚îÜ str        ‚îÜ str       ‚îÜ str       ‚îÜ   ‚îÜ str       ‚îÜ str    ‚îÜ ---       ‚îÜ str       ‚îÇ\n",
       " ‚îÇ i64        ‚îÜ            ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ str       ‚îÜ           ‚îÇ\n",
       " ‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       " ‚îÇ 1          ‚îÜ Tyler      ‚îÜ tyler.gar ‚îÜ 922.970.2 ‚îÜ ‚Ä¶ ‚îÜ United    ‚îÜ M      ‚îÜ 2003-07-1 ‚îÜ null      ‚îÇ\n",
       " ‚îÇ            ‚îÜ Garcia     ‚îÜ cia@fake_ ‚îÜ 265x47563 ‚îÜ   ‚îÜ States    ‚îÜ        ‚îÜ 5         ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ gmail.com ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 2          ‚îÜ Joshua     ‚îÜ joshua.mi ‚îÜ +1-958-72 ‚îÜ ‚Ä¶ ‚îÜ United    ‚îÜ M      ‚îÜ 2000-06-1 ‚îÜ Records   ‚îÇ\n",
       " ‚îÇ            ‚îÜ Miller     ‚îÜ ller@fake ‚îÜ 9-6169    ‚îÜ   ‚îÜ States    ‚îÜ        ‚îÜ 6         ‚îÜ manager   ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ _gmail.co ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ m         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 3          ‚îÜ Alison     ‚îÜ alison.ma ‚îÜ +1-645-56 ‚îÜ ‚Ä¶ ‚îÜ United    ‚îÜ F      ‚îÜ 2003-07-2 ‚îÜ null      ‚îÇ\n",
       " ‚îÇ            ‚îÜ Marshall   ‚îÜ rshall.dd ‚îÜ 7-0876x54 ‚îÜ   ‚îÜ States    ‚îÜ        ‚îÜ 2         ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ DDS        ‚îÜ s@fake_ho ‚îÜ 09        ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ tma‚Ä¶      ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 4          ‚îÜ Jeffery    ‚îÜ jeffery.a ‚îÜ 212.336.0 ‚îÜ ‚Ä¶ ‚îÜ United    ‚îÜ M      ‚îÜ 1996-11-1 ‚îÜ Proofread ‚îÇ\n",
       " ‚îÇ            ‚îÜ Acosta     ‚îÜ costa@fak ‚îÜ 912x84994 ‚îÜ   ‚îÜ States    ‚îÜ        ‚îÜ 2         ‚îÜ er        ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ e_yahoo.c ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ om        ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 5          ‚îÜ Ashley     ‚îÜ ashley.sa ‚îÜ 781453578 ‚îÜ ‚Ä¶ ‚îÜ United    ‚îÜ F      ‚îÜ 1998-02-1 ‚îÜ Exercise  ‚îÇ\n",
       " ‚îÇ            ‚îÜ Sanders    ‚îÜ nders@fak ‚îÜ 1         ‚îÜ   ‚îÜ States    ‚îÜ        ‚îÜ 0         ‚îÜ physiolog ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ e_hotmail ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ ist       ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ .co‚Ä¶      ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ ‚Ä¶          ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÇ\n",
       " ‚îÇ 1643302    ‚îÜ Bernardo   ‚îÜ bernardo. ‚îÜ (351)     ‚îÜ ‚Ä¶ ‚îÜ Portugal  ‚îÜ M      ‚îÜ 1973-02-2 ‚îÜ Structura ‚îÇ\n",
       " ‚îÇ            ‚îÜ Vicente    ‚îÜ vicente@f ‚îÜ 962314916 ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ 7         ‚îÜ l         ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ ake_hotma ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ engineer  ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ il.‚Ä¶      ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 1643303    ‚îÜ Luana      ‚îÜ luana.lei ‚îÜ (351) 288 ‚îÜ ‚Ä¶ ‚îÜ Portugal  ‚îÜ F      ‚îÜ 1997-02-0 ‚îÜ Futures   ‚îÇ\n",
       " ‚îÇ            ‚îÜ Leite      ‚îÜ te@fake_c ‚îÜ 728 807   ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ 5         ‚îÜ trader    ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ lix.pt    ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 1643304    ‚îÜ Ema        ‚îÜ ema.freit ‚îÜ +35191099 ‚îÜ ‚Ä¶ ‚îÜ Portugal  ‚îÜ F      ‚îÜ 2005-03-1 ‚îÜ null      ‚îÇ\n",
       " ‚îÇ            ‚îÜ Freitas    ‚îÜ as@fake_c ‚îÜ 0620      ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ 4         ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ lix.pt    ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 1643305    ‚îÜ Rafaela    ‚îÜ rafaela.c ‚îÜ +35193818 ‚îÜ ‚Ä¶ ‚îÜ Portugal  ‚îÜ F      ‚îÜ 1989-07-1 ‚îÜ Futures   ‚îÇ\n",
       " ‚îÇ            ‚îÜ Carneiro   ‚îÜ arneiro@f ‚îÜ 2129      ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ 4         ‚îÜ trader    ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ ake_clix. ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ pt        ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ 1643306    ‚îÜ Pilar da   ‚îÜ pilar.da. ‚îÜ (351) 938 ‚îÜ ‚Ä¶ ‚îÜ Portugal  ‚îÜ F      ‚îÜ 1978-12-2 ‚îÜ Garment/t ‚îÇ\n",
       " ‚îÇ            ‚îÜ Coelho     ‚îÜ coelho@fa ‚îÜ 886 805   ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ 2         ‚îÜ extile    ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ ke_hotmai ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ technolog ‚îÇ\n",
       " ‚îÇ            ‚îÜ            ‚îÜ l.c‚Ä¶      ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ        ‚îÜ           ‚îÜ ist       ‚îÇ\n",
       " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò,\n",
       " shape: (6_416_827, 19)\n",
       " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       " ‚îÇ Invoice ID ‚îÜ Line ‚îÜ Customer   ‚îÜ Product ID ‚îÜ ‚Ä¶ ‚îÜ SKU        ‚îÜ Transacti ‚îÜ Payment   ‚îÜ Invoice   ‚îÇ\n",
       " ‚îÇ ---        ‚îÜ ---  ‚îÜ ID         ‚îÜ ---        ‚îÜ   ‚îÜ ---        ‚îÜ on Type   ‚îÜ Method    ‚îÜ Total     ‚îÇ\n",
       " ‚îÇ str        ‚îÜ i64  ‚îÜ ---        ‚îÜ i64        ‚îÜ   ‚îÜ str        ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÇ\n",
       " ‚îÇ            ‚îÜ      ‚îÜ i64        ‚îÜ            ‚îÜ   ‚îÜ            ‚îÜ str       ‚îÜ str       ‚îÜ f64       ‚îÇ\n",
       " ‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       " ‚îÇ INV-US-001 ‚îÜ 1    ‚îÜ 47162      ‚îÜ 485        ‚îÜ ‚Ä¶ ‚îÜ MASU485-M- ‚îÜ Sale      ‚îÜ Cash      ‚îÜ 126.7     ‚îÇ\n",
       " ‚îÇ -03558761  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ            ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-US-001 ‚îÜ 2    ‚îÜ 47162      ‚îÜ 2779       ‚îÜ ‚Ä¶ ‚îÜ CHCO2779-G ‚îÜ Sale      ‚îÜ Cash      ‚îÜ 126.7     ‚îÇ\n",
       " ‚îÇ -03558761  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ -          ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-US-001 ‚îÜ 3    ‚îÜ 47162      ‚îÜ 64         ‚îÜ ‚Ä¶ ‚îÜ MACO64-M-N ‚îÜ Sale      ‚îÜ Cash      ‚îÜ 126.7     ‚îÇ\n",
       " ‚îÇ -03558761  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ EUTRAL     ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-US-001 ‚îÜ 1    ‚îÜ 10142      ‚îÜ 131        ‚îÜ ‚Ä¶ ‚îÜ FECO131-M- ‚îÜ Sale      ‚îÜ Cash      ‚îÜ 77.0      ‚îÇ\n",
       " ‚îÇ -03558762  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ BLUE       ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-US-001 ‚îÜ 2    ‚îÜ 10142      ‚îÜ 716        ‚îÜ ‚Ä¶ ‚îÜ MAT-716-L- ‚îÜ Sale      ‚îÜ Cash      ‚îÜ 77.0      ‚îÇ\n",
       " ‚îÇ -03558762  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ WHITE      ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       " ‚îÇ ‚Ä¶          ‚îÜ ‚Ä¶    ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÇ\n",
       " ‚îÇ INV-PT-035 ‚îÜ 2    ‚îÜ 1640168    ‚îÜ 15414      ‚îÜ ‚Ä¶ ‚îÜ CHGI15414- ‚îÜ Sale      ‚îÜ Credit    ‚îÜ 69.55     ‚îÇ\n",
       " ‚îÇ -01497756  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ P-         ‚îÜ           ‚îÜ Card      ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-PT-035 ‚îÜ 3    ‚îÜ 1640168    ‚îÜ 15232      ‚îÜ ‚Ä¶ ‚îÜ CHGI15232- ‚îÜ Sale      ‚îÜ Credit    ‚îÜ 69.55     ‚îÇ\n",
       " ‚îÇ -01497756  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ G-RED      ‚îÜ           ‚îÜ Card      ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-PT-035 ‚îÜ 1    ‚îÜ 1636770    ‚îÜ 15401      ‚îÜ ‚Ä¶ ‚îÜ FESP15401- ‚îÜ Sale      ‚îÜ Credit    ‚îÜ 40.0      ‚îÇ\n",
       " ‚îÇ -01497757  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ XL-        ‚îÜ           ‚îÜ Card      ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-PT-035 ‚îÜ 1    ‚îÜ 1642472    ‚îÜ 15671      ‚îÜ ‚Ä¶ ‚îÜ MAUN15671- ‚îÜ Sale      ‚îÜ Credit    ‚îÜ 36.5      ‚îÇ\n",
       " ‚îÇ -01497758  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ M-         ‚îÜ           ‚îÜ Card      ‚îÜ           ‚îÇ\n",
       " ‚îÇ INV-PT-035 ‚îÜ 1    ‚îÜ 1639026    ‚îÜ 17424      ‚îÜ ‚Ä¶ ‚îÜ FESH17424- ‚îÜ Sale      ‚îÜ Credit    ‚îÜ 16.57     ‚îÇ\n",
       " ‚îÇ -01497759  ‚îÜ      ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ M-         ‚îÜ           ‚îÜ Card      ‚îÜ           ‚îÇ\n",
       " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò,\n",
       " {'discounts': {'total_records': 181,\n",
       "   'total_columns': 6,\n",
       "   'columns': ['Start',\n",
       "    'End',\n",
       "    'Discont',\n",
       "    'Description',\n",
       "    'Category',\n",
       "    'Sub Category'],\n",
       "   'data_types': {'Start': 'String',\n",
       "    'End': 'String',\n",
       "    'Discont': 'Float64',\n",
       "    'Description': 'String',\n",
       "    'Category': 'String',\n",
       "    'Sub Category': 'String'},\n",
       "   'null_counts': {'Start': 0,\n",
       "    'End': 0,\n",
       "    'Discont': 0,\n",
       "    'Description': 0,\n",
       "    'Category': 10,\n",
       "    'Sub Category': 10},\n",
       "   'memory_usage_mb': 0.017075538635253906,\n",
       "   'numeric_summary': {'statistic': {0: 'count',\n",
       "     1: 'null_count',\n",
       "     2: 'mean',\n",
       "     3: 'std',\n",
       "     4: 'min',\n",
       "     5: '25%',\n",
       "     6: '50%',\n",
       "     7: '75%',\n",
       "     8: 'max'},\n",
       "    'Discont': {0: 181.0,\n",
       "     1: 0.0,\n",
       "     2: 0.3433701657458564,\n",
       "     3: 0.1036029868428037,\n",
       "     4: 0.2,\n",
       "     5: 0.25,\n",
       "     6: 0.35,\n",
       "     7: 0.4,\n",
       "     8: 0.6}}},\n",
       "  'products': {'total_records': 17940,\n",
       "   'total_columns': 12,\n",
       "   'columns': ['Product ID',\n",
       "    'Category',\n",
       "    'Sub Category',\n",
       "    'Description PT',\n",
       "    'Description DE',\n",
       "    'Description FR',\n",
       "    'Description ES',\n",
       "    'Description EN',\n",
       "    'Description ZH',\n",
       "    'Color',\n",
       "    'Sizes',\n",
       "    'Production Cost'],\n",
       "   'data_types': {'Product ID': 'Int64',\n",
       "    'Category': 'String',\n",
       "    'Sub Category': 'String',\n",
       "    'Description PT': 'String',\n",
       "    'Description DE': 'String',\n",
       "    'Description FR': 'String',\n",
       "    'Description ES': 'String',\n",
       "    'Description EN': 'String',\n",
       "    'Description ZH': 'String',\n",
       "    'Color': 'String',\n",
       "    'Sizes': 'String',\n",
       "    'Production Cost': 'Float64'},\n",
       "   'null_counts': {'Product ID': 0,\n",
       "    'Category': 0,\n",
       "    'Sub Category': 0,\n",
       "    'Description PT': 0,\n",
       "    'Description DE': 0,\n",
       "    'Description FR': 0,\n",
       "    'Description ES': 0,\n",
       "    'Description EN': 0,\n",
       "    'Description ZH': 0,\n",
       "    'Color': 12445,\n",
       "    'Sizes': 2070,\n",
       "    'Production Cost': 0},\n",
       "   'memory_usage_mb': 4.672783851623535,\n",
       "   'unique_categories': 3,\n",
       "   'category_distribution': [{'Category': 'Feminine', 'len': 7590},\n",
       "    {'Category': 'Masculine', 'len': 6210},\n",
       "    {'Category': 'Children', 'len': 4140}],\n",
       "   'price_summary': {'statistic': {0: 'count',\n",
       "     1: 'null_count',\n",
       "     2: 'mean',\n",
       "     3: 'std',\n",
       "     4: 'min',\n",
       "     5: '25%',\n",
       "     6: '50%',\n",
       "     7: '75%',\n",
       "     8: 'max'},\n",
       "    'Production Cost': {0: 17940.0,\n",
       "     1: 0.0,\n",
       "     2: 16.096188963210704,\n",
       "     3: 11.628072215331974,\n",
       "     4: 0.56,\n",
       "     5: 7.8,\n",
       "     6: 13.14,\n",
       "     7: 20.97,\n",
       "     8: 77.19}}},\n",
       "  'employees': {'total_records': 404,\n",
       "   'total_columns': 4,\n",
       "   'columns': ['Employee ID', 'Store ID', 'Name', 'Position'],\n",
       "   'data_types': {'Employee ID': 'Int64',\n",
       "    'Store ID': 'Int64',\n",
       "    'Name': 'String',\n",
       "    'Position': 'String'},\n",
       "   'null_counts': {'Employee ID': 0, 'Store ID': 0, 'Name': 0, 'Position': 0},\n",
       "   'memory_usage_mb': 0.017333984375,\n",
       "   'Position_distribution': [{'Position': 'Sales Associate', 'len': 264},\n",
       "    {'Position': 'Assistant Manager', 'len': 35},\n",
       "    {'Position': 'Store Manager', 'len': 35},\n",
       "    {'Position': 'Cashier', 'len': 35},\n",
       "    {'Position': 'Stock Clerk', 'len': 35}]},\n",
       "  'stores': {'total_records': 35,\n",
       "   'total_columns': 8,\n",
       "   'columns': ['Store ID',\n",
       "    'Country',\n",
       "    'City',\n",
       "    'Store Name',\n",
       "    'Number of Employees',\n",
       "    'ZIP Code',\n",
       "    'Latitude',\n",
       "    'Longitude'],\n",
       "   'data_types': {'Store ID': 'Int64',\n",
       "    'Country': 'String',\n",
       "    'City': 'String',\n",
       "    'Store Name': 'String',\n",
       "    'Number of Employees': 'Int64',\n",
       "    'ZIP Code': 'String',\n",
       "    'Latitude': 'Float64',\n",
       "    'Longitude': 'Float64'},\n",
       "   'null_counts': {'Store ID': 0,\n",
       "    'Country': 0,\n",
       "    'City': 0,\n",
       "    'Store Name': 0,\n",
       "    'Number of Employees': 0,\n",
       "    'ZIP Code': 0,\n",
       "    'Latitude': 0,\n",
       "    'Longitude': 0},\n",
       "   'memory_usage_mb': 0.0022535324096679688,\n",
       "   'Country_distribution': [{'Country': 'France', 'len': 5},\n",
       "    {'Country': 'United States', 'len': 5},\n",
       "    {'Country': 'Espa√±a', 'len': 5},\n",
       "    {'Country': 'Portugal', 'len': 5},\n",
       "    {'Country': 'United Kingdom', 'len': 5},\n",
       "    {'Country': 'Deutschland', 'len': 5},\n",
       "    {'Country': '‰∏≠ÂõΩ', 'len': 5}],\n",
       "   'City_distribution': [{'City': 'Lyon', 'len': 1},\n",
       "    {'City': 'Valencia', 'len': 1},\n",
       "    {'City': 'ÈáçÂ∫Ü', 'len': 1},\n",
       "    {'City': 'Sevilla', 'len': 1},\n",
       "    {'City': 'K√∂ln', 'len': 1},\n",
       "    {'City': 'Toulouse', 'len': 1},\n",
       "    {'City': 'London', 'len': 1},\n",
       "    {'City': 'ÂπøÂ∑û', 'len': 1},\n",
       "    {'City': 'Porto', 'len': 1},\n",
       "    {'City': 'Glasgow', 'len': 1},\n",
       "    {'City': 'Nice', 'len': 1},\n",
       "    {'City': 'Âåó‰∫¨', 'len': 1},\n",
       "    {'City': 'Lisboa', 'len': 1},\n",
       "    {'City': 'Madrid', 'len': 1},\n",
       "    {'City': 'M√ºnchen', 'len': 1},\n",
       "    {'City': 'Houston', 'len': 1},\n",
       "    {'City': 'Liverpool', 'len': 1},\n",
       "    {'City': 'Phoenix', 'len': 1},\n",
       "    {'City': 'Barcelona', 'len': 1},\n",
       "    {'City': 'Chicago', 'len': 1},\n",
       "    {'City': 'Hamburg', 'len': 1},\n",
       "    {'City': 'Coimbra', 'len': 1},\n",
       "    {'City': 'Marseille', 'len': 1},\n",
       "    {'City': 'Birmingham', 'len': 1},\n",
       "    {'City': 'Paris', 'len': 1},\n",
       "    {'City': 'New York', 'len': 1},\n",
       "    {'City': 'Braga', 'len': 1},\n",
       "    {'City': 'Ê∑±Âú≥', 'len': 1},\n",
       "    {'City': 'Los Angeles', 'len': 1},\n",
       "    {'City': 'Frankfurt am Main', 'len': 1},\n",
       "    {'City': 'Berlin', 'len': 1},\n",
       "    {'City': 'Zaragoza', 'len': 1},\n",
       "    {'City': 'Guimar√£es', 'len': 1},\n",
       "    {'City': '‰∏äÊµ∑', 'len': 1},\n",
       "    {'City': 'Bristol', 'len': 1}]},\n",
       "  'customers': {'total_records': 1643306,\n",
       "   'total_columns': 9,\n",
       "   'columns': ['Customer ID',\n",
       "    'Name',\n",
       "    'Email',\n",
       "    'Telephone',\n",
       "    'City',\n",
       "    'Country',\n",
       "    'Gender',\n",
       "    'Date Of Birth',\n",
       "    'Job Title'],\n",
       "   'data_types': {'Customer ID': 'Int64',\n",
       "    'Name': 'String',\n",
       "    'Email': 'String',\n",
       "    'Telephone': 'String',\n",
       "    'City': 'String',\n",
       "    'Country': 'String',\n",
       "    'Gender': 'String',\n",
       "    'Date Of Birth': 'String',\n",
       "    'Job Title': 'String'},\n",
       "   'null_counts': {'Customer ID': 0,\n",
       "    'Name': 0,\n",
       "    'Email': 0,\n",
       "    'Telephone': 0,\n",
       "    'City': 0,\n",
       "    'Country': 0,\n",
       "    'Gender': 0,\n",
       "    'Date Of Birth': 0,\n",
       "    'Job Title': 584185},\n",
       "   'memory_usage_mb': 169.70775318145752,\n",
       "   'City_distribution': [{'City': 'Ê∑±Âú≥', 'len': 60709},\n",
       "    {'City': 'Âåó‰∫¨', 'len': 51163},\n",
       "    {'City': 'New York', 'len': 50000},\n",
       "    {'City': 'Los Angeles', 'len': 45000},\n",
       "    {'City': '‰∏äÊµ∑', 'len': 42381},\n",
       "    {'City': 'Chicago', 'len': 40000},\n",
       "    {'City': 'Houston', 'len': 35000},\n",
       "    {'City': 'ÂπøÂ∑û', 'len': 33600},\n",
       "    {'City': 'Phoenix', 'len': 30000},\n",
       "    {'City': 'Berlin', 'len': 29000}],\n",
       "   'Country_distribution': [{'Country': 'United States', 'len': 354450},\n",
       "    {'Country': '‰∏≠ÂõΩ', 'len': 340082},\n",
       "    {'Country': 'Espa√±a', 'len': 237575},\n",
       "    {'Country': 'Deutschland', 'len': 205560},\n",
       "    {'Country': 'France', 'len': 196696},\n",
       "    {'Country': 'United Kingdom', 'len': 190574},\n",
       "    {'Country': 'Portugal', 'len': 118369}],\n",
       "   'Gender_distribution': [{'Gender': 'M', 'len': 964562},\n",
       "    {'Gender': 'F', 'len': 677041},\n",
       "    {'Gender': 'D', 'len': 1703}]},\n",
       "  'transactions': {'total_records': 6416827,\n",
       "   'total_columns': 19,\n",
       "   'columns': ['Invoice ID',\n",
       "    'Line',\n",
       "    'Customer ID',\n",
       "    'Product ID',\n",
       "    'Size',\n",
       "    'Color',\n",
       "    'Unit Price',\n",
       "    'Quantity',\n",
       "    'Date',\n",
       "    'Discount',\n",
       "    'Line Total',\n",
       "    'Store ID',\n",
       "    'Employee ID',\n",
       "    'Currency',\n",
       "    'Currency Symbol',\n",
       "    'SKU',\n",
       "    'Transaction Type',\n",
       "    'Payment Method',\n",
       "    'Invoice Total'],\n",
       "   'data_types': {'Invoice ID': 'String',\n",
       "    'Line': 'Int64',\n",
       "    'Customer ID': 'Int64',\n",
       "    'Product ID': 'Int64',\n",
       "    'Size': 'String',\n",
       "    'Color': 'String',\n",
       "    'Unit Price': 'Float64',\n",
       "    'Quantity': 'Int64',\n",
       "    'Date': 'String',\n",
       "    'Discount': 'Float64',\n",
       "    'Line Total': 'Float64',\n",
       "    'Store ID': 'Int64',\n",
       "    'Employee ID': 'Int64',\n",
       "    'Currency': 'String',\n",
       "    'Currency Symbol': 'String',\n",
       "    'SKU': 'String',\n",
       "    'Transaction Type': 'String',\n",
       "    'Payment Method': 'String',\n",
       "    'Invoice Total': 'Float64'},\n",
       "   'null_counts': {'Invoice ID': 0,\n",
       "    'Line': 0,\n",
       "    'Customer ID': 0,\n",
       "    'Product ID': 0,\n",
       "    'Size': 413102,\n",
       "    'Color': 4350783,\n",
       "    'Unit Price': 0,\n",
       "    'Quantity': 0,\n",
       "    'Date': 0,\n",
       "    'Discount': 0,\n",
       "    'Line Total': 0,\n",
       "    'Store ID': 0,\n",
       "    'Employee ID': 0,\n",
       "    'Currency': 0,\n",
       "    'Currency Symbol': 0,\n",
       "    'SKU': 0,\n",
       "    'Transaction Type': 0,\n",
       "    'Payment Method': 0,\n",
       "    'Invoice Total': 0},\n",
       "   'memory_usage_mb': 936.6401176452637,\n",
       "   'financial_summary': {'statistic': {0: 'count',\n",
       "     1: 'null_count',\n",
       "     2: 'mean',\n",
       "     3: 'std',\n",
       "     4: 'min',\n",
       "     5: '25%',\n",
       "     6: '50%',\n",
       "     7: '75%',\n",
       "     8: 'max'},\n",
       "    'Unit Price': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 132.4640200600702,\n",
       "     3: 185.0971221528057,\n",
       "     4: 2.0,\n",
       "     5: 32.5,\n",
       "     6: 51.0,\n",
       "     7: 116.5,\n",
       "     8: 1153.5},\n",
       "    'Quantity': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 1.1002433134008445,\n",
       "     3: 0.39637920769696927,\n",
       "     4: 1.0,\n",
       "     5: 1.0,\n",
       "     6: 1.0,\n",
       "     7: 1.0,\n",
       "     8: 3.0},\n",
       "    'Line Total': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 114.19115319612014,\n",
       "     3: 211.5864597028735,\n",
       "     4: -3348.0,\n",
       "     5: 24.75,\n",
       "     6: 43.5,\n",
       "     7: 109.0,\n",
       "     8: 3460.5},\n",
       "    'Invoice Total': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 243.5266428205093,\n",
       "     3: 536.733823248412,\n",
       "     4: -6750.5,\n",
       "     5: 34.02,\n",
       "     6: 83.5,\n",
       "     7: 241.0,\n",
       "     8: 8977.0}},\n",
       "   'Date_range': {'min_date': '2023-01-01 00:00:00',\n",
       "    'max_date': '2025-03-18 20:59:00',\n",
       "    'unique_dates': 608986},\n",
       "   'unique_customer_id': 1283707,\n",
       "   'unique_product_id': 17940,\n",
       "   'unique_store_id': 35,\n",
       "   'unique_employee_id': 264},\n",
       "  'overall': {'total_datasets': 6,\n",
       "   'total_records_across_all': 8078693,\n",
       "   'total_memory_usage_mb': 1111.0573177337646,\n",
       "   'analysis_timestamp': '2025-07-27T15:58:46.889335'}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_descriptive_statistics(discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl):\n",
    "    \"\"\"\n",
    "    Perform comprehensive descriptive statistics on all datasets\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä PERFORMING DESCRIPTIVE STATISTICS ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create output directory\n",
    "    stats_dir = \"descriptive_statistics\"\n",
    "    os.makedirs(stats_dir, exist_ok=True)\n",
    "    \n",
    "    stats_summary = {}\n",
    "    \n",
    "    # 1. DISCOUNTS DATASET ANALYSIS\n",
    "    print(\"\\nüè∑Ô∏è DISCOUNTS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    discounts_stats = {\n",
    "        'total_records': discounts_pl.shape[0],\n",
    "        'total_columns': discounts_pl.shape[1],\n",
    "        'columns': discounts_pl.columns,\n",
    "        'data_types': dict(zip(discounts_pl.columns, [str(dtype) for dtype in discounts_pl.dtypes])),\n",
    "        'null_counts': discounts_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': discounts_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Numeric columns analysis for discounts\n",
    "    numeric_cols = discounts_pl.select(pl.col(pl.NUMERIC_DTYPES)).columns\n",
    "    if numeric_cols:\n",
    "        discounts_stats['numeric_summary'] = discounts_pl.select(numeric_cols).describe().to_pandas().to_dict()\n",
    "    \n",
    "    stats_summary['discounts'] = discounts_stats\n",
    "    \n",
    "    print(f\"   üìã Records: {discounts_stats['total_records']:,}\")\n",
    "    print(f\"   üìä Columns: {discounts_stats['total_columns']}\")\n",
    "    print(f\"   üíæ Memory: {discounts_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 2. PRODUCTS DATASET ANALYSIS\n",
    "    print(\"\\nüì¶ PRODUCTS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    products_stats = {\n",
    "        'total_records': products_pl.shape[0],\n",
    "        'total_columns': products_pl.shape[1],\n",
    "        'columns': products_pl.columns,\n",
    "        'data_types': dict(zip(products_pl.columns, [str(dtype) for dtype in products_pl.dtypes])),\n",
    "        'null_counts': products_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': products_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Unique categories/brands analysis\n",
    "    if 'Category' in products_pl.columns:\n",
    "        products_stats['unique_categories'] = products_pl['Category'].n_unique()\n",
    "        products_stats['category_distribution'] = products_pl.group_by('Category').len().sort('len', descending=True).to_pandas().to_dict('records')\n",
    "    \n",
    "    # Price analysis if available\n",
    "    price_cols = [col for col in products_pl.columns if 'price' in col.lower() or 'cost' in col.lower()]\n",
    "    if price_cols:\n",
    "        products_stats['price_summary'] = products_pl.select(price_cols).describe().to_pandas().to_dict()\n",
    "    \n",
    "    stats_summary['products'] = products_stats\n",
    "    \n",
    "    print(f\"   üìã Records: {products_stats['total_records']:,}\")\n",
    "    print(f\"   üìä Columns: {products_stats['total_columns']}\")\n",
    "    print(f\"   üíæ Memory: {products_stats['memory_usage_mb']:.2f} MB\")\n",
    "    if 'unique_categories' in products_stats:\n",
    "        print(f\"   üè∑Ô∏è Categories: {products_stats['unique_categories']}\")\n",
    "    \n",
    "    # 3. EMPLOYEES DATASET ANALYSIS\n",
    "    print(\"\\nüë• EMPLOYEES Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    employees_stats = {\n",
    "        'total_records': employees_pl.shape[0],\n",
    "        'total_columns': employees_pl.shape[1],\n",
    "        'columns': employees_pl.columns,\n",
    "        'data_types': dict(zip(employees_pl.columns, [str(dtype) for dtype in employees_pl.dtypes])),\n",
    "        'null_counts': employees_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': employees_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Department/Role analysis if available\n",
    "    dept_cols = [col for col in employees_pl.columns if any(keyword in col.lower() for keyword in ['department', 'role', 'position', 'title'])]\n",
    "    for col in dept_cols:\n",
    "        employees_stats[f'{col}_distribution'] = employees_pl.group_by(col).len().sort('len', descending=True).to_pandas().to_dict('records')\n",
    "    \n",
    "    stats_summary['employees'] = employees_stats\n",
    "    \n",
    "    print(f\"   üìã Records: {employees_stats['total_records']:,}\")\n",
    "    print(f\"   üìä Columns: {employees_stats['total_columns']}\")\n",
    "    print(f\"   üíæ Memory: {employees_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 4. STORES DATASET ANALYSIS\n",
    "    print(\"\\nüè™ STORES Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    stores_stats = {\n",
    "        'total_records': stores_pl.shape[0],\n",
    "        'total_columns': stores_pl.shape[1],\n",
    "        'columns': stores_pl.columns,\n",
    "        'data_types': dict(zip(stores_pl.columns, [str(dtype) for dtype in stores_pl.dtypes])),\n",
    "        'null_counts': stores_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': stores_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Location analysis if available\n",
    "    location_cols = [col for col in stores_pl.columns if any(keyword in col.lower() for keyword in ['city', 'state', 'country', 'region'])]\n",
    "    for col in location_cols:\n",
    "        if col in stores_pl.columns:\n",
    "            stores_stats[f'{col}_distribution'] = stores_pl.group_by(col).len().sort('len', descending=True).to_pandas().to_dict('records')\n",
    "    \n",
    "    stats_summary['stores'] = stores_stats\n",
    "    \n",
    "    print(f\"   üìã Records: {stores_stats['total_records']:,}\")\n",
    "    print(f\"   üìä Columns: {stores_stats['total_columns']}\")\n",
    "    print(f\"   üíæ Memory: {stores_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 5. CUSTOMERS DATASET ANALYSIS\n",
    "    print(\"\\nüë§ CUSTOMERS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    customers_stats = {\n",
    "        'total_records': customers_pl.shape[0],\n",
    "        'total_columns': customers_pl.shape[1],\n",
    "        'columns': customers_pl.columns,\n",
    "        'data_types': dict(zip(customers_pl.columns, [str(dtype) for dtype in customers_pl.dtypes])),\n",
    "        'null_counts': customers_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': customers_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Demographics analysis\n",
    "    demo_cols = [col for col in customers_pl.columns if any(keyword in col.lower() for keyword in ['gender', 'age', 'city', 'state', 'country'])]\n",
    "    for col in demo_cols:\n",
    "        if col in customers_pl.columns:\n",
    "            customers_stats[f'{col}_distribution'] = customers_pl.group_by(col).len().sort('len', descending=True).head(10).to_pandas().to_dict('records')\n",
    "    \n",
    "    stats_summary['customers'] = customers_stats\n",
    "    \n",
    "    print(f\"   üìã Records: {customers_stats['total_records']:,}\")\n",
    "    print(f\"   üìä Columns: {customers_stats['total_columns']}\")\n",
    "    print(f\"   üíæ Memory: {customers_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 6. TRANSACTIONS DATASET ANALYSIS (Most Important)\n",
    "    print(\"\\nüí≥ TRANSACTIONS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    transactions_stats = {\n",
    "        'total_records': transactions_pl.shape[0],\n",
    "        'total_columns': transactions_pl.shape[1],\n",
    "        'columns': transactions_pl.columns,\n",
    "        'data_types': dict(zip(transactions_pl.columns, [str(dtype) for dtype in transactions_pl.dtypes])),\n",
    "        'null_counts': transactions_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': transactions_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Financial metrics\n",
    "    financial_cols = [col for col in transactions_pl.columns if any(keyword in col.lower() for keyword in ['amount', 'total', 'price', 'cost', 'revenue', 'quantity'])]\n",
    "    if financial_cols:\n",
    "        transactions_stats['financial_summary'] = transactions_pl.select(financial_cols).describe().to_pandas().to_dict()\n",
    "    \n",
    "    # Date range analysis\n",
    "    date_cols = [col for col in transactions_pl.columns if any(keyword in col.lower() for keyword in ['date', 'time'])]\n",
    "    for col in date_cols:\n",
    "        if col in transactions_pl.columns:\n",
    "            try:\n",
    "                date_stats = transactions_pl.select([\n",
    "                    pl.col(col).min().alias('min_date'),\n",
    "                    pl.col(col).max().alias('max_date'),\n",
    "                    pl.col(col).n_unique().alias('unique_dates')\n",
    "                ]).to_pandas().iloc[0].to_dict()\n",
    "                transactions_stats[f'{col}_range'] = date_stats\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Unique counts for key columns\n",
    "    key_cols = ['Customer ID', 'Product ID', 'Store ID', 'Employee ID']\n",
    "    for col in key_cols:\n",
    "        if col in transactions_pl.columns:\n",
    "            transactions_stats[f'unique_{col.lower().replace(\" \", \"_\")}'] = transactions_pl[col].n_unique()\n",
    "    \n",
    "    stats_summary['transactions'] = transactions_stats\n",
    "    \n",
    "    print(f\"   üìã Records: {transactions_stats['total_records']:,}\")\n",
    "    print(f\"   üìä Columns: {transactions_stats['total_columns']}\")\n",
    "    print(f\"   üíæ Memory: {transactions_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 7. OVERALL SUMMARY\n",
    "    print(\"\\nüìà OVERALL DATA SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_records = sum([stats['total_records'] for stats in stats_summary.values()])\n",
    "    total_memory = sum([stats['memory_usage_mb'] for stats in stats_summary.values()])\n",
    "    \n",
    "    overall_stats = {\n",
    "        'total_datasets': len(stats_summary),\n",
    "        'total_records_across_all': total_records,\n",
    "        'total_memory_usage_mb': total_memory,\n",
    "        'analysis_timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    stats_summary['overall'] = overall_stats\n",
    "    \n",
    "    print(f\"   üìä Total Datasets: {overall_stats['total_datasets']}\")\n",
    "    print(f\"   üìã Total Records: {overall_stats['total_records_across_all']:,}\")\n",
    "    print(f\"   üíæ Total Memory: {overall_stats['total_memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 8. SAVE RESULTS\n",
    "    print(f\"\\nüíæ Saving descriptive statistics...\")\n",
    "    \n",
    "    # Save as JSON\n",
    "    import json\n",
    "    with open(f\"{stats_dir}/descriptive_statistics_summary.json\", 'w') as f:\n",
    "        json.dump(stats_summary, f, indent=2, default=str)\n",
    "    \n",
    "    # Save detailed CSV reports for each dataset\n",
    "    for dataset_name, stats in stats_summary.items():\n",
    "        if dataset_name != 'overall':\n",
    "            stats_df = pd.DataFrame([stats])\n",
    "            stats_df.to_csv(f\"{stats_dir}/{dataset_name}_statistics.csv\", index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Descriptive statistics completed!\")\n",
    "    print(f\"üìÅ Results saved in: {stats_dir}/\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return stats_summary\n",
    "\n",
    "# Usage in your main function:\n",
    "def load_data_and_analyze():\n",
    "    \"\"\"Load data and perform descriptive statistics\"\"\"\n",
    "    \n",
    "    # Load data (your existing function)\n",
    "    discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl = load_data_efficiently()\n",
    "    \n",
    "    # Perform descriptive statistics\n",
    "    stats_summary = perform_descriptive_statistics(\n",
    "        discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl\n",
    "    )\n",
    "    \n",
    "    return discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl, stats_summary\n",
    "\n",
    "load_data_and_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b773a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating master dataset...\n",
      "üìä Loading data efficiently...\n",
      "Loading discounts...\n",
      "Loading products...\n",
      "Loading employees...\n",
      "Loading stores...\n",
      "Loading customers...\n",
      "Loading transactions (this may take a moment)...\n",
      "Converting to Polars for better performance...\n",
      "‚úÖ Data loaded successfully!\n",
      "Transactions shape: (6416827, 19)\n",
      "üîß Preparing optimized lookup tables...\n",
      "üóìÔ∏è Converting date columns to YYYY-MM-DD format: ['Start', 'End']\n",
      "‚úÖ Converted Start to YYYY-MM-DD date format\n",
      "‚úÖ Converted End to YYYY-MM-DD date format\n",
      "üóìÔ∏è Converting date columns to YYYY-MM-DD format: ['Date Of Birth']\n",
      "‚úÖ Converted Date Of Birth to YYYY-MM-DD date format\n",
      "‚úÖ Lookup tables prepared\n",
      "üí∞ Processing transactions...\n",
      "üóìÔ∏è Converting date columns to YYYY-MM-DD format: ['Date']\n",
      "‚úÖ Converted Date to YYYY-MM-DD date format\n",
      "üí± Adding USD conversion...\n",
      "‚úÖ Created Unit_Price_USD\n",
      "‚úÖ Created Line_Total_USD\n",
      "‚úÖ Created Invoice_Total_USD\n",
      "üîó Merging tables...\n",
      "‚úÖ Merged with products. Shape: (6416827, 29)\n",
      "‚úÖ Merged with customers. Shape: (6416827, 34)\n",
      "‚úÖ Merged with stores. Shape: (6416827, 38)\n",
      "‚úÖ Merged with employees. Shape: (6416827, 41)\n",
      "üíæ Saving lookup tables...\n",
      "üíæ Saving master dataset...\n",
      "‚úÖ Master dataset created successfully!\n",
      "Final shape: (6416827, 41)\n",
      "Memory usage optimized by keeping only essential columns from lookup tables\n"
     ]
    }
   ],
   "source": [
    "master_data, discounts_lookup = create_master_dataset()\n",
    "# final_data = show_dataset_summary(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6e1497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6416827, 41)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58fe1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 =master_data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ad8213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6416029, 41)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cea357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading customers...\n"
     ]
    }
   ],
   "source": [
    "# Intial Transactions loaded: 6416827 rows\n",
    "import pandas as pd\n",
    "print(\"Loading customers...\")\n",
    "customers = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\transactions.csv', low_memory=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0bc0cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283707"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers['Customer ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c0970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
