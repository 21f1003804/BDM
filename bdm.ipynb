{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3492c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.offline as pyo\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import polars as pl\n",
    "# import gc\n",
    "\n",
    "# # Load and prepare data\n",
    "# transactions = pd.read_parquet(\"../data/transactions_cleaned.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94174ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Standardize column names for consistency\n",
    "# column_mapping = {\n",
    "#     'Store Country': 'Store_Country',\n",
    "#     'Store City': 'Store_City', \n",
    "#     'Employee ID': 'Employee_ID',\n",
    "#     'Customer ID': 'Customer_ID',\n",
    "#     'Product ID': 'Product_ID',\n",
    "#     'Invoice USD': 'Invoice_USD',\n",
    "#     'Unit Price': 'Unit_Price'\n",
    "# }\n",
    "\n",
    "# # Apply column mapping if columns exist\n",
    "# for old_name, new_name in column_mapping.items():\n",
    "#     if old_name in transactions.columns:\n",
    "#         transactions.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "# # Data preparation and cleaning\n",
    "# def prepare_data():\n",
    "#     \"\"\"Prepare and clean all datasets for analysis\"\"\"\n",
    "    \n",
    "#     # Geographic Sales Data\n",
    "#     geo_sales = (\n",
    "#         transactions\n",
    "#         .dropna(subset=['Store_Country', 'Store_City', 'Latitude', 'Longitude', 'Invoice_USD'])\n",
    "#         .groupby(['Store_Country', 'Store_City', 'Latitude', 'Longitude'], as_index=False)\n",
    "#         .agg({'Invoice_USD': 'sum'})\n",
    "#         .rename(columns={'Invoice_USD': 'Total_Sales_USD'})\n",
    "#     )\n",
    "#     geo_sales.to_csv(\"data/geo_sales_summary.csv\", index=False)\n",
    "    \n",
    "#     # Employee Performance Data\n",
    "#     employee_perf = transactions.groupby(\"Employee_ID\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     employee_perf[\"Avg_Price\"] = employee_perf[\"Total_Sales\"] / employee_perf[\"Total_Quantity\"]\n",
    "#     employee_perf = employee_perf[employee_perf[\"Total_Quantity\"] >= 5]  # Filter minimum activity\n",
    "#     employee_perf.to_csv(\"data/employee_performance.csv\", index=False)\n",
    "    \n",
    "#     # Country Performance Data\n",
    "#     country_perf = transactions.groupby(\"Store_Country\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     country_perf[\"Avg_Price\"] = country_perf[\"Total_Sales\"] / country_perf[\"Total_Quantity\"]\n",
    "#     country_perf.to_csv(\"data/country_performance.csv\", index=False)\n",
    "    \n",
    "#     # City Performance Data\n",
    "#     city_perf = transactions.groupby(\"Store_City\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     city_perf[\"Avg_Price\"] = city_perf[\"Total_Sales\"] / city_perf[\"Total_Quantity\"]\n",
    "#     city_perf.to_csv(\"data/city_performance.csv\", index=False)\n",
    "    \n",
    "#     # Customer Performance Data\n",
    "#     customer_perf = transactions.groupby(\"Customer_ID\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     customer_perf[\"Avg_Price\"] = customer_perf[\"Total_Sales\"] / customer_perf[\"Total_Quantity\"]\n",
    "#     customer_perf = customer_perf[\n",
    "#         (customer_perf[\"Total_Quantity\"] > 0) &\n",
    "#         (customer_perf[\"Total_Sales\"] > 0) &\n",
    "#         customer_perf[\"Avg_Price\"].notna()\n",
    "#     ]\n",
    "#     customer_perf.to_csv(\"data/customer_performance.csv\", index=False)\n",
    "    \n",
    "#     # Product Performance Data\n",
    "#     product_perf = transactions.groupby(\"Product_ID\", as_index=False).agg(\n",
    "#         Total_Sales=(\"Invoice_USD\", \"sum\"),\n",
    "#         Total_Quantity=(\"Quantity\", \"sum\"),\n",
    "#         Transaction_Count=(\"Invoice_USD\", \"count\")\n",
    "#     )\n",
    "#     product_perf[\"Avg_Price\"] = product_perf[\"Total_Sales\"] / product_perf[\"Total_Quantity\"]\n",
    "#     product_perf = product_perf[\n",
    "#         (product_perf[\"Total_Quantity\"] > 0) &\n",
    "#         (product_perf[\"Total_Sales\"] > 0) &\n",
    "#         product_perf[\"Avg_Price\"].notna()\n",
    "#     ]\n",
    "#     product_perf.to_csv(\"data/product_performance.csv\", index=False)\n",
    "    \n",
    "#     # Discount Analysis Data\n",
    "#     transactions['Net_Revenue'] = transactions['Quantity'] * (\n",
    "#         transactions['Unit_Price'] * (1 - transactions['Discount'])\n",
    "#     )\n",
    "    \n",
    "#     discount_analysis = transactions.groupby('Product_ID').agg(\n",
    "#         Avg_Discount=('Discount', 'mean'),\n",
    "#         Total_Quantity=('Quantity', 'sum'),\n",
    "#         Net_Revenue=('Net_Revenue', 'sum'),\n",
    "#         Total_Sales=('Invoice_USD', 'sum')\n",
    "#     ).reset_index()\n",
    "#     discount_analysis.to_csv(\"data/discount_analysis.csv\", index=False)\n",
    "    \n",
    "#     # Customer Segmentation (RFM Analysis)\n",
    "#     # Assuming we have date column for recency calculation\n",
    "#     if 'Date' in transactions.columns:\n",
    "#         current_date = transactions['Date'].max()\n",
    "#         rfm_data = transactions.groupby('Customer_ID').agg(\n",
    "#             Recency=('Date', lambda x: (current_date - x.max()).days),\n",
    "#             Frequency=('Invoice_USD', 'count'),\n",
    "#             Monetary=('Invoice_USD', 'sum')\n",
    "#         ).reset_index()\n",
    "        \n",
    "#         # RFM Scoring\n",
    "#         rfm_data['R_Score'] = pd.qcut(rfm_data['Recency'], 5, labels=[5,4,3,2,1])\n",
    "#         rfm_data['F_Score'] = pd.qcut(rfm_data['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "#         rfm_data['M_Score'] = pd.qcut(rfm_data['Monetary'], 5, labels=[1,2,3,4,5])\n",
    "#         rfm_data['RFM_Score'] = rfm_data['R_Score'].astype(str) + rfm_data['F_Score'].astype(str) + rfm_data['M_Score'].astype(str)\n",
    "        \n",
    "#         # Customer Segments\n",
    "#         def segment_customers(row):\n",
    "#             if row['RFM_Score'] in ['555', '554', '544', '545', '454', '455', '445']:\n",
    "#                 return 'Champions'\n",
    "#             elif row['RFM_Score'] in ['543', '444', '435', '355', '354', '345', '344', '335']:\n",
    "#                 return 'Loyal Customers'\n",
    "#             elif row['RFM_Score'] in ['512', '511', '422', '421', '412', '411', '311']:\n",
    "#                 return 'Potential Loyalists'\n",
    "#             elif row['RFM_Score'] in ['533', '532', '531', '523', '522', '521', '515', '514', '513', '425', '424', '413', '414', '415', '315', '314', '313']:\n",
    "#                 return 'New Customers'\n",
    "#             elif row['RFM_Score'] in ['155', '154', '144', '214', '215', '115', '114']:\n",
    "#                 return 'At Risk'\n",
    "#             elif row['RFM_Score'] in ['255', '254', '245', '244', '253', '252', '243', '242', '235', '234', '225', '224', '153', '152', '145', '143', '142', '135', '134', '125', '124']:\n",
    "#                 return 'Cannot Lose Them'\n",
    "#             else:\n",
    "#                 return 'Others'\n",
    "        \n",
    "#         rfm_data['Customer_Segment'] = rfm_data.apply(segment_customers, axis=1)\n",
    "#         rfm_data.to_csv(\"data/rfm_analysis.csv\", index=False)\n",
    "    \n",
    "#     print(\"âœ… All data preparation completed successfully!\")\n",
    "\n",
    "# # Execute data preparation\n",
    "# prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# from datetime import datetime, timedelta\n",
    "# import gc\n",
    "# import os\n",
    "\n",
    "# # Create data directory if it doesn't exist\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# # Load data with Polars for better memory efficiency\n",
    "# print(\"ğŸ“Š Loading data with Polars for memory efficiency...\")\n",
    "# # transactions_pl = pl.read_parquet(\"data/transactions_cleaned.parquet\")\n",
    "# transactions_pl = pl.from_pandas(transactions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5119b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Optimized Data Pipeline...\n",
      "ğŸ—ï¸ Creating master dataset...\n",
      "ğŸ“Š Loading data efficiently...\n",
      "Loading discounts...\n",
      "Loading products...\n",
      "Loading employees...\n",
      "Loading stores...\n",
      "Loading customers...\n",
      "Loading transactions (this may take a moment)...\n",
      "Intial Transactions loaded: 6416827 rows\n",
      "Final Transactions loaded: 6416029 rows\n",
      "Converting to Polars for better performance...\n",
      "âœ… Data loaded successfully!\n",
      "Transactions shape: (6416029, 19)\n",
      "ğŸ”§ Preparing optimized lookup tables...\n",
      "ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: ['Start', 'End']\n",
      "âœ… Converted Start to YYYY-MM-DD date format\n",
      "âœ… Converted End to YYYY-MM-DD date format\n",
      "ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: ['Date Of Birth']\n",
      "âœ… Converted Date Of Birth to YYYY-MM-DD date format\n",
      "âœ… Lookup tables prepared\n",
      "ğŸ’° Processing transactions...\n",
      "ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: ['Date']\n",
      "âœ… Converted Date to YYYY-MM-DD date format\n",
      "ğŸ’± Adding USD conversion...\n",
      "âœ… Created Unit_Price_USD\n",
      "âœ… Created Line_Total_USD\n",
      "âœ… Created Invoice_Total_USD\n",
      "ğŸ”— Merging tables...\n",
      "âœ… Merged with products. Shape: (6416029, 29)\n",
      "âœ… Merged with customers. Shape: (6416029, 34)\n",
      "âœ… Merged with stores. Shape: (6416029, 38)\n",
      "âœ… Merged with employees. Shape: (6416029, 41)\n",
      "ğŸ’¾ Saving lookup tables...\n",
      "ğŸ’¾ Saving master dataset...\n",
      "âœ… Master dataset created successfully!\n",
      "Final shape: (6416029, 41)\n",
      "Memory usage optimized by keeping only essential columns from lookup tables\n",
      "\n",
      "ğŸ“Š MASTER DATASET SUMMARY:\n",
      "Shape: (6416029, 41)\n",
      "Columns: 41\n",
      "\n",
      "ğŸ“‹ Column List:\n",
      " 1. Invoice ID\n",
      " 2. Line\n",
      " 3. Customer ID\n",
      " 4. Product ID\n",
      " 5. Size\n",
      " 6. Color\n",
      " 7. Unit Price\n",
      " 8. Quantity\n",
      " 9. Date\n",
      "10. Discount\n",
      "11. Line Total\n",
      "12. Store ID\n",
      "13. Employee ID\n",
      "14. Currency\n",
      "15. Currency Symbol\n",
      "16. SKU\n",
      "17. Transaction Type\n",
      "18. Payment Method\n",
      "19. Invoice Total\n",
      "20. Exchange_Rate_to_USD\n",
      "21. Unit_Price_USD\n",
      "22. Line_Total_USD\n",
      "23. Invoice_Total_USD\n",
      "24. Category\n",
      "25. Sub Category\n",
      "26. Description EN\n",
      "27. Color_right\n",
      "28. Sizes\n",
      "29. Production Cost\n",
      "30. Name\n",
      "31. Email\n",
      "32. Gender\n",
      "33. Date Of Birth\n",
      "34. Job Title\n",
      "35. Country\n",
      "36. City\n",
      "37. Store Name\n",
      "38. Number of Employees\n",
      "39. Store ID_right\n",
      "40. Name_right\n",
      "41. Position\n",
      "\n",
      "ğŸ’° USD Converted Columns:\n",
      "   â€¢ Exchange_Rate_to_USD\n",
      "   â€¢ Unit_Price_USD\n",
      "   â€¢ Line_Total_USD\n",
      "   â€¢ Invoice_Total_USD\n",
      "\n",
      "ğŸ—“ï¸ Date Columns (YYYY-MM-DD format):\n",
      "   â€¢ Date\n",
      "     Sample: [datetime.date(2023, 1, 1), datetime.date(2023, 1, 1), datetime.date(2023, 1, 1)]\n",
      "   â€¢ Date Of Birth\n",
      "     Sample: [datetime.date(1983, 12, 25), datetime.date(1983, 12, 25), datetime.date(1983, 12, 25)]\n",
      "\n",
      "ğŸ“ˆ Sample Data:\n",
      "shape: (3, 41)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Invoice ID â”† Line â”† Customer   â”† Product ID â”† â€¦ â”† Number of  â”† Store     â”† Name_righ â”† Position  â”‚\n",
      "â”‚ ---        â”† ---  â”† ID         â”† ---        â”†   â”† Employees  â”† ID_right  â”† t         â”† ---       â”‚\n",
      "â”‚ str        â”† i64  â”† ---        â”† i64        â”†   â”† ---        â”† ---       â”† ---       â”† str       â”‚\n",
      "â”‚            â”†      â”† i64        â”†            â”†   â”† i64        â”† i64       â”† str       â”†           â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ INV-US-001 â”† 1    â”† 47162      â”† 485        â”† â€¦ â”† 10         â”† 1         â”† Melissa   â”† Sales     â”‚\n",
      "â”‚ -03558761  â”†      â”†            â”†            â”†   â”†            â”†           â”† Wilson    â”† Associate â”‚\n",
      "â”‚ INV-US-001 â”† 2    â”† 47162      â”† 2779       â”† â€¦ â”† 10         â”† 1         â”† Melissa   â”† Sales     â”‚\n",
      "â”‚ -03558761  â”†      â”†            â”†            â”†   â”†            â”†           â”† Wilson    â”† Associate â”‚\n",
      "â”‚ INV-US-001 â”† 3    â”† 47162      â”† 64         â”† â€¦ â”† 10         â”† 1         â”† Melissa   â”† Sales     â”‚\n",
      "â”‚ -03558761  â”†      â”†            â”†            â”†   â”†            â”†           â”† Wilson    â”† Associate â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "âœ… Pipeline Complete!\n",
      "Files saved:\n",
      "   â€¢ data/master_transactions.parquet (main dataset)\n",
      "   â€¢ data/master_transactions_sample.csv (sample for inspection)\n",
      "   â€¢ data/discounts_lookup.parquet (for discount analysis)\n",
      "   â€¢ data/products_lookup.parquet\n",
      "   â€¢ data/employees_lookup.parquet\n",
      "   â€¢ data/stores_lookup.parquet\n",
      "   â€¢ data/customers_lookup.parquet\n",
      "\n",
      "ğŸ“… All dates are now in simple YYYY-MM-DD format!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Exchange rates you provided\n",
    "exchange_rates = {\n",
    "    'EUR': 1.13,\n",
    "    'GBP': 1.34,\n",
    "    'CNY': 0.14,\n",
    "    'USD': 1.0\n",
    "}\n",
    "\n",
    "city_translation_map = {\n",
    "\n",
    "}\n",
    "\n",
    "country_translation_map = {\n",
    "    'ä¸­å›½': 'China',\n",
    "    'EspaÃ±a': 'Spain',\n",
    "    'Portugal': 'Portugal',\n",
    "    'Deutschland': 'Germany',\n",
    "    'France': 'France',\n",
    "    'United Kingdom': 'United Kingdom',\n",
    "    'United States': 'United States'\n",
    "}\n",
    "\n",
    "def load_data_efficiently():\n",
    "    \"\"\"Load data with optimized memory usage\"\"\"\n",
    "    print(\"ğŸ“Š Loading data efficiently...\")\n",
    "    \n",
    "    # Load with pandas first, then convert to polars for better performance\n",
    "    print(\"Loading discounts...\")\n",
    "    discounts = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\discounts.csv')\n",
    "    \n",
    "    print(\"Loading products...\")\n",
    "    products = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\products.csv')\n",
    "    \n",
    "    print(\"Loading employees...\")\n",
    "    employees = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\employees.csv')\n",
    "    \n",
    "    print(\"Loading stores...\")\n",
    "    stores = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\stores.csv')\n",
    "    \n",
    "    print(\"Loading customers...\")\n",
    "    customers = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\customers.csv', low_memory=False)\n",
    "    \n",
    "    print(\"Loading transactions (this may take a moment)...\")\n",
    "    transactions = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\transactions.csv', low_memory=False)\n",
    "    print(f\"Intial Transactions loaded: {len(transactions)} rows\")\n",
    "    transactions=transactions.drop_duplicates()\n",
    "    print(f\"Final Transactions loaded: {len(transactions)} rows\")\n",
    "    \n",
    "    # Convert to polars for better performance\n",
    "    print(\"Converting to Polars for better performance...\")\n",
    "    discounts_pl = pl.from_pandas(discounts)\n",
    "    products_pl = pl.from_pandas(products)\n",
    "    employees_pl = pl.from_pandas(employees)\n",
    "    stores_pl = pl.from_pandas(stores)\n",
    "    customers_pl = pl.from_pandas(customers)\n",
    "    transactions_pl = pl.from_pandas(transactions)\n",
    "    \n",
    "    print(f\"âœ… Data loaded successfully!\")\n",
    "    print(f\"Transactions shape: {transactions_pl.shape}\")\n",
    "    \n",
    "    return discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl\n",
    "\n",
    "\n",
    "def clean_and_translate_data(master_data, city_translation_map, country_translation_map):\n",
    "    \"\"\"\n",
    "    Clean and translate city and country names into English using Polars DataFrame.\n",
    "    Compatible with older Polars versions.\n",
    "    \"\"\"\n",
    "    master_data = master_data.with_columns([\n",
    "        pl.col(\"City\").replace(city_translation_map).alias(\"City\"),\n",
    "        pl.col(\"Country\").replace(country_translation_map).alias(\"Country\")\n",
    "    ])\n",
    "    return master_data\n",
    "\n",
    "\n",
    "def clean_date_columns(df, date_columns):\n",
    "    \"\"\"Clean and convert date columns to simple YYYY-MM-DD format\"\"\"\n",
    "    print(f\"ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: {date_columns}\")\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                # Convert to date (not datetime) - this removes time component automatically\n",
    "                df = df.with_columns(\n",
    "                    pl.col(col).str.strptime(pl.Date, format=\"%Y-%m-%d\", strict=False)\n",
    "                    .fill_null(\n",
    "                        pl.col(col).str.strptime(pl.Date, format=\"%Y-%m-%d %H:%M:%S\", strict=False)\n",
    "                    )\n",
    "                    .fill_null(\n",
    "                        pl.col(col).str.strptime(pl.Date, format=\"%d/%m/%Y\", strict=False)\n",
    "                    )\n",
    "                    .alias(col)\n",
    "                )\n",
    "                print(f\"âœ… Converted {col} to YYYY-MM-DD date format\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Could not convert {col}: {e}\")\n",
    "                # Keep original if conversion fails\n",
    "                pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_lookup_tables(discounts_pl, products_pl, employees_pl, stores_pl, customers_pl):\n",
    "    \"\"\"Prepare minimal lookup tables with only essential information\"\"\"\n",
    "    print(\"ğŸ”§ Preparing optimized lookup tables...\")\n",
    "    \n",
    "    # Clean discount dates - Start and End to YYYY-MM-DD\n",
    "    discounts_clean = clean_date_columns(discounts_pl, ['Start', 'End'])\n",
    "    discounts_lookup = discounts_clean.select([\n",
    "        'Start', 'End', 'Discont', 'Description', 'Category', 'Sub Category'\n",
    "    ])\n",
    "    \n",
    "    # Products - keep essential info only\n",
    "    products_lookup = products_pl.select([\n",
    "        'Product ID', 'Category', 'Sub Category', 'Description EN', \n",
    "        'Color', 'Sizes', 'Production Cost'\n",
    "    ])\n",
    "    \n",
    "    # Employees - minimal info\n",
    "    employees_lookup = employees_pl.select([\n",
    "        'Employee ID', 'Store ID', 'Name', 'Position'\n",
    "    ])\n",
    "    \n",
    "    # Stores - essential location info\n",
    "    stores_pl = clean_and_translate_data(stores_pl, city_translation_map, country_translation_map)\n",
    "    stores_lookup = stores_pl.select([\n",
    "        'Store ID', 'Country', 'City', 'Store Name', 'Number of Employees'\n",
    "    ])\n",
    "    \n",
    "    # Customers - clean birth date to YYYY-MM-DD and keep essential info\n",
    "    customers_pl = clean_and_translate_data(customers_pl, city_translation_map, country_translation_map)\n",
    "    customers_clean = clean_date_columns(customers_pl, ['Date Of Birth'])\n",
    "    customers_lookup = customers_clean.select([\n",
    "        'Customer ID', 'Name', 'Email', 'Gender', 'Date Of Birth', 'Job Title'\n",
    "    ])\n",
    "    \n",
    "    print(\"âœ… Lookup tables prepared\")\n",
    "    return discounts_lookup, products_lookup, employees_lookup, stores_lookup, customers_lookup\n",
    "\n",
    "def process_transactions(transactions_pl, exchange_rates):\n",
    "    \"\"\"Process transactions with USD conversion and date cleaning\"\"\"\n",
    "    print(\"ğŸ’° Processing transactions...\")\n",
    "    \n",
    "    # Clean transaction dates - convert Date to YYYY-MM-DD format (removes time)\n",
    "    \n",
    "    transactions_clean = clean_date_columns(transactions_pl, ['Date'])\n",
    "    \n",
    "    # Add exchange rate column\n",
    "    print(\"ğŸ’± Adding USD conversion...\")\n",
    "    transactions_clean = transactions_clean.with_columns(\n",
    "        pl.col('Currency').map_elements(\n",
    "            lambda x: exchange_rates.get(x, 1.0), \n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(\"Exchange_Rate_to_USD\")\n",
    "    )\n",
    "    \n",
    "    # Convert monetary columns to USD\n",
    "    monetary_columns = ['Unit Price', 'Line Total', 'Invoice Total']\n",
    "    \n",
    "    for col in monetary_columns:\n",
    "        if col in transactions_clean.columns:\n",
    "            usd_col_name = f\"{col.replace(' ', '_')}_USD\"\n",
    "            transactions_clean = transactions_clean.with_columns(\n",
    "                (pl.col(col) * pl.col(\"Exchange_Rate_to_USD\")).alias(usd_col_name)\n",
    "            )\n",
    "            print(f\"âœ… Created {usd_col_name}\")\n",
    "    \n",
    "    return transactions_clean\n",
    "\n",
    "def create_master_dataset():\n",
    "    \"\"\"Create the master dataset with optimized merging\"\"\"\n",
    "    print(\"ğŸ—ï¸ Creating master dataset...\")\n",
    "    \n",
    "    # Load data\n",
    "    discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl = load_data_efficiently()\n",
    "    \n",
    "    # Prepare lookup tables\n",
    "    discounts_lookup, products_lookup, employees_lookup, stores_lookup, customers_lookup = prepare_lookup_tables(\n",
    "        discounts_pl, products_pl, employees_pl, stores_pl, customers_pl\n",
    "    )\n",
    "    \n",
    "    # Process transactions\n",
    "    transactions_processed = process_transactions(transactions_pl, exchange_rates)\n",
    "    \n",
    "    # Merge with lookup tables (left joins to keep all transactions)\n",
    "    print(\"ğŸ”— Merging tables...\")\n",
    "    \n",
    "    # Merge with products\n",
    "    master_data = transactions_processed.join(\n",
    "        products_lookup, \n",
    "        on='Product ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"âœ… Merged with products. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Merge with customers\n",
    "    master_data = master_data.join(\n",
    "        customers_lookup, \n",
    "        on='Customer ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"âœ… Merged with customers. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Merge with stores\n",
    "    master_data = master_data.join(\n",
    "        stores_lookup, \n",
    "        on='Store ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"âœ… Merged with stores. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Merge with employees\n",
    "    master_data = master_data.join(\n",
    "        employees_lookup, \n",
    "        on='Employee ID', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"âœ… Merged with employees. Shape: {master_data.shape}\")\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Save lookup tables separately for future use\n",
    "    print(\"ğŸ’¾ Saving lookup tables...\")\n",
    "    discounts_lookup.write_parquet(\"data/discounts_lookup.parquet\")\n",
    "    products_lookup.write_parquet(\"data/products_lookup.parquet\")\n",
    "    employees_lookup.write_parquet(\"data/employees_lookup.parquet\")\n",
    "    stores_lookup.write_parquet(\"data/stores_lookup.parquet\")\n",
    "    customers_lookup.write_parquet(\"data/customers_lookup.parquet\")\n",
    "    \n",
    "    # Save master dataset\n",
    "    print(\"ğŸ’¾ Saving master dataset...\")\n",
    "    master_data.write_parquet(\"data/master_transactions.parquet\")\n",
    "    \n",
    "    # Save a sample CSV for inspection (first 10k rows)\n",
    "    master_data.head(10000).write_csv(\"data/master_transactions_sample.csv\")\n",
    "    \n",
    "    print(\"âœ… Master dataset created successfully!\")\n",
    "    print(f\"Final shape: {master_data.shape}\")\n",
    "    print(f\"Memory usage optimized by keeping only essential columns from lookup tables\")\n",
    "    \n",
    "    return master_data, discounts_lookup\n",
    "\n",
    "def show_dataset_summary(master_data):\n",
    "    \"\"\"Show summary of the final dataset\"\"\"\n",
    "    print(\"\\nğŸ“Š MASTER DATASET SUMMARY:\")\n",
    "    print(f\"Shape: {master_data.shape}\")\n",
    "    print(f\"Columns: {len(master_data.columns)}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Column List:\")\n",
    "    for i, col in enumerate(master_data.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’° USD Converted Columns:\")\n",
    "    usd_cols = [col for col in master_data.columns if 'USD' in col]\n",
    "    for col in usd_cols:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "    \n",
    "    print(f\"\\nğŸ—“ï¸ Date Columns (YYYY-MM-DD format):\")\n",
    "    date_cols = [col for col in master_data.columns if master_data[col].dtype == pl.Date]\n",
    "    for col in date_cols:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "        # Show sample dates\n",
    "        sample_dates = master_data.select(col).drop_nulls().head(3)\n",
    "        print(f\"     Sample: {sample_dates.to_series().to_list()}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Sample Data:\")\n",
    "    print(master_data.head(3))\n",
    "    \n",
    "    return master_data\n",
    "\n",
    "# Execute the pipeline\n",
    "print(\"ğŸš€ Starting Optimized Data Pipeline...\")\n",
    "master_data, discounts_lookup = create_master_dataset()\n",
    "final_data = show_dataset_summary(master_data)\n",
    "\n",
    "print(\"\\nâœ… Pipeline Complete!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"   â€¢ data/master_transactions.parquet (main dataset)\")\n",
    "print(\"   â€¢ data/master_transactions_sample.csv (sample for inspection)\")\n",
    "print(\"   â€¢ data/discounts_lookup.parquet (for discount analysis)\")\n",
    "print(\"   â€¢ data/products_lookup.parquet\")\n",
    "print(\"   â€¢ data/employees_lookup.parquet\") \n",
    "print(\"   â€¢ data/stores_lookup.parquet\")\n",
    "print(\"   â€¢ data/customers_lookup.parquet\")\n",
    "print(\"\\nğŸ“… All dates are now in simple YYYY-MM-DD format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08f3cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ Memory cleared: 0 objects\n"
     ]
    }
   ],
   "source": [
    "# Add this line before loading your data\n",
    "import gc; gc.collect(); print(f\"ğŸ§¹ Memory cleared: {gc.collect()} objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b888a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total USD for Sale: 305884836.54719996\n",
      "Total USD for Return: -17136183.740900002\n"
     ]
    }
   ],
   "source": [
    "sale_total = final_data.filter(pl.col(\"Transaction Type\") == \"Sale\")[\"Line_Total_USD\"].sum()\n",
    "\n",
    "# Filter rows for 'Return' and calculate the sum of 'Line_Total_USD'\n",
    "return_total = final_data.filter(pl.col(\"Transaction Type\") == \"Return\")[\"Line_Total_USD\"].sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total USD for Sale: {sale_total}\")\n",
    "print(f\"Total USD for Return: {return_total}\")\n",
    "\n",
    "# # Print the results\n",
    "# print(sum_by_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f30ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Line_Total_USD for unique InvoiceIDs (Sale transactions): 305884634.1774\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming final_data is your Polars DataFrame\n",
    "# Step 1: Filter rows where the transaction type is 'Sale'\n",
    "sale_data = final_data.filter(pl.col(\"Transaction Type\") == \"Sale\")\n",
    "\n",
    "# Step 2: Remove duplicate InvoiceID values\n",
    "unique_sale_data = sale_data.unique(subset=[\"Invoice ID\"])\n",
    "\n",
    "# Step 3: Sum the Line_Total_USD column\n",
    "line_total_sum = unique_sale_data[\"Invoice_Total_USD\"].sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Sum of Line_Total_USD for unique InvoiceIDs (Sale transactions): {line_total_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b87e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Line_Total_USD for unique InvoiceIDs (Return transactions): -15683410.0896\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assuming final_data is your Polars DataFrame\n",
    "# Step 1: Filter rows where the transaction type is 'Sale'\n",
    "sale_data2 = final_data.filter(pl.col(\"Transaction Type\") == \"Return\")\n",
    "\n",
    "# Step 2: Remove duplicate InvoiceID values\n",
    "unique_sale_data2 = sale_data2.unique(subset=[\"Invoice ID\"])\n",
    "\n",
    "# Step 3: Sum the Line_Total_USD column\n",
    "line_total_sum2 = unique_sale_data2[\"Invoice_Total_USD\"].sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Sum of Line_Total_USD for unique InvoiceIDs (Return transactions): {line_total_sum2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff9c6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data efficiently...\n",
      "Loading discounts...\n",
      "Loading products...\n",
      "Loading employees...\n",
      "Loading stores...\n",
      "Loading customers...\n",
      "Loading transactions (this may take a moment)...\n",
      "Converting to Polars for better performance...\n",
      "âœ… Data loaded successfully!\n",
      "Transactions shape: (6416827, 19)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š PERFORMING DESCRIPTIVE STATISTICS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ğŸ·ï¸ DISCOUNTS Dataset Analysis:\n",
      "----------------------------------------\n",
      "   ğŸ“‹ Records: 181\n",
      "   ğŸ“Š Columns: 6\n",
      "   ğŸ’¾ Memory: 0.02 MB\n",
      "\n",
      "ğŸ“¦ PRODUCTS Dataset Analysis:\n",
      "----------------------------------------\n",
      "   ğŸ“‹ Records: 17,940\n",
      "   ğŸ“Š Columns: 12\n",
      "   ğŸ’¾ Memory: 4.67 MB\n",
      "   ğŸ·ï¸ Categories: 3\n",
      "\n",
      "ğŸ‘¥ EMPLOYEES Dataset Analysis:\n",
      "----------------------------------------\n",
      "   ğŸ“‹ Records: 404\n",
      "   ğŸ“Š Columns: 4\n",
      "   ğŸ’¾ Memory: 0.02 MB\n",
      "\n",
      "ğŸª STORES Dataset Analysis:\n",
      "----------------------------------------\n",
      "   ğŸ“‹ Records: 35\n",
      "   ğŸ“Š Columns: 8\n",
      "   ğŸ’¾ Memory: 0.00 MB\n",
      "\n",
      "ğŸ‘¤ CUSTOMERS Dataset Analysis:\n",
      "----------------------------------------\n",
      "   ğŸ“‹ Records: 1,643,306\n",
      "   ğŸ“Š Columns: 9\n",
      "   ğŸ’¾ Memory: 169.71 MB\n",
      "\n",
      "ğŸ’³ TRANSACTIONS Dataset Analysis:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alan\\AppData\\Local\\Temp\\ipykernel_47356\\164116053.py:32: DeprecationWarning: `NUMERIC_DTYPES` was deprecated in version 1.0.0. Define your own data type groups or use the `polars.selectors` module for selecting columns of a certain data type.\n",
      "  numeric_cols = discounts_pl.select(pl.col(pl.NUMERIC_DTYPES)).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ“‹ Records: 6,416,827\n",
      "   ğŸ“Š Columns: 19\n",
      "   ğŸ’¾ Memory: 936.64 MB\n",
      "\n",
      "ğŸ“ˆ OVERALL DATA SUMMARY:\n",
      "----------------------------------------\n",
      "   ğŸ“Š Total Datasets: 6\n",
      "   ğŸ“‹ Total Records: 8,078,693\n",
      "   ğŸ’¾ Total Memory: 1111.06 MB\n",
      "\n",
      "ğŸ’¾ Saving descriptive statistics...\n",
      "âœ… Descriptive statistics completed!\n",
      "ğŸ“ Results saved in: descriptive_statistics/\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(shape: (181, 6)\n",
       " â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       " â”‚ Start      â”† End        â”† Discont â”† Description         â”† Category  â”† Sub Category               â”‚\n",
       " â”‚ ---        â”† ---        â”† ---     â”† ---                 â”† ---       â”† ---                        â”‚\n",
       " â”‚ str        â”† str        â”† f64     â”† str                 â”† str       â”† str                        â”‚\n",
       " â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       " â”‚ 2020-01-01 â”† 2020-01-10 â”† 0.4     â”† 40% discount during â”† Feminine  â”† Coats and Blazers          â”‚\n",
       " â”‚            â”†            â”†         â”† our New Yeâ€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2020-01-01 â”† 2020-01-10 â”† 0.4     â”† 40% discount during â”† Feminine  â”† Sweaters and Knitwear      â”‚\n",
       " â”‚            â”†            â”†         â”† our New Yeâ€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2020-01-01 â”† 2020-01-10 â”† 0.4     â”† 40% discount during â”† Masculine â”† Coats and Blazers          â”‚\n",
       " â”‚            â”†            â”†         â”† our New Yeâ€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2020-01-01 â”† 2020-01-10 â”† 0.4     â”† 40% discount during â”† Masculine â”† Sweaters and Sweatshirts   â”‚\n",
       " â”‚            â”†            â”†         â”† our New Yeâ€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2020-01-01 â”† 2020-01-10 â”† 0.4     â”† 40% discount during â”† Children  â”† Coats                      â”‚\n",
       " â”‚            â”†            â”†         â”† our New Yeâ€¦         â”†           â”†                            â”‚\n",
       " â”‚ â€¦          â”† â€¦          â”† â€¦       â”† â€¦                   â”† â€¦         â”† â€¦                          â”‚\n",
       " â”‚ 2025-03-15 â”† 2025-03-31 â”† 0.35    â”† 35% discount during â”† Feminine  â”† Dresses and Jumpsuits      â”‚\n",
       " â”‚            â”†            â”†         â”† our Early â€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2025-03-15 â”† 2025-03-31 â”† 0.35    â”† 35% discount during â”† Feminine  â”† Shirts and Blouses         â”‚\n",
       " â”‚            â”†            â”†         â”† our Early â€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2025-03-15 â”† 2025-03-31 â”† 0.35    â”† 35% discount during â”† Masculine â”† T-shirts and Polos         â”‚\n",
       " â”‚            â”†            â”†         â”† our Early â€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2025-03-15 â”† 2025-03-31 â”† 0.35    â”† 35% discount during â”† Masculine â”† Shirts                     â”‚\n",
       " â”‚            â”†            â”†         â”† our Early â€¦         â”†           â”†                            â”‚\n",
       " â”‚ 2025-03-15 â”† 2025-03-31 â”† 0.35    â”† 35% discount during â”† Children  â”† Girl and Boy (1-5 years,   â”‚\n",
       " â”‚            â”†            â”†         â”† our Early â€¦         â”†           â”† 6-14 â€¦                     â”‚\n",
       " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜,\n",
       " shape: (17_940, 12)\n",
       " â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       " â”‚ Product ID â”† Category â”† Sub       â”† Descripti â”† â€¦ â”† Descripti â”† Color     â”† Sizes    â”† Productio â”‚\n",
       " â”‚ ---        â”† ---      â”† Category  â”† on PT     â”†   â”† on ZH     â”† ---       â”† ---      â”† n Cost    â”‚\n",
       " â”‚ i64        â”† str      â”† ---       â”† ---       â”†   â”† ---       â”† str       â”† str      â”† ---       â”‚\n",
       " â”‚            â”†          â”† str       â”† str       â”†   â”† str       â”†           â”†          â”† f64       â”‚\n",
       " â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       " â”‚ 1          â”† Feminine â”† Coats and â”† Esportivo â”† â€¦ â”† è¿åŠ¨å¤©é¹…  â”† null      â”† S|M|L|XL â”† 10.73     â”‚\n",
       " â”‚            â”†          â”† Blazers   â”† Veludo    â”†   â”† ç»’è¿åŠ¨ä¸  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Verde Com â”†   â”† æŒ‰é’®      â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Botâ€¦      â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 2          â”† Feminine â”† Sweaters  â”† Luxuoso   â”† â€¦ â”† è±ªåçš„ç²‰  â”† PINK      â”† S|M|L|XL â”† 19.55     â”‚\n",
       " â”‚            â”†          â”† and       â”† Denim     â”†   â”† çº¢è‰²ç‰›ä»”  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”† Knitwear  â”† Rosa Com  â”†   â”† å¸ƒå’Œçº½æ‰£  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† BotÃµes    â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 3          â”† Feminine â”† Dresses   â”† RetrÃ´     â”† â€¦ â”† é»‘è‰²ä¸‰è§’  â”† BLACK     â”† S|M|L|XL â”† 25.59     â”‚\n",
       " â”‚            â”†          â”† and       â”† Tricot    â”†   â”† å½¢å°åˆ·ä¸‰  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”† Jumpsuits â”† Preto     â”†   â”† è§’å½¢      â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Estampado â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 4          â”† Feminine â”† Shirts    â”† Blusa De  â”† â€¦ â”† åŸºæœ¬çš„æ£‰  â”† null      â”† S|M|L|XL â”† 27.62     â”‚\n",
       " â”‚            â”†          â”† and       â”† AlgodÃ£o   â”†   â”† è¡¬è¡«      â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”† Blouses   â”† BÃ¡sica    â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 5          â”† Feminine â”† T-shirts  â”† T-Shirt   â”† â€¦ â”† åŸºæœ¬æ£‰Tæ¤ â”† null      â”† S|M|L    â”† 11.69     â”‚\n",
       " â”‚            â”†          â”† and Tops  â”† BÃ¡sica De â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† AlgodÃ£o   â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ â€¦          â”† â€¦        â”† â€¦         â”† â€¦         â”† â€¦ â”† â€¦         â”† â€¦         â”† â€¦        â”† â€¦         â”‚\n",
       " â”‚ 17936      â”† Children â”† Girl and  â”† Executivo â”† â€¦ â”† è¡Œæ”¿ç»¿é©  â”† GREEN     â”† P|M|G|GG â”† 7.69      â”‚\n",
       " â”‚            â”†          â”† Boy (1-5  â”† CamurÃ§a   â”†   â”† ä¸æ‹‰é“¾    â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”† years,    â”† Verde Com â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”† 6-14 â€¦    â”† ZÃ­â€¦       â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 17937      â”† Children â”† Coats     â”† Luxuoso   â”† â€¦ â”† è±ªåçš„ç»¿  â”† TURQUOISE â”† P|M|G    â”† 11.65     â”‚\n",
       " â”‚            â”†          â”†           â”† LÃ£        â”†   â”† æ¾çŸ³ç¾Šæ¯›  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Turquesa  â”†   â”† å’Œå¼•æ“ç›–  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Com Capuz â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 17938      â”† Children â”† Sweaters  â”† Camisola  â”† â€¦ â”† å¸¦å‡ ä½•å°  â”† null      â”† P|M|G    â”† 24.38     â”‚\n",
       " â”‚            â”†          â”†           â”† Infantil  â”†   â”† åˆ·çš„Kidsk â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† De TricÃ´  â”†   â”† otè¡¬è¡«    â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Comâ€¦      â”†   â”†           â”†           â”†          â”†           â”‚\n",
       " â”‚ 17939      â”† Children â”† Pajamas   â”† Pijama    â”† â€¦ â”† å­©å­ä»¬ç¼  â”† null      â”† P|M|G    â”† 18.27     â”‚\n",
       " â”‚            â”†          â”†           â”† Infantil  â”†   â”† é¢ç¡è¡£ï¼Œ  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† De Cetim  â”†   â”† å…‰æ»‘çš„å…‰  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Com Bâ€¦    â”†   â”† æ³½å’Œå£è¢‹  â”†           â”†          â”†           â”‚\n",
       " â”‚ 17940      â”† Children â”† Accessori â”† Protetor  â”† â€¦ â”† ä¸ºäº†å®‰å…¨  â”† null      â”† null     â”† 10.99     â”‚\n",
       " â”‚            â”†          â”† es        â”† De BraÃ§o  â”†   â”† èµ·è§å„¿ç«¥  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Infantil  â”†   â”† æ‰‹è‡‚ä¿æŠ¤  â”†           â”†          â”†           â”‚\n",
       " â”‚            â”†          â”†           â”† Parâ€¦      â”†   â”† å™¨        â”†           â”†          â”†           â”‚\n",
       " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜,\n",
       " shape: (404, 4)\n",
       " â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       " â”‚ Employee ID â”† Store ID â”† Name               â”† Position          â”‚\n",
       " â”‚ ---         â”† ---      â”† ---                â”† ---               â”‚\n",
       " â”‚ i64         â”† i64      â”† str                â”† str               â”‚\n",
       " â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       " â”‚ 1           â”† 1        â”† Stephen Johnson    â”† Store Manager     â”‚\n",
       " â”‚ 2           â”† 1        â”† Rebecca Myers      â”† Assistant Manager â”‚\n",
       " â”‚ 3           â”† 1        â”† Katherine Buchanan â”† Cashier           â”‚\n",
       " â”‚ 4           â”† 1        â”† Jessica Hicks      â”† Stock Clerk       â”‚\n",
       " â”‚ 5           â”† 1        â”† Ryan Gross         â”† Sales Associate   â”‚\n",
       " â”‚ â€¦           â”† â€¦        â”† â€¦                  â”† â€¦                 â”‚\n",
       " â”‚ 400         â”† 35       â”† Henrique Amaral    â”† Sales Associate   â”‚\n",
       " â”‚ 401         â”† 35       â”† Brian Rocha        â”† Sales Associate   â”‚\n",
       " â”‚ 402         â”† 35       â”† Matilde Campos     â”† Sales Associate   â”‚\n",
       " â”‚ 403         â”† 35       â”† Emanuel Marques    â”† Sales Associate   â”‚\n",
       " â”‚ 404         â”† 35       â”† Violeta GonÃ§alves  â”† Sales Associate   â”‚\n",
       " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜,\n",
       " shape: (35, 8)\n",
       " â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       " â”‚ Store ID â”† Country     â”† City        â”† Store Name â”† Number of  â”† ZIP Code â”† Latitude â”† Longitude â”‚\n",
       " â”‚ ---      â”† ---         â”† ---         â”† ---        â”† Employees  â”† ---      â”† ---      â”† ---       â”‚\n",
       " â”‚ i64      â”† str         â”† str         â”† str        â”† ---        â”† str      â”† f64      â”† f64       â”‚\n",
       " â”‚          â”†             â”†             â”†            â”† i64        â”†          â”†          â”†           â”‚\n",
       " â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       " â”‚ 1        â”† United      â”† New York    â”† Store New  â”† 10         â”† 10001    â”† 40.7128  â”† -74.006   â”‚\n",
       " â”‚          â”† States      â”†             â”† York       â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 2        â”† United      â”† Los Angeles â”† Store Los  â”† 8          â”† 90001    â”† 34.0522  â”† -118.2437 â”‚\n",
       " â”‚          â”† States      â”†             â”† Angeles    â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 3        â”† United      â”† Chicago     â”† Store      â”† 9          â”† 60601    â”† 41.8781  â”† -87.6298  â”‚\n",
       " â”‚          â”† States      â”†             â”† Chicago    â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 4        â”† United      â”† Houston     â”† Store      â”† 10         â”† 77001    â”† 29.7604  â”† -95.3698  â”‚\n",
       " â”‚          â”† States      â”†             â”† Houston    â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 5        â”† United      â”† Phoenix     â”† Store      â”† 9          â”† 85001    â”† 33.4484  â”† -112.074  â”‚\n",
       " â”‚          â”† States      â”†             â”† Phoenix    â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ â€¦        â”† â€¦           â”† â€¦           â”† â€¦          â”† â€¦          â”† â€¦        â”† â€¦        â”† â€¦         â”‚\n",
       " â”‚ 31       â”† Portugal    â”† Lisboa      â”† Store      â”† 10         â”† 1000-001 â”† 38.7167  â”† -9.1333   â”‚\n",
       " â”‚          â”†             â”†             â”† Lisboa     â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 32       â”† Portugal    â”† Porto       â”† Store      â”† 7          â”† 4000-001 â”† 41.1496  â”† -8.611    â”‚\n",
       " â”‚          â”†             â”†             â”† Porto      â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 33       â”† Portugal    â”† Braga       â”† Store      â”† 9          â”† 4700-001 â”† 41.5503  â”† -8.4201   â”‚\n",
       " â”‚          â”†             â”†             â”† Braga      â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 34       â”† Portugal    â”† GuimarÃ£es   â”† Store      â”† 9          â”† 4800-001 â”† 41.4444  â”† -8.2962   â”‚\n",
       " â”‚          â”†             â”†             â”† GuimarÃ£es  â”†            â”†          â”†          â”†           â”‚\n",
       " â”‚ 35       â”† Portugal    â”† Coimbra     â”† Store      â”† 7          â”† 3000-001 â”† 40.2056  â”† -8.4196   â”‚\n",
       " â”‚          â”†             â”†             â”† Coimbra    â”†            â”†          â”†          â”†           â”‚\n",
       " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜,\n",
       " shape: (1_643_306, 9)\n",
       " â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       " â”‚ Customer   â”† Name       â”† Email     â”† Telephone â”† â€¦ â”† Country   â”† Gender â”† Date Of   â”† Job Title â”‚\n",
       " â”‚ ID         â”† ---        â”† ---       â”† ---       â”†   â”† ---       â”† ---    â”† Birth     â”† ---       â”‚\n",
       " â”‚ ---        â”† str        â”† str       â”† str       â”†   â”† str       â”† str    â”† ---       â”† str       â”‚\n",
       " â”‚ i64        â”†            â”†           â”†           â”†   â”†           â”†        â”† str       â”†           â”‚\n",
       " â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       " â”‚ 1          â”† Tyler      â”† tyler.gar â”† 922.970.2 â”† â€¦ â”† United    â”† M      â”† 2003-07-1 â”† null      â”‚\n",
       " â”‚            â”† Garcia     â”† cia@fake_ â”† 265x47563 â”†   â”† States    â”†        â”† 5         â”†           â”‚\n",
       " â”‚            â”†            â”† gmail.com â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 2          â”† Joshua     â”† joshua.mi â”† +1-958-72 â”† â€¦ â”† United    â”† M      â”† 2000-06-1 â”† Records   â”‚\n",
       " â”‚            â”† Miller     â”† ller@fake â”† 9-6169    â”†   â”† States    â”†        â”† 6         â”† manager   â”‚\n",
       " â”‚            â”†            â”† _gmail.co â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚            â”†            â”† m         â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 3          â”† Alison     â”† alison.ma â”† +1-645-56 â”† â€¦ â”† United    â”† F      â”† 2003-07-2 â”† null      â”‚\n",
       " â”‚            â”† Marshall   â”† rshall.dd â”† 7-0876x54 â”†   â”† States    â”†        â”† 2         â”†           â”‚\n",
       " â”‚            â”† DDS        â”† s@fake_ho â”† 09        â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚            â”†            â”† tmaâ€¦      â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 4          â”† Jeffery    â”† jeffery.a â”† 212.336.0 â”† â€¦ â”† United    â”† M      â”† 1996-11-1 â”† Proofread â”‚\n",
       " â”‚            â”† Acosta     â”† costa@fak â”† 912x84994 â”†   â”† States    â”†        â”† 2         â”† er        â”‚\n",
       " â”‚            â”†            â”† e_yahoo.c â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚            â”†            â”† om        â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 5          â”† Ashley     â”† ashley.sa â”† 781453578 â”† â€¦ â”† United    â”† F      â”† 1998-02-1 â”† Exercise  â”‚\n",
       " â”‚            â”† Sanders    â”† nders@fak â”† 1         â”†   â”† States    â”†        â”† 0         â”† physiolog â”‚\n",
       " â”‚            â”†            â”† e_hotmail â”†           â”†   â”†           â”†        â”†           â”† ist       â”‚\n",
       " â”‚            â”†            â”† .coâ€¦      â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ â€¦          â”† â€¦          â”† â€¦         â”† â€¦         â”† â€¦ â”† â€¦         â”† â€¦      â”† â€¦         â”† â€¦         â”‚\n",
       " â”‚ 1643302    â”† Bernardo   â”† bernardo. â”† (351)     â”† â€¦ â”† Portugal  â”† M      â”† 1973-02-2 â”† Structura â”‚\n",
       " â”‚            â”† Vicente    â”† vicente@f â”† 962314916 â”†   â”†           â”†        â”† 7         â”† l         â”‚\n",
       " â”‚            â”†            â”† ake_hotma â”†           â”†   â”†           â”†        â”†           â”† engineer  â”‚\n",
       " â”‚            â”†            â”† il.â€¦      â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 1643303    â”† Luana      â”† luana.lei â”† (351) 288 â”† â€¦ â”† Portugal  â”† F      â”† 1997-02-0 â”† Futures   â”‚\n",
       " â”‚            â”† Leite      â”† te@fake_c â”† 728 807   â”†   â”†           â”†        â”† 5         â”† trader    â”‚\n",
       " â”‚            â”†            â”† lix.pt    â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 1643304    â”† Ema        â”† ema.freit â”† +35191099 â”† â€¦ â”† Portugal  â”† F      â”† 2005-03-1 â”† null      â”‚\n",
       " â”‚            â”† Freitas    â”† as@fake_c â”† 0620      â”†   â”†           â”†        â”† 4         â”†           â”‚\n",
       " â”‚            â”†            â”† lix.pt    â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 1643305    â”† Rafaela    â”† rafaela.c â”† +35193818 â”† â€¦ â”† Portugal  â”† F      â”† 1989-07-1 â”† Futures   â”‚\n",
       " â”‚            â”† Carneiro   â”† arneiro@f â”† 2129      â”†   â”†           â”†        â”† 4         â”† trader    â”‚\n",
       " â”‚            â”†            â”† ake_clix. â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚            â”†            â”† pt        â”†           â”†   â”†           â”†        â”†           â”†           â”‚\n",
       " â”‚ 1643306    â”† Pilar da   â”† pilar.da. â”† (351) 938 â”† â€¦ â”† Portugal  â”† F      â”† 1978-12-2 â”† Garment/t â”‚\n",
       " â”‚            â”† Coelho     â”† coelho@fa â”† 886 805   â”†   â”†           â”†        â”† 2         â”† extile    â”‚\n",
       " â”‚            â”†            â”† ke_hotmai â”†           â”†   â”†           â”†        â”†           â”† technolog â”‚\n",
       " â”‚            â”†            â”† l.câ€¦      â”†           â”†   â”†           â”†        â”†           â”† ist       â”‚\n",
       " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜,\n",
       " shape: (6_416_827, 19)\n",
       " â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       " â”‚ Invoice ID â”† Line â”† Customer   â”† Product ID â”† â€¦ â”† SKU        â”† Transacti â”† Payment   â”† Invoice   â”‚\n",
       " â”‚ ---        â”† ---  â”† ID         â”† ---        â”†   â”† ---        â”† on Type   â”† Method    â”† Total     â”‚\n",
       " â”‚ str        â”† i64  â”† ---        â”† i64        â”†   â”† str        â”† ---       â”† ---       â”† ---       â”‚\n",
       " â”‚            â”†      â”† i64        â”†            â”†   â”†            â”† str       â”† str       â”† f64       â”‚\n",
       " â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       " â”‚ INV-US-001 â”† 1    â”† 47162      â”† 485        â”† â€¦ â”† MASU485-M- â”† Sale      â”† Cash      â”† 126.7     â”‚\n",
       " â”‚ -03558761  â”†      â”†            â”†            â”†   â”†            â”†           â”†           â”†           â”‚\n",
       " â”‚ INV-US-001 â”† 2    â”† 47162      â”† 2779       â”† â€¦ â”† CHCO2779-G â”† Sale      â”† Cash      â”† 126.7     â”‚\n",
       " â”‚ -03558761  â”†      â”†            â”†            â”†   â”† -          â”†           â”†           â”†           â”‚\n",
       " â”‚ INV-US-001 â”† 3    â”† 47162      â”† 64         â”† â€¦ â”† MACO64-M-N â”† Sale      â”† Cash      â”† 126.7     â”‚\n",
       " â”‚ -03558761  â”†      â”†            â”†            â”†   â”† EUTRAL     â”†           â”†           â”†           â”‚\n",
       " â”‚ INV-US-001 â”† 1    â”† 10142      â”† 131        â”† â€¦ â”† FECO131-M- â”† Sale      â”† Cash      â”† 77.0      â”‚\n",
       " â”‚ -03558762  â”†      â”†            â”†            â”†   â”† BLUE       â”†           â”†           â”†           â”‚\n",
       " â”‚ INV-US-001 â”† 2    â”† 10142      â”† 716        â”† â€¦ â”† MAT-716-L- â”† Sale      â”† Cash      â”† 77.0      â”‚\n",
       " â”‚ -03558762  â”†      â”†            â”†            â”†   â”† WHITE      â”†           â”†           â”†           â”‚\n",
       " â”‚ â€¦          â”† â€¦    â”† â€¦          â”† â€¦          â”† â€¦ â”† â€¦          â”† â€¦         â”† â€¦         â”† â€¦         â”‚\n",
       " â”‚ INV-PT-035 â”† 2    â”† 1640168    â”† 15414      â”† â€¦ â”† CHGI15414- â”† Sale      â”† Credit    â”† 69.55     â”‚\n",
       " â”‚ -01497756  â”†      â”†            â”†            â”†   â”† P-         â”†           â”† Card      â”†           â”‚\n",
       " â”‚ INV-PT-035 â”† 3    â”† 1640168    â”† 15232      â”† â€¦ â”† CHGI15232- â”† Sale      â”† Credit    â”† 69.55     â”‚\n",
       " â”‚ -01497756  â”†      â”†            â”†            â”†   â”† G-RED      â”†           â”† Card      â”†           â”‚\n",
       " â”‚ INV-PT-035 â”† 1    â”† 1636770    â”† 15401      â”† â€¦ â”† FESP15401- â”† Sale      â”† Credit    â”† 40.0      â”‚\n",
       " â”‚ -01497757  â”†      â”†            â”†            â”†   â”† XL-        â”†           â”† Card      â”†           â”‚\n",
       " â”‚ INV-PT-035 â”† 1    â”† 1642472    â”† 15671      â”† â€¦ â”† MAUN15671- â”† Sale      â”† Credit    â”† 36.5      â”‚\n",
       " â”‚ -01497758  â”†      â”†            â”†            â”†   â”† M-         â”†           â”† Card      â”†           â”‚\n",
       " â”‚ INV-PT-035 â”† 1    â”† 1639026    â”† 17424      â”† â€¦ â”† FESH17424- â”† Sale      â”† Credit    â”† 16.57     â”‚\n",
       " â”‚ -01497759  â”†      â”†            â”†            â”†   â”† M-         â”†           â”† Card      â”†           â”‚\n",
       " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜,\n",
       " {'discounts': {'total_records': 181,\n",
       "   'total_columns': 6,\n",
       "   'columns': ['Start',\n",
       "    'End',\n",
       "    'Discont',\n",
       "    'Description',\n",
       "    'Category',\n",
       "    'Sub Category'],\n",
       "   'data_types': {'Start': 'String',\n",
       "    'End': 'String',\n",
       "    'Discont': 'Float64',\n",
       "    'Description': 'String',\n",
       "    'Category': 'String',\n",
       "    'Sub Category': 'String'},\n",
       "   'null_counts': {'Start': 0,\n",
       "    'End': 0,\n",
       "    'Discont': 0,\n",
       "    'Description': 0,\n",
       "    'Category': 10,\n",
       "    'Sub Category': 10},\n",
       "   'memory_usage_mb': 0.017075538635253906,\n",
       "   'numeric_summary': {'statistic': {0: 'count',\n",
       "     1: 'null_count',\n",
       "     2: 'mean',\n",
       "     3: 'std',\n",
       "     4: 'min',\n",
       "     5: '25%',\n",
       "     6: '50%',\n",
       "     7: '75%',\n",
       "     8: 'max'},\n",
       "    'Discont': {0: 181.0,\n",
       "     1: 0.0,\n",
       "     2: 0.3433701657458564,\n",
       "     3: 0.1036029868428037,\n",
       "     4: 0.2,\n",
       "     5: 0.25,\n",
       "     6: 0.35,\n",
       "     7: 0.4,\n",
       "     8: 0.6}}},\n",
       "  'products': {'total_records': 17940,\n",
       "   'total_columns': 12,\n",
       "   'columns': ['Product ID',\n",
       "    'Category',\n",
       "    'Sub Category',\n",
       "    'Description PT',\n",
       "    'Description DE',\n",
       "    'Description FR',\n",
       "    'Description ES',\n",
       "    'Description EN',\n",
       "    'Description ZH',\n",
       "    'Color',\n",
       "    'Sizes',\n",
       "    'Production Cost'],\n",
       "   'data_types': {'Product ID': 'Int64',\n",
       "    'Category': 'String',\n",
       "    'Sub Category': 'String',\n",
       "    'Description PT': 'String',\n",
       "    'Description DE': 'String',\n",
       "    'Description FR': 'String',\n",
       "    'Description ES': 'String',\n",
       "    'Description EN': 'String',\n",
       "    'Description ZH': 'String',\n",
       "    'Color': 'String',\n",
       "    'Sizes': 'String',\n",
       "    'Production Cost': 'Float64'},\n",
       "   'null_counts': {'Product ID': 0,\n",
       "    'Category': 0,\n",
       "    'Sub Category': 0,\n",
       "    'Description PT': 0,\n",
       "    'Description DE': 0,\n",
       "    'Description FR': 0,\n",
       "    'Description ES': 0,\n",
       "    'Description EN': 0,\n",
       "    'Description ZH': 0,\n",
       "    'Color': 12445,\n",
       "    'Sizes': 2070,\n",
       "    'Production Cost': 0},\n",
       "   'memory_usage_mb': 4.672783851623535,\n",
       "   'unique_categories': 3,\n",
       "   'category_distribution': [{'Category': 'Feminine', 'len': 7590},\n",
       "    {'Category': 'Masculine', 'len': 6210},\n",
       "    {'Category': 'Children', 'len': 4140}],\n",
       "   'price_summary': {'statistic': {0: 'count',\n",
       "     1: 'null_count',\n",
       "     2: 'mean',\n",
       "     3: 'std',\n",
       "     4: 'min',\n",
       "     5: '25%',\n",
       "     6: '50%',\n",
       "     7: '75%',\n",
       "     8: 'max'},\n",
       "    'Production Cost': {0: 17940.0,\n",
       "     1: 0.0,\n",
       "     2: 16.096188963210704,\n",
       "     3: 11.628072215331974,\n",
       "     4: 0.56,\n",
       "     5: 7.8,\n",
       "     6: 13.14,\n",
       "     7: 20.97,\n",
       "     8: 77.19}}},\n",
       "  'employees': {'total_records': 404,\n",
       "   'total_columns': 4,\n",
       "   'columns': ['Employee ID', 'Store ID', 'Name', 'Position'],\n",
       "   'data_types': {'Employee ID': 'Int64',\n",
       "    'Store ID': 'Int64',\n",
       "    'Name': 'String',\n",
       "    'Position': 'String'},\n",
       "   'null_counts': {'Employee ID': 0, 'Store ID': 0, 'Name': 0, 'Position': 0},\n",
       "   'memory_usage_mb': 0.017333984375,\n",
       "   'Position_distribution': [{'Position': 'Sales Associate', 'len': 264},\n",
       "    {'Position': 'Assistant Manager', 'len': 35},\n",
       "    {'Position': 'Store Manager', 'len': 35},\n",
       "    {'Position': 'Cashier', 'len': 35},\n",
       "    {'Position': 'Stock Clerk', 'len': 35}]},\n",
       "  'stores': {'total_records': 35,\n",
       "   'total_columns': 8,\n",
       "   'columns': ['Store ID',\n",
       "    'Country',\n",
       "    'City',\n",
       "    'Store Name',\n",
       "    'Number of Employees',\n",
       "    'ZIP Code',\n",
       "    'Latitude',\n",
       "    'Longitude'],\n",
       "   'data_types': {'Store ID': 'Int64',\n",
       "    'Country': 'String',\n",
       "    'City': 'String',\n",
       "    'Store Name': 'String',\n",
       "    'Number of Employees': 'Int64',\n",
       "    'ZIP Code': 'String',\n",
       "    'Latitude': 'Float64',\n",
       "    'Longitude': 'Float64'},\n",
       "   'null_counts': {'Store ID': 0,\n",
       "    'Country': 0,\n",
       "    'City': 0,\n",
       "    'Store Name': 0,\n",
       "    'Number of Employees': 0,\n",
       "    'ZIP Code': 0,\n",
       "    'Latitude': 0,\n",
       "    'Longitude': 0},\n",
       "   'memory_usage_mb': 0.0022535324096679688,\n",
       "   'Country_distribution': [{'Country': 'France', 'len': 5},\n",
       "    {'Country': 'United States', 'len': 5},\n",
       "    {'Country': 'EspaÃ±a', 'len': 5},\n",
       "    {'Country': 'Portugal', 'len': 5},\n",
       "    {'Country': 'United Kingdom', 'len': 5},\n",
       "    {'Country': 'Deutschland', 'len': 5},\n",
       "    {'Country': 'ä¸­å›½', 'len': 5}],\n",
       "   'City_distribution': [{'City': 'Lyon', 'len': 1},\n",
       "    {'City': 'Valencia', 'len': 1},\n",
       "    {'City': 'é‡åº†', 'len': 1},\n",
       "    {'City': 'Sevilla', 'len': 1},\n",
       "    {'City': 'KÃ¶ln', 'len': 1},\n",
       "    {'City': 'Toulouse', 'len': 1},\n",
       "    {'City': 'London', 'len': 1},\n",
       "    {'City': 'å¹¿å·', 'len': 1},\n",
       "    {'City': 'Porto', 'len': 1},\n",
       "    {'City': 'Glasgow', 'len': 1},\n",
       "    {'City': 'Nice', 'len': 1},\n",
       "    {'City': 'åŒ—äº¬', 'len': 1},\n",
       "    {'City': 'Lisboa', 'len': 1},\n",
       "    {'City': 'Madrid', 'len': 1},\n",
       "    {'City': 'MÃ¼nchen', 'len': 1},\n",
       "    {'City': 'Houston', 'len': 1},\n",
       "    {'City': 'Liverpool', 'len': 1},\n",
       "    {'City': 'Phoenix', 'len': 1},\n",
       "    {'City': 'Barcelona', 'len': 1},\n",
       "    {'City': 'Chicago', 'len': 1},\n",
       "    {'City': 'Hamburg', 'len': 1},\n",
       "    {'City': 'Coimbra', 'len': 1},\n",
       "    {'City': 'Marseille', 'len': 1},\n",
       "    {'City': 'Birmingham', 'len': 1},\n",
       "    {'City': 'Paris', 'len': 1},\n",
       "    {'City': 'New York', 'len': 1},\n",
       "    {'City': 'Braga', 'len': 1},\n",
       "    {'City': 'æ·±åœ³', 'len': 1},\n",
       "    {'City': 'Los Angeles', 'len': 1},\n",
       "    {'City': 'Frankfurt am Main', 'len': 1},\n",
       "    {'City': 'Berlin', 'len': 1},\n",
       "    {'City': 'Zaragoza', 'len': 1},\n",
       "    {'City': 'GuimarÃ£es', 'len': 1},\n",
       "    {'City': 'ä¸Šæµ·', 'len': 1},\n",
       "    {'City': 'Bristol', 'len': 1}]},\n",
       "  'customers': {'total_records': 1643306,\n",
       "   'total_columns': 9,\n",
       "   'columns': ['Customer ID',\n",
       "    'Name',\n",
       "    'Email',\n",
       "    'Telephone',\n",
       "    'City',\n",
       "    'Country',\n",
       "    'Gender',\n",
       "    'Date Of Birth',\n",
       "    'Job Title'],\n",
       "   'data_types': {'Customer ID': 'Int64',\n",
       "    'Name': 'String',\n",
       "    'Email': 'String',\n",
       "    'Telephone': 'String',\n",
       "    'City': 'String',\n",
       "    'Country': 'String',\n",
       "    'Gender': 'String',\n",
       "    'Date Of Birth': 'String',\n",
       "    'Job Title': 'String'},\n",
       "   'null_counts': {'Customer ID': 0,\n",
       "    'Name': 0,\n",
       "    'Email': 0,\n",
       "    'Telephone': 0,\n",
       "    'City': 0,\n",
       "    'Country': 0,\n",
       "    'Gender': 0,\n",
       "    'Date Of Birth': 0,\n",
       "    'Job Title': 584185},\n",
       "   'memory_usage_mb': 169.70775318145752,\n",
       "   'City_distribution': [{'City': 'æ·±åœ³', 'len': 60709},\n",
       "    {'City': 'åŒ—äº¬', 'len': 51163},\n",
       "    {'City': 'New York', 'len': 50000},\n",
       "    {'City': 'Los Angeles', 'len': 45000},\n",
       "    {'City': 'ä¸Šæµ·', 'len': 42381},\n",
       "    {'City': 'Chicago', 'len': 40000},\n",
       "    {'City': 'Houston', 'len': 35000},\n",
       "    {'City': 'å¹¿å·', 'len': 33600},\n",
       "    {'City': 'Phoenix', 'len': 30000},\n",
       "    {'City': 'Berlin', 'len': 29000}],\n",
       "   'Country_distribution': [{'Country': 'United States', 'len': 354450},\n",
       "    {'Country': 'ä¸­å›½', 'len': 340082},\n",
       "    {'Country': 'EspaÃ±a', 'len': 237575},\n",
       "    {'Country': 'Deutschland', 'len': 205560},\n",
       "    {'Country': 'France', 'len': 196696},\n",
       "    {'Country': 'United Kingdom', 'len': 190574},\n",
       "    {'Country': 'Portugal', 'len': 118369}],\n",
       "   'Gender_distribution': [{'Gender': 'M', 'len': 964562},\n",
       "    {'Gender': 'F', 'len': 677041},\n",
       "    {'Gender': 'D', 'len': 1703}]},\n",
       "  'transactions': {'total_records': 6416827,\n",
       "   'total_columns': 19,\n",
       "   'columns': ['Invoice ID',\n",
       "    'Line',\n",
       "    'Customer ID',\n",
       "    'Product ID',\n",
       "    'Size',\n",
       "    'Color',\n",
       "    'Unit Price',\n",
       "    'Quantity',\n",
       "    'Date',\n",
       "    'Discount',\n",
       "    'Line Total',\n",
       "    'Store ID',\n",
       "    'Employee ID',\n",
       "    'Currency',\n",
       "    'Currency Symbol',\n",
       "    'SKU',\n",
       "    'Transaction Type',\n",
       "    'Payment Method',\n",
       "    'Invoice Total'],\n",
       "   'data_types': {'Invoice ID': 'String',\n",
       "    'Line': 'Int64',\n",
       "    'Customer ID': 'Int64',\n",
       "    'Product ID': 'Int64',\n",
       "    'Size': 'String',\n",
       "    'Color': 'String',\n",
       "    'Unit Price': 'Float64',\n",
       "    'Quantity': 'Int64',\n",
       "    'Date': 'String',\n",
       "    'Discount': 'Float64',\n",
       "    'Line Total': 'Float64',\n",
       "    'Store ID': 'Int64',\n",
       "    'Employee ID': 'Int64',\n",
       "    'Currency': 'String',\n",
       "    'Currency Symbol': 'String',\n",
       "    'SKU': 'String',\n",
       "    'Transaction Type': 'String',\n",
       "    'Payment Method': 'String',\n",
       "    'Invoice Total': 'Float64'},\n",
       "   'null_counts': {'Invoice ID': 0,\n",
       "    'Line': 0,\n",
       "    'Customer ID': 0,\n",
       "    'Product ID': 0,\n",
       "    'Size': 413102,\n",
       "    'Color': 4350783,\n",
       "    'Unit Price': 0,\n",
       "    'Quantity': 0,\n",
       "    'Date': 0,\n",
       "    'Discount': 0,\n",
       "    'Line Total': 0,\n",
       "    'Store ID': 0,\n",
       "    'Employee ID': 0,\n",
       "    'Currency': 0,\n",
       "    'Currency Symbol': 0,\n",
       "    'SKU': 0,\n",
       "    'Transaction Type': 0,\n",
       "    'Payment Method': 0,\n",
       "    'Invoice Total': 0},\n",
       "   'memory_usage_mb': 936.6401176452637,\n",
       "   'financial_summary': {'statistic': {0: 'count',\n",
       "     1: 'null_count',\n",
       "     2: 'mean',\n",
       "     3: 'std',\n",
       "     4: 'min',\n",
       "     5: '25%',\n",
       "     6: '50%',\n",
       "     7: '75%',\n",
       "     8: 'max'},\n",
       "    'Unit Price': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 132.4640200600702,\n",
       "     3: 185.0971221528057,\n",
       "     4: 2.0,\n",
       "     5: 32.5,\n",
       "     6: 51.0,\n",
       "     7: 116.5,\n",
       "     8: 1153.5},\n",
       "    'Quantity': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 1.1002433134008445,\n",
       "     3: 0.39637920769696927,\n",
       "     4: 1.0,\n",
       "     5: 1.0,\n",
       "     6: 1.0,\n",
       "     7: 1.0,\n",
       "     8: 3.0},\n",
       "    'Line Total': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 114.19115319612014,\n",
       "     3: 211.5864597028735,\n",
       "     4: -3348.0,\n",
       "     5: 24.75,\n",
       "     6: 43.5,\n",
       "     7: 109.0,\n",
       "     8: 3460.5},\n",
       "    'Invoice Total': {0: 6416827.0,\n",
       "     1: 0.0,\n",
       "     2: 243.5266428205093,\n",
       "     3: 536.733823248412,\n",
       "     4: -6750.5,\n",
       "     5: 34.02,\n",
       "     6: 83.5,\n",
       "     7: 241.0,\n",
       "     8: 8977.0}},\n",
       "   'Date_range': {'min_date': '2023-01-01 00:00:00',\n",
       "    'max_date': '2025-03-18 20:59:00',\n",
       "    'unique_dates': 608986},\n",
       "   'unique_customer_id': 1283707,\n",
       "   'unique_product_id': 17940,\n",
       "   'unique_store_id': 35,\n",
       "   'unique_employee_id': 264},\n",
       "  'overall': {'total_datasets': 6,\n",
       "   'total_records_across_all': 8078693,\n",
       "   'total_memory_usage_mb': 1111.0573177337646,\n",
       "   'analysis_timestamp': '2025-07-27T15:58:46.889335'}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_descriptive_statistics(discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl):\n",
    "    \"\"\"\n",
    "    Perform comprehensive descriptive statistics on all datasets\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š PERFORMING DESCRIPTIVE STATISTICS ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create output directory\n",
    "    stats_dir = \"descriptive_statistics\"\n",
    "    os.makedirs(stats_dir, exist_ok=True)\n",
    "    \n",
    "    stats_summary = {}\n",
    "    \n",
    "    # 1. DISCOUNTS DATASET ANALYSIS\n",
    "    print(\"\\nğŸ·ï¸ DISCOUNTS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    discounts_stats = {\n",
    "        'total_records': discounts_pl.shape[0],\n",
    "        'total_columns': discounts_pl.shape[1],\n",
    "        'columns': discounts_pl.columns,\n",
    "        'data_types': dict(zip(discounts_pl.columns, [str(dtype) for dtype in discounts_pl.dtypes])),\n",
    "        'null_counts': discounts_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': discounts_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Numeric columns analysis for discounts\n",
    "    numeric_cols = discounts_pl.select(pl.col(pl.NUMERIC_DTYPES)).columns\n",
    "    if numeric_cols:\n",
    "        discounts_stats['numeric_summary'] = discounts_pl.select(numeric_cols).describe().to_pandas().to_dict()\n",
    "    \n",
    "    stats_summary['discounts'] = discounts_stats\n",
    "    \n",
    "    print(f\"   ğŸ“‹ Records: {discounts_stats['total_records']:,}\")\n",
    "    print(f\"   ğŸ“Š Columns: {discounts_stats['total_columns']}\")\n",
    "    print(f\"   ğŸ’¾ Memory: {discounts_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 2. PRODUCTS DATASET ANALYSIS\n",
    "    print(\"\\nğŸ“¦ PRODUCTS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    products_stats = {\n",
    "        'total_records': products_pl.shape[0],\n",
    "        'total_columns': products_pl.shape[1],\n",
    "        'columns': products_pl.columns,\n",
    "        'data_types': dict(zip(products_pl.columns, [str(dtype) for dtype in products_pl.dtypes])),\n",
    "        'null_counts': products_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': products_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Unique categories/brands analysis\n",
    "    if 'Category' in products_pl.columns:\n",
    "        products_stats['unique_categories'] = products_pl['Category'].n_unique()\n",
    "        products_stats['category_distribution'] = products_pl.group_by('Category').len().sort('len', descending=True).to_pandas().to_dict('records')\n",
    "    \n",
    "    # Price analysis if available\n",
    "    price_cols = [col for col in products_pl.columns if 'price' in col.lower() or 'cost' in col.lower()]\n",
    "    if price_cols:\n",
    "        products_stats['price_summary'] = products_pl.select(price_cols).describe().to_pandas().to_dict()\n",
    "    \n",
    "    stats_summary['products'] = products_stats\n",
    "    \n",
    "    print(f\"   ğŸ“‹ Records: {products_stats['total_records']:,}\")\n",
    "    print(f\"   ğŸ“Š Columns: {products_stats['total_columns']}\")\n",
    "    print(f\"   ğŸ’¾ Memory: {products_stats['memory_usage_mb']:.2f} MB\")\n",
    "    if 'unique_categories' in products_stats:\n",
    "        print(f\"   ğŸ·ï¸ Categories: {products_stats['unique_categories']}\")\n",
    "    \n",
    "    # 3. EMPLOYEES DATASET ANALYSIS\n",
    "    print(\"\\nğŸ‘¥ EMPLOYEES Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    employees_stats = {\n",
    "        'total_records': employees_pl.shape[0],\n",
    "        'total_columns': employees_pl.shape[1],\n",
    "        'columns': employees_pl.columns,\n",
    "        'data_types': dict(zip(employees_pl.columns, [str(dtype) for dtype in employees_pl.dtypes])),\n",
    "        'null_counts': employees_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': employees_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Department/Role analysis if available\n",
    "    dept_cols = [col for col in employees_pl.columns if any(keyword in col.lower() for keyword in ['department', 'role', 'position', 'title'])]\n",
    "    for col in dept_cols:\n",
    "        employees_stats[f'{col}_distribution'] = employees_pl.group_by(col).len().sort('len', descending=True).to_pandas().to_dict('records')\n",
    "    \n",
    "    stats_summary['employees'] = employees_stats\n",
    "    \n",
    "    print(f\"   ğŸ“‹ Records: {employees_stats['total_records']:,}\")\n",
    "    print(f\"   ğŸ“Š Columns: {employees_stats['total_columns']}\")\n",
    "    print(f\"   ğŸ’¾ Memory: {employees_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 4. STORES DATASET ANALYSIS\n",
    "    print(\"\\nğŸª STORES Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    stores_stats = {\n",
    "        'total_records': stores_pl.shape[0],\n",
    "        'total_columns': stores_pl.shape[1],\n",
    "        'columns': stores_pl.columns,\n",
    "        'data_types': dict(zip(stores_pl.columns, [str(dtype) for dtype in stores_pl.dtypes])),\n",
    "        'null_counts': stores_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': stores_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Location analysis if available\n",
    "    location_cols = [col for col in stores_pl.columns if any(keyword in col.lower() for keyword in ['city', 'state', 'country', 'region'])]\n",
    "    for col in location_cols:\n",
    "        if col in stores_pl.columns:\n",
    "            stores_stats[f'{col}_distribution'] = stores_pl.group_by(col).len().sort('len', descending=True).to_pandas().to_dict('records')\n",
    "    \n",
    "    stats_summary['stores'] = stores_stats\n",
    "    \n",
    "    print(f\"   ğŸ“‹ Records: {stores_stats['total_records']:,}\")\n",
    "    print(f\"   ğŸ“Š Columns: {stores_stats['total_columns']}\")\n",
    "    print(f\"   ğŸ’¾ Memory: {stores_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 5. CUSTOMERS DATASET ANALYSIS\n",
    "    print(\"\\nğŸ‘¤ CUSTOMERS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    customers_stats = {\n",
    "        'total_records': customers_pl.shape[0],\n",
    "        'total_columns': customers_pl.shape[1],\n",
    "        'columns': customers_pl.columns,\n",
    "        'data_types': dict(zip(customers_pl.columns, [str(dtype) for dtype in customers_pl.dtypes])),\n",
    "        'null_counts': customers_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': customers_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Demographics analysis\n",
    "    demo_cols = [col for col in customers_pl.columns if any(keyword in col.lower() for keyword in ['gender', 'age', 'city', 'state', 'country'])]\n",
    "    for col in demo_cols:\n",
    "        if col in customers_pl.columns:\n",
    "            customers_stats[f'{col}_distribution'] = customers_pl.group_by(col).len().sort('len', descending=True).head(10).to_pandas().to_dict('records')\n",
    "    \n",
    "    stats_summary['customers'] = customers_stats\n",
    "    \n",
    "    print(f\"   ğŸ“‹ Records: {customers_stats['total_records']:,}\")\n",
    "    print(f\"   ğŸ“Š Columns: {customers_stats['total_columns']}\")\n",
    "    print(f\"   ğŸ’¾ Memory: {customers_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 6. TRANSACTIONS DATASET ANALYSIS (Most Important)\n",
    "    print(\"\\nğŸ’³ TRANSACTIONS Dataset Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    transactions_stats = {\n",
    "        'total_records': transactions_pl.shape[0],\n",
    "        'total_columns': transactions_pl.shape[1],\n",
    "        'columns': transactions_pl.columns,\n",
    "        'data_types': dict(zip(transactions_pl.columns, [str(dtype) for dtype in transactions_pl.dtypes])),\n",
    "        'null_counts': transactions_pl.null_count().to_pandas().iloc[0].to_dict(),\n",
    "        'memory_usage_mb': transactions_pl.estimated_size('mb')\n",
    "    }\n",
    "    \n",
    "    # Financial metrics\n",
    "    financial_cols = [col for col in transactions_pl.columns if any(keyword in col.lower() for keyword in ['amount', 'total', 'price', 'cost', 'revenue', 'quantity'])]\n",
    "    if financial_cols:\n",
    "        transactions_stats['financial_summary'] = transactions_pl.select(financial_cols).describe().to_pandas().to_dict()\n",
    "    \n",
    "    # Date range analysis\n",
    "    date_cols = [col for col in transactions_pl.columns if any(keyword in col.lower() for keyword in ['date', 'time'])]\n",
    "    for col in date_cols:\n",
    "        if col in transactions_pl.columns:\n",
    "            try:\n",
    "                date_stats = transactions_pl.select([\n",
    "                    pl.col(col).min().alias('min_date'),\n",
    "                    pl.col(col).max().alias('max_date'),\n",
    "                    pl.col(col).n_unique().alias('unique_dates')\n",
    "                ]).to_pandas().iloc[0].to_dict()\n",
    "                transactions_stats[f'{col}_range'] = date_stats\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Unique counts for key columns\n",
    "    key_cols = ['Customer ID', 'Product ID', 'Store ID', 'Employee ID']\n",
    "    for col in key_cols:\n",
    "        if col in transactions_pl.columns:\n",
    "            transactions_stats[f'unique_{col.lower().replace(\" \", \"_\")}'] = transactions_pl[col].n_unique()\n",
    "    \n",
    "    stats_summary['transactions'] = transactions_stats\n",
    "    \n",
    "    print(f\"   ğŸ“‹ Records: {transactions_stats['total_records']:,}\")\n",
    "    print(f\"   ğŸ“Š Columns: {transactions_stats['total_columns']}\")\n",
    "    print(f\"   ğŸ’¾ Memory: {transactions_stats['memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 7. OVERALL SUMMARY\n",
    "    print(\"\\nğŸ“ˆ OVERALL DATA SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_records = sum([stats['total_records'] for stats in stats_summary.values()])\n",
    "    total_memory = sum([stats['memory_usage_mb'] for stats in stats_summary.values()])\n",
    "    \n",
    "    overall_stats = {\n",
    "        'total_datasets': len(stats_summary),\n",
    "        'total_records_across_all': total_records,\n",
    "        'total_memory_usage_mb': total_memory,\n",
    "        'analysis_timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    stats_summary['overall'] = overall_stats\n",
    "    \n",
    "    print(f\"   ğŸ“Š Total Datasets: {overall_stats['total_datasets']}\")\n",
    "    print(f\"   ğŸ“‹ Total Records: {overall_stats['total_records_across_all']:,}\")\n",
    "    print(f\"   ğŸ’¾ Total Memory: {overall_stats['total_memory_usage_mb']:.2f} MB\")\n",
    "    \n",
    "    # 8. SAVE RESULTS\n",
    "    print(f\"\\nğŸ’¾ Saving descriptive statistics...\")\n",
    "    \n",
    "    # Save as JSON\n",
    "    import json\n",
    "    with open(f\"{stats_dir}/descriptive_statistics_summary.json\", 'w') as f:\n",
    "        json.dump(stats_summary, f, indent=2, default=str)\n",
    "    \n",
    "    # Save detailed CSV reports for each dataset\n",
    "    for dataset_name, stats in stats_summary.items():\n",
    "        if dataset_name != 'overall':\n",
    "            stats_df = pd.DataFrame([stats])\n",
    "            stats_df.to_csv(f\"{stats_dir}/{dataset_name}_statistics.csv\", index=False)\n",
    "    \n",
    "    print(f\"âœ… Descriptive statistics completed!\")\n",
    "    print(f\"ğŸ“ Results saved in: {stats_dir}/\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return stats_summary\n",
    "\n",
    "# Usage in your main function:\n",
    "def load_data_and_analyze():\n",
    "    \"\"\"Load data and perform descriptive statistics\"\"\"\n",
    "    \n",
    "    # Load data (your existing function)\n",
    "    discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl = load_data_efficiently()\n",
    "    \n",
    "    # Perform descriptive statistics\n",
    "    stats_summary = perform_descriptive_statistics(\n",
    "        discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl\n",
    "    )\n",
    "    \n",
    "    return discounts_pl, products_pl, employees_pl, stores_pl, customers_pl, transactions_pl, stats_summary\n",
    "\n",
    "load_data_and_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b773a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Creating master dataset...\n",
      "ğŸ“Š Loading data efficiently...\n",
      "Loading discounts...\n",
      "Loading products...\n",
      "Loading employees...\n",
      "Loading stores...\n",
      "Loading customers...\n",
      "Loading transactions (this may take a moment)...\n",
      "Converting to Polars for better performance...\n",
      "âœ… Data loaded successfully!\n",
      "Transactions shape: (6416827, 19)\n",
      "ğŸ”§ Preparing optimized lookup tables...\n",
      "ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: ['Start', 'End']\n",
      "âœ… Converted Start to YYYY-MM-DD date format\n",
      "âœ… Converted End to YYYY-MM-DD date format\n",
      "ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: ['Date Of Birth']\n",
      "âœ… Converted Date Of Birth to YYYY-MM-DD date format\n",
      "âœ… Lookup tables prepared\n",
      "ğŸ’° Processing transactions...\n",
      "ğŸ—“ï¸ Converting date columns to YYYY-MM-DD format: ['Date']\n",
      "âœ… Converted Date to YYYY-MM-DD date format\n",
      "ğŸ’± Adding USD conversion...\n",
      "âœ… Created Unit_Price_USD\n",
      "âœ… Created Line_Total_USD\n",
      "âœ… Created Invoice_Total_USD\n",
      "ğŸ”— Merging tables...\n",
      "âœ… Merged with products. Shape: (6416827, 29)\n",
      "âœ… Merged with customers. Shape: (6416827, 34)\n",
      "âœ… Merged with stores. Shape: (6416827, 38)\n",
      "âœ… Merged with employees. Shape: (6416827, 41)\n",
      "ğŸ’¾ Saving lookup tables...\n",
      "ğŸ’¾ Saving master dataset...\n",
      "âœ… Master dataset created successfully!\n",
      "Final shape: (6416827, 41)\n",
      "Memory usage optimized by keeping only essential columns from lookup tables\n"
     ]
    }
   ],
   "source": [
    "master_data, discounts_lookup = create_master_dataset()\n",
    "# final_data = show_dataset_summary(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6e1497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6416827, 41)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58fe1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 =master_data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ad8213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6416029, 41)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cea357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading customers...\n"
     ]
    }
   ],
   "source": [
    "# Intial Transactions loaded: 6416827 rows\n",
    "import pandas as pd\n",
    "print(\"Loading customers...\")\n",
    "customers = pd.read_csv(r'C:\\Users\\Alan\\Downloads\\BDM\\BDM_raw_data\\transactions.csv', low_memory=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0bc0cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283707"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers['Customer ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c0970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
